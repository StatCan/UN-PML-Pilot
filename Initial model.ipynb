{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absolute-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joeri/UN-PML-Pilot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grateful-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "responsible-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "excessive-kernel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' X_train=pd.read_csv(\"./DATA/UCI_HAR_Dataset/train/X_train.txt\", delim_whitespace=True, names=[\"F\"+str(i) for i in range(1, 562)])\\ny_train=pd.read_csv(\"./DATA/UCI_HAR_Dataset/train/y_train.txt\", delim_whitespace=True, names=[\"label\"])\\ny_train[\\'label\\']=y_train[\\'label\\']-1\\n\\nX_test=pd.read_csv(\"./DATA/UCI_HAR_Dataset/test/X_test.txt\", delim_whitespace=True, names=[\"F\"+str(i) for i in range(1, 562)])\\ny_test=pd.read_csv(\"./DATA/UCI_HAR_Dataset/test/y_test.txt\", delim_whitespace=True, names=[\"label\"])\\ny_test[\\'label\\']=y_test[\\'label\\']-1 '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell for training with all original data\n",
    "\n",
    "\"\"\" X_train=pd.read_csv(\"./DATA/UCI_HAR_Dataset/train/X_train.txt\", delim_whitespace=True, names=[\"F\"+str(i) for i in range(1, 562)])\n",
    "y_train=pd.read_csv(\"./DATA/UCI_HAR_Dataset/train/y_train.txt\", delim_whitespace=True, names=[\"label\"])\n",
    "y_train['label']=y_train['label']-1\n",
    "\n",
    "X_test=pd.read_csv(\"./DATA/UCI_HAR_Dataset/test/X_test.txt\", delim_whitespace=True, names=[\"F\"+str(i) for i in range(1, 562)])\n",
    "y_test=pd.read_csv(\"./DATA/UCI_HAR_Dataset/test/y_test.txt\", delim_whitespace=True, names=[\"label\"])\n",
    "y_test['label']=y_test['label']-1 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell for training with data subset in format after running splitting script\n",
    "\n",
    "train_path = \"benchmark/benchmark_data/0/train/ALL_train.csv\"\n",
    "test_path = \"benchmark/benchmark_data/0/test/ALL_test.csv\"\n",
    "\n",
    "trainingset = pd.read_csv(train_path, delimiter=';')\n",
    "testset = pd.read_csv(test_path, delimiter=';')\n",
    "\n",
    "X_train = pd.concat([trainingset[str(i)]\n",
    "                    for i in range(561)], axis=1)\n",
    "y_train = trainingset['Y'] - 1\n",
    "\n",
    "X_test = pd.concat([testset[str(i)] for i in range(561)], axis=1)\n",
    "y_test = testset['Y'] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strong-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.concat([X_train,y_train],axis=1) \n",
    "\n",
    "testDF=pd.concat([X_test, y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amazing-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22184689,  0.03410767, -0.12361242, ..., -0.02075593,\n",
       "        -0.25526977,  3.        ],\n",
       "       [ 0.23715407,  0.00782512, -0.12283791, ...,  0.00614111,\n",
       "        -0.21275283,  3.        ],\n",
       "       [ 0.27394057, -0.01314758, -0.10543517, ..., -0.01704646,\n",
       "        -0.20844898,  3.        ],\n",
       "       ...,\n",
       "       [ 0.20754233, -0.04869768, -0.05346682, ...,  0.14532692,\n",
       "         0.00870735,  2.        ],\n",
       "       [ 0.22328281,  0.01391053, -0.21415242, ...,  0.25322243,\n",
       "         0.01445158,  1.        ],\n",
       "       [ 0.29966534, -0.05719341, -0.18123302, ...,  0.23860439,\n",
       "         0.04981914,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "removable-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.utils.data.TensorDataset(torch.tensor(X_train.values).float(), torch.as_tensor(y_train.values).squeeze())\n",
    "test_data=torch.utils.data.TensorDataset(torch.tensor(X_test.values).float(), torch.as_tensor(y_test.values).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "senior-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "#for X, y in test_dataloader:\n",
    "#    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "#    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sixth-candidate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=561, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(561, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "south-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=561, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "trying-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "premier-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        #print(\"pred:\",pred.shape, pred.dtype,\" y:\" ,y.shape,y.dtype)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secondary-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "altered-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.772827  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 1.772668 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.765643  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 27.5%, Avg loss: 1.765602 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.758855  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 24.7%, Avg loss: 1.758973 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.752440  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 21.7%, Avg loss: 1.752698 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.746350  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 19.7%, Avg loss: 1.746737 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.740558  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 19.3%, Avg loss: 1.741030 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.734956  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 19.0%, Avg loss: 1.735552 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.729540  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 19.3%, Avg loss: 1.730249 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.724337  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 1.725110 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.719289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 22.7%, Avg loss: 1.720103 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.714346  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 24.4%, Avg loss: 1.715208 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.709531  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 25.1%, Avg loss: 1.710406 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.704784  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 1.705680 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.700077  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 1.701001 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.695418  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 1.696360 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.690779  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 30.5%, Avg loss: 1.691765 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.686180  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 31.2%, Avg loss: 1.687199 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.681603  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 1.682648 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.677014  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 33.6%, Avg loss: 1.678104 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.672419  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 33.9%, Avg loss: 1.673574 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.667802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 1.669041 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.663178  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 1.664493 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.658546  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 1.659926 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.653889  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 1.655341 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.649203  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 1.650737 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.644497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 1.646107 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.639774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.641445 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.635021  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.636747 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.630233  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.632007 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.625409  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 42.4%, Avg loss: 1.627225 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.620544  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 42.4%, Avg loss: 1.622396 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.615622  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 1.617516 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.610645  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.612582 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.605620  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 1.607586 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.600548  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.602536 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.595433  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 1.597428 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.590251  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.592260 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.585007  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.587033 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.579708  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.581745 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.574347  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.576399 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.568924  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.571003 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.563453  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.565552 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.557935  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 1.560053 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.552371  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.554513 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.546753  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.548917 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.541080  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.543279 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.535361  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.537591 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.529598  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.531859 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.523780  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.526078 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.517919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.520257 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.512023  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.514388 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.506076  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.508474 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.500084  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.502522 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.494057  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.496521 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.487985  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 1.490476 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.481868  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.484396 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.475713  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 1.478283 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.469527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.472129 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.463305  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.465951 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.457050  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.459755 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.450764  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.453534 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.444464  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.447295 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.438153  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.441037 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 1.431826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.434760 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.425481  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.428465 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.419125  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.422160 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.412766  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.415847 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.406415  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.409531 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.400065  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.403211 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.393705  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.396884 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.387356  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.390560 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.381017  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.384235 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.374695  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.377921 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.368392  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.371615 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.362115  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.365325 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.355862  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.359055 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.349629  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.352804 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.343423  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.346575 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.337248  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.340372 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.331113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.334198 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.325016  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.328057 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.318965  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.321949 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 1.312956  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.315880 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.306987  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.309850 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.301069  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.303862 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.295207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.297917 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.289403  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.292019 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.283653  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.286172 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.277963  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.280376 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.272331  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.274634 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.266765  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.268945 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.261260  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.263312 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 1.255824  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.257738 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.250453  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.252220 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.245146  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.246751 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.239902  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.241338 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 1.234725  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.235984 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 1.229610  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.230688 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.224562  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.225450 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 1.219583  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.220271 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 1.214677  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.215159 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 1.209842  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.210109 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 1.205068  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.205121 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 1.200364  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.200200 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 1.195732  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.195345 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 1.191170  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.190556 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 1.186678  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.185837 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 1.182255  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.181178 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 1.177893  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.176581 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 1.173594  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.172049 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 1.169360  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.167577 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 1.165195  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.163162 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 1.161096  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.158807 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 1.157070  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.154512 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 1.153109  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.150274 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 1.149208  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.146088 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 1.145366  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.141959 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 1.141580  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.137882 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 1.137848  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.133860 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 1.134171  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 1.129892 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 1.130540  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 1.125974 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 1.126963  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.122103 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 1.123438  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1.118281 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 1.119959  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.114508 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 1.116527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.110781 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 1.113152  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.107099 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 1.109825  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.103461 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 1.106543  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.099870 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 1.103302  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.096320 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 1.100106  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.092815 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 1.096950  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.089349 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 1.093832  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.085920 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 1.090751  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.082529 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 1.087706  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1.079173 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 1.084695  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.075852 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 1.081713  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.072563 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 1.078768  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.069308 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 1.075857  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.066087 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 1.072976  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.062897 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 1.070122  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.059742 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 1.067296  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.056617 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 1.064494  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.053523 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 1.061720  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.050457 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 1.058973  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 1.047417 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 1.056253  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 1.044404 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 1.053554  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 1.041417 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 1.050881  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 1.038456 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 1.048229  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.035518 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 1.045597  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.032604 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 1.042986  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.029710 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 1.040398  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.026840 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 1.037822  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.023993 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 1.035266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.021166 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 1.032727  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.018358 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 1.030200  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.015569 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 1.027689  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.012800 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 1.025194  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.010051 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 1.022712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.007324 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 1.020241  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.004615 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 1.017789  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 1.001925 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 1.015356  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.999253 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 1.012935  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.996598 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 1.010526  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.993958 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 1.008130  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.991334 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 1.005742  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.988725 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 1.003366  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.986132 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 1.001001  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.983551 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.998646  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.980988 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.996300  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.978437 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.993964  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.975901 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.991639  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.973377 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.989324  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.970865 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.987016  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.968366 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.984717  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.965877 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.982425  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.963400 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.980142  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.960935 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.977867  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.958482 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.975599  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.956042 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.973338  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.953613 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.971083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.951196 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.968833  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.948790 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.966589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.946394 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.964355  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.944008 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.962128  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.941632 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.959903  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.939268 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.957685  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 0.936913 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.955471  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.934568 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.953260  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.932232 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.951054  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.929906 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.948852  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.927590 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.946656  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.925283 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.944467  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.922985 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.942288  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.920697 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.940113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.918419 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.937941  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.916151 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.935773  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.913891 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.933608  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.911641 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.931449  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.909400 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.929296  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.907169 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.927145  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.904946 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.925001  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.902733 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.922859  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.900530 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.920722  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.898337 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.918589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.896155 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.916459  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.893982 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.914334  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.891819 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.912213  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.889664 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.910098  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.887517 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.907987  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.885378 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.905875  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.883248 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.903768  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.881128 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.901663  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.879017 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.899564  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.876914 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.897469  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.874822 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.895377  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.872740 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.893292  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.870667 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.891210  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.868604 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.889131  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.866550 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.887057  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.864505 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.884992  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.862469 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.882930  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.860442 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.880876  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.858424 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.878828  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.856416 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.876783  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.854417 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.874741  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.852427 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.872704  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.850445 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.870672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.848474 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.868643  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.846512 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.866619  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.844558 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.864601  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.842615 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.862585  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.840679 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.860577  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.838753 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.858574  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.836833 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.856577  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.834924 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.854581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.833022 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.852588  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.831130 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.850603  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.829247 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.848620  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.827375 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.846642  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.825511 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.844666  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.823658 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.842696  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.821814 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.840732  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.819979 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.838774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.818153 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.836823  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.816335 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.834875  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.814526 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.832934  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.812723 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.830999  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.810933 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.829068  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.809152 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.827141  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.807378 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.825219  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.805612 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.823304  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.803855 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.821395  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.802107 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.819490  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.800369 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.817589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.798640 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.815691  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.796920 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.813798  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.795209 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.811911  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.793508 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.810034  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.791814 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.808160  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.790130 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.806292  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.788454 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.804428  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.786785 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.802571  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.785127 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.800719  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.783479 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.798865  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.781840 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.797019  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.780210 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.795176  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.778589 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.793340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.776977 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.791511  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.775374 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.789686  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.773777 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.787868  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.772190 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.786057  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.770613 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.784252  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.769043 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.782453  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.767481 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.780657  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.765926 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.778865  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.764380 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.777075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.762843 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.775289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.761312 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.773506  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.759790 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.771729  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.758275 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.769958  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.756767 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.768194  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.755267 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.766434  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.753776 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.764682  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.752292 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.762937  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.750816 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.761199  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.749348 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.759464  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.747888 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.757728  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.746433 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.755998  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.744986 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.754272  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.743546 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.752553  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.742115 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.750837  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.740692 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.749126  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.739278 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.747421  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.737871 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.745718  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.736469 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.744018  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.735074 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.742325  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.733685 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.740639  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.732303 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.738954  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.730928 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.737275  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.729560 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.735600  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.728198 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.733932  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.726844 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.732269  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.725496 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.730609  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.724155 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.728951  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.722820 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.727298  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.721491 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.725650  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.720170 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.724005  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.718855 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.722362  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.717545 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.720722  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.716241 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.719086  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.714941 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.717451  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.713647 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.715820  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.712361 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.714194  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.711079 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.712576  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.709803 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.710962  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.708532 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.709352  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.707267 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.707745  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.706007 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.706141  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.704751 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.704543  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.703502 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.702949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.702258 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.701361  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.701021 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.699776  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.699791 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.698195  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.698565 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.696619  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.697345 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.695047  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.696129 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.693480  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.694919 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.691916  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.693713 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.690358  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.692512 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.688806  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.691317 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.687254  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.690127 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.685706  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.688943 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.684161  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.687764 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.682619  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.686589 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.681083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.685420 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.679551  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.684256 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.678023  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.683094 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.676496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.681939 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.674975  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.680788 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.673456  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.679641 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.671943  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.678498 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.670430  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.677359 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.668919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.676225 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.667407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.675096 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.665897  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.673970 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.664389  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.672851 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.662885  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.671734 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.661385  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.670621 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.659887  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.669513 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.658390  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.668407 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.656898  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.667308 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.655407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.666209 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.653921  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.665116 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.652441  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.664024 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.650960  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.662938 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.649480  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.661856 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.648004  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.660776 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.646532  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.659703 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.645066  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.658631 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.643600  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.657563 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.642138  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.656498 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.640679  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.655435 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.639223  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.654378 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.637771  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.653324 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.636323  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.652274 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.634879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.651227 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.633437  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.650185 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.631999  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.649143 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.630562  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.648107 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.629128  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.647073 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.627697  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.646042 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.626268  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.645015 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.624842  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.643992 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.623419  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.642973 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.621998  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.641956 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.620579  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.640942 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.619164  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.639931 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.617749  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.638923 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.616338  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.637919 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.614929  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.636916 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.613522  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.635917 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.612118  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.634921 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.610716  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.633926 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.609316  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.632935 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.607919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.631948 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.606522  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.630962 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.605127  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.629980 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.603735  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.628999 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.602345  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.628022 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.600957  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.627048 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.599572  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.626078 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.598188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.625109 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.596808  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.624145 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.595431  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.623183 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.594056  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.622221 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.592683  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.621263 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.591315  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.620308 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.589949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.619353 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.588585  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.618402 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.587225  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.617454 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.585866  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.616507 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.584511  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.615563 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.583155  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.614622 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.581802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.613683 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.580454  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.612748 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.579111  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.611814 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.577770  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.610883 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.576430  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.609954 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.575093  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.609026 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.573757  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.608100 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.572424  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.607176 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.571092  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.606256 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.569764  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.605340 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.568437  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.604424 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.567112  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.603512 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.565789  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.602600 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.564469  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.601690 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.563151  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.600782 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.561834  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.599876 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.560520  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.598973 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.559212  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.598072 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.557902  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.597175 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.556595  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.596277 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.555289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.595384 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.553988  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.594491 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.552689  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.593599 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.551391  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.592709 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.550097  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.591822 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.548805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.590936 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.547520  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.590049 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.546233  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.589167 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.544951  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.588287 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.543670  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.587406 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.542389  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.586530 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.541110  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.585655 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.539832  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.584782 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.538556  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.583911 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.537283  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.583044 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.536013  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.582177 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.534745  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.581310 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.533479  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.580447 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.532214  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.579583 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.530950  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.578723 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.529690  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.577863 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.528432  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.577007 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.527178  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.576152 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.525925  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.575300 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.524676  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.574450 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.523431  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.573601 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.522188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.572756 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.520950  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.571912 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.519714  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.571069 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.518480  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.570228 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.517248  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.569388 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.516018  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.568548 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.514790  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.567714 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.513564  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.566879 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.512338  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.566045 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.511115  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.565212 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.509895  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.564384 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.508677  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.563556 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.507460  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.562727 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.506247  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.561903 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.505037  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.561081 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.503831  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.560262 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.502626  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.559443 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.501424  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.558626 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.500224  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.557812 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.499023  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.557001 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.497828  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.556188 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.496634  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.555377 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.495446  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.554572 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.494259  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.553765 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.493074  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.552964 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.491893  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.552163 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.490713  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.551363 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.489536  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.550561 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.488363  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.549763 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.487191  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.548966 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.486022  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.548171 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.484855  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.547378 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.483692  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.546587 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.482530  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.545797 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.481373  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.545009 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.480217  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.544222 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.479064  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.543441 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.477914  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.542658 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.476767  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.541880 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.475623  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.541100 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.474479  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.540322 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.473338  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.539547 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.472198  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.538773 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.471064  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.538002 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.469931  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.537230 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.468802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.536462 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.467675  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.535696 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.466551  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.534928 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.465433  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.534163 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.464314  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.533399 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.463195  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.532637 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.462083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.531879 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.460972  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.531120 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.459865  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.530369 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.458761  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.529613 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.457658  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.528861 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.456559  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.528111 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.455462  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.527364 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.454366  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.526618 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.453273  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.525874 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.452184  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.525133 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.451097  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.524389 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.450011  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.523650 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.448928  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.522912 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.447848  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.522174 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.446771  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.521439 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.445696  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.520708 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.444626  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.519976 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.443559  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.519245 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.442496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.518518 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.441435  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.517791 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.440376  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.517069 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.439320  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.516347 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.438266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.515624 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.437214  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.514904 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.436167  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.514188 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.435124  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.513472 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.434083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.512756 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.433043  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.512045 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.432005  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.511336 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.430971  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.510627 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.429937  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.509920 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.428908  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.509216 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.427883  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.508511 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.426859  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.507808 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.425840  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.507106 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.424820  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.506401 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.423804  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.505701 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.422790  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.505004 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.421779  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.504309 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.420774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.503614 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.419767  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.502923 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.418767  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.502229 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.417766  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.501537 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.416770  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.500853 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.415779  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.500164 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.414788  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.499481 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.413802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.498800 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.412816  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.498119 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.411835  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.497438 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.410854  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.496763 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.409879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.496085 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.408905  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.495408 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.407934  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.494734 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.406967  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.494065 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.406003  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.493394 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.405041  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.492728 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.404082  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.492060 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.403125  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.491394 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.402171  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.490728 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.401219  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.490065 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.400270  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.489404 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.399324  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.488746 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.398381  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.488086 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.397439  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.487433 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.396502  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.486779 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.395567  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.486126 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.394635  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.485474 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.393704  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.484824 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.392777  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.484177 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.391854  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.483527 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.390931  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.482884 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.390014  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.482242 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.389099  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.481597 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.388188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.480960 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.387281  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.480325 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.386376  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.479688 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.385473  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.479054 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.384573  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.478422 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.383674  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.477788 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.382776  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.477157 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.381881  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.476529 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.380990  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.475900 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.380101  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.475276 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.379216  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.474654 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.378332  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.474038 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.377457  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.473414 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.376576  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.472798 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.375703  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.472182 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.374834  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.471565 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.373966  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.470952 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.373101  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.470338 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.372236  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.469726 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.371373  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.469109 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.370512  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.468505 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.369655  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.467897 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.368800  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.467294 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.367948  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.466692 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.367099  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.466088 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.366250  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.465492 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.365407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.464896 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.364565  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.464302 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.363729  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.463707 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.362893  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.463118 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.362060  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.462517 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.361227  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.461934 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.360401  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.461348 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.359578  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.460761 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.358754  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.460177 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.357935  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.459595 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.357117  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.459008 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.356301  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.458433 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.355491  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.457849 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.354680  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.457272 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.353872  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.456699 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.353069  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.456122 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.352266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.455549 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.351467  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.454977 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.350670  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.454405 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.349876  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.453836 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.349083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.453269 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.348294  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.452705 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.347506  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.452138 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.346720  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.451576 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.345935  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.451009 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.345151  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.450446 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.344370  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.449887 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.343589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.449329 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.342813  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.448769 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.342037  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.448211 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.341265  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.447657 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.340499  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.447104 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.339734  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.446551 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.338971  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.446005 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.338213  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.445446 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.337451  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444901 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.336696  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.444357 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.335943  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.443815 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.335194  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.443275 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.334447  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.442737 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.333703  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.442196 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.332960  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441660 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.332219  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441118 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.331478  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.440585 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.330742  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.440052 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.330007  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.439519 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.329274  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.438987 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.328542  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.438453 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.327812  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.437925 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.327086  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.437394 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.326361  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.436870 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.325641  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.436338 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.324919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.435818 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.324203  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.435296 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.323488  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.434776 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.322775  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.434259 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.322066  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.433739 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.321358  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.433220 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.320653  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.432708 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.319951  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.432190 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.319250  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.431681 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.318553  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.431172 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.317858  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.430660 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.317163  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.430152 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.316472  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.429648 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.315783  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.429138 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.315095  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.428636 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.314409  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.428130 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.313724  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.427629 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.313042  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.427128 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.312364  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.426624 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.311685  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.426125 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.311012  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.425629 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.310340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.425127 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.309670  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.424634 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.309003  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.424144 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.308340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.423647 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.307676  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.423158 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.307014  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.422676 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.306356  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.422186 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.305698  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.421697 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.305042  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.421209 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.304388  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.420723 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.303737  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.420233 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.303086  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.419751 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.302438  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.419263 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.301788  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.418785 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.301142  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.418308 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.300497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.417828 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.299853  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.417350 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.299212  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.416872 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.298573  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.416397 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.297937  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.415923 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.297303  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.415446 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.296672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.414975 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.296041  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.414503 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.295415  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.414040 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.294792  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.413569 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.294168  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.413100 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.293544  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.412635 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.292925  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.412170 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.292308  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.411708 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.291692  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.411246 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.291079  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.410785 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.290468  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.410325 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.289858  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.409866 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.289252  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.409411 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.288646  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.408950 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.288040  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.408496 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.287437  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.408041 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.286836  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.407586 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.286236  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.407129 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.285637  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.406683 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.285043  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.406231 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.284447  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.405778 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.283852  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.405336 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.283263  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.404885 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.282672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.404433 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.282081  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.403992 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.281496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.403544 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.280910  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.403101 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.280327  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.402659 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.279747  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.402216 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.279167  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.401775 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.278589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.401341 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.278015  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.400902 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.277440  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.400466 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.276868  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.400028 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.276297  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.399593 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.275728  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.399155 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.275158  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.398723 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.274592  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.398291 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.274027  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.397862 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.273464  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.397433 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.272902  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.397004 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.272340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.396577 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.271783  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.396151 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.271225  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.395725 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.270669  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.395302 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.270117  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.394880 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.269564  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.394460 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.269014  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.394040 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.268465  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.393624 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.267918  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.393206 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.267372  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.392789 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.266826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.392370 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.266283  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.391953 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.265740  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.391537 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.265200  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.391123 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.264660  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.390711 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.264123  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.390298 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.263588  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.389883 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.263050  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.389473 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.262518  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.389063 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.261986  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.388653 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.261457  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.388246 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.260929  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387845 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.260404  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387441 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.259880  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387037 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.259356  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.386633 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.258834  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.386232 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.258315  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.385830 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.257796  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.385431 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.257281  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.385030 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.256765  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.384629 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.256251  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.384229 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.255737  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.383832 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.255228  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.383440 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.254720  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.383043 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.254211  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382652 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.253707  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382263 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.253203  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.381868 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.252699  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.381480 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.252199  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.381091 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.251698  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.380699 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.251199  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.380313 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.250703  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.379923 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.250207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.379536 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.249713  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.379151 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.249219  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.378765 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.248729  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.378377 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.248236  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377992 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.247748  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377610 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.247259  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377231 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.246774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.376848 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.246289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.376466 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.245804  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.376088 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.245322  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.375709 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.244842  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.375336 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.244363  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374962 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.243885  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374583 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.243408  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374211 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.242932  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.373839 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.242458  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.373471 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.241988  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.373103 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.241518  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.372731 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.241048  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.372365 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.240581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.371992 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.240113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.371626 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.239649  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.371264 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.239185  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.370898 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.238723  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.370530 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.238260  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.370168 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.237798  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369800 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.237339  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369437 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.236879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369075 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.236422  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368712 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.235965  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368351 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.235510  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.367998 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.235059  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.367635 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.234606  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.367272 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.234154  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.366915 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.233705  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.366556 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.233256  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.366199 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.232809  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.365845 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.232364  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.365487 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.231919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.365130 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.231474  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.364771 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.231030  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.364425 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.230591  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.364067 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.230150  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.363719 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.229712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.363365 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.229274  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.363014 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.228837  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362665 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.228401  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362317 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.227967  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.361970 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.227534  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.361617 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.227099  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.361274 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.226669  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.360930 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.226240  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.360584 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.225810  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.360234 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.225380  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359893 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.224954  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359546 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.224527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359206 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.224103  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.358870 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.223683  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.358524 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.223259  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.358185 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.222838  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.357842 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.222417  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.357505 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.221999  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.357164 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.221581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.356830 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.221165  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.356495 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.220749  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.356161 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.220335  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355828 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.219923  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355488 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.219509  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355158 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.219098  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.354824 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.218687  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.354494 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.218278  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.354165 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.217873  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.353843 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.217468  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.353511 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.217062  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.353183 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.216659  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352857 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.216256  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352530 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.215855  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352202 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.215452  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.351879 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.215055  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.351556 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.214659  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.351228 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.214259  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.350901 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.213863  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.350577 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.213466  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.350253 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.213073  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.349930 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.212679  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.349606 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.212286  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.349288 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.211895  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.348967 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.211506  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.348651 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.211116  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.348331 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.210728  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.348015 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.210341  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347699 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.209955  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347378 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.209569  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347069 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.209188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346754 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.208805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346436 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.208422  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346128 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.208043  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.345812 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.207662  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.345499 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.207282  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.345188 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.206904  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.344878 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.206527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.344562 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.206149  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.344254 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.205774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.343946 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.205401  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.343634 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.205026  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.343325 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.204652  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.343021 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.204282  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342714 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.203911  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342407 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.203541  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342098 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.203172  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.341794 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.202804  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.341490 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.202439  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.341182 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.202073  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340886 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.201712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340579 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.201347  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340281 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.200986  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.339981 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.200625  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.339679 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.200264  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.339382 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.199906  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.339084 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.199547  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.338787 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.199191  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.338483 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.198832  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.338191 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.198479  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.337894 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.198124  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.337594 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.197768  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.337298 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.197415  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.337002 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.197063  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336710 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.196712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336417 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.196363  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336123 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.196013  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335833 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.195666  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335536 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.195316  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.335246 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.194969  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.334950 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.194621  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.334664 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.194276  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.334373 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.193932  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.334083 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.193589  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.333793 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.193247  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.333509 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.192905  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.333221 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.192565  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.332930 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.192225  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.332649 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.191887  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.332363 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.191549  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.332076 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.191212  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331795 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.190875  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331508 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.190538  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.331228 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.190204  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.330946 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.189870  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.330662 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.189536  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.330374 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.189201  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.330100 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.188871  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329814 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.188539  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329531 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.188208  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.329258 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.187881  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328976 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.187552  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328694 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.187223  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328423 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.186897  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328138 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.186569  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.327868 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.186247  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.327588 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.185920  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.327314 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.185599  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.327039 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.185276  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.326771 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.184957  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.326490 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.184635  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.326224 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.184318  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.325947 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.183997  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.325682 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.183681  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.325411 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.183364  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.325142 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.183048  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.324867 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.182731  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.324603 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.182418  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.324330 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.182104  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.324065 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.181790  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.323799 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.181479  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.323529 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.181166  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.323268 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.180858  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.322998 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.180546  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.322733 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.180238  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.322473 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.179930  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.322207 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.179622  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.321947 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.179316  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.321680 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.179008  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.321414 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.178702  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.321152 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.178398  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.320889 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.178093  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.320631 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.177790  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.320367 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.177487  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.320108 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.177185  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.319847 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.176885  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.319589 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.176585  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.319330 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.176287  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.319071 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.175987  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.318809 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.175688  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.318550 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.175391  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.318293 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.175095  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.318033 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.174798  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.317785 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.174504  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.317525 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.174208  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.317269 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.173914  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.317020 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.173623  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.316766 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.173332  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.316515 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.173040  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.316258 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.172748  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.316009 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.172459  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.315754 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.172168  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.315505 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.171881  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.315249 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.171591  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.314997 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.171304  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.314751 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.171019  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.314499 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.170734  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.314248 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.170447  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.313998 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.170165  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.313748 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.169879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.313501 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.169598  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.313251 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.169315  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.312997 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.169031  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.312756 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.168752  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.312507 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.168470  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.312258 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.168191  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.312019 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.167913  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.311769 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.167634  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.311527 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.167356  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.311282 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.167079  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.311038 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.166802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.310800 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.166527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.310550 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.166251  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.310312 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.165975  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.310067 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.165699  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.309830 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.165426  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.309589 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.165152  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.309348 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.164878  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.309109 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.164607  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.308870 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.164335  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.308632 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.164063  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.308397 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.163794  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.308160 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.163525  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.307927 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.163257  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.307690 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.162989  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.307453 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.162721  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.307221 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.162455  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306980 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.162188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306752 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.161925  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306511 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.161659  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306275 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.161394  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.306041 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.161130  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.305801 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.160865  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.305571 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.160604  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.305341 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.160343  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.305106 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.160082  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.304875 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.159821  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.304644 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.159562  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.304418 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.159303  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.304184 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.159045  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.303959 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.158787  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.303724 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.158528  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.303495 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.158272  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.303269 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.158016  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.303038 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.157759  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.302807 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.157503  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.302580 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.157249  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.302352 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.156996  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.302126 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.156743  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.301896 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.156487  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.301679 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.156239  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.301449 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.155984  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.301227 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.155734  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.301003 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.155483  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.300779 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.155234  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.300555 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.154983  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.300333 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.154734  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.300109 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.154486  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.299886 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.154238  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.299665 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.153991  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.299438 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.153743  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.299216 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.153496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.298999 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.153252  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.298778 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.153005  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.298558 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.152761  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.298338 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.152517  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.298117 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.152272  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297902 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.152030  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297682 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.151786  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297465 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.151545  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297244 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.151303  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297030 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.151062  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.296812 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.150821  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.296597 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.150582  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.296381 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.150342  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.296166 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.150103  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.295952 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.149866  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.295734 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.149626  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.295524 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.149390  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.295305 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.149151  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.295093 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.148916  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.294886 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.148682  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.294670 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.148447  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.294459 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.148213  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.294245 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.147979  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.294034 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.147746  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.293824 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.147514  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.293610 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.147280  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.293403 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.147051  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.293181 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.146818  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292974 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.146588  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292762 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.146357  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292551 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.146127  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292344 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.145900  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292134 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.145669  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.291924 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.145441  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.291721 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.145214  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.291518 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.144987  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.291306 \n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.144760  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.291105 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.144536  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290894 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.144309  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290692 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.144085  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290490 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.143861  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290283 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.143636  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.290075 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.143413  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.289874 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.143190  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.289665 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.142966  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.289462 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.142744  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.289266 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.142525  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.289056 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.142303  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.288852 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.142081  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.288650 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.141862  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.288450 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.141643  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.288243 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.141423  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.288042 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.141204  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.287843 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.140987  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.287641 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.140770  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.287440 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.140552  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.287243 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.140338  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.287038 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.140120  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.286838 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.139906  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.286642 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.139691  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.286440 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.139476  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.286247 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.139266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.286047 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.139051  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.285843 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.138838  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.285651 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.138627  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.285456 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.138415  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.285260 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.138205  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.285056 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.137992  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.284867 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.137784  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.284668 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.137573  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.284470 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.137363  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.284283 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.137158  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.284082 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.136948  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.283894 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.136741  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.283695 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.136533  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.283505 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.136328  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.283309 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.136120  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.283116 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.135914  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.282924 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.135710  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.282736 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.135506  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.282539 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.135302  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.282351 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.135097  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.282156 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.134893  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.281969 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.134690  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.281773 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.134486  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.281585 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.134284  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.281395 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.134083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.281205 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.133880  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.281015 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.133679  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.280826 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.133478  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.280638 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.133277  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.280452 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.133078  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.280268 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.132879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.280072 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.132677  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.279890 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.132481  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.279705 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.132284  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.279521 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.132087  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.279338 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.131892  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.279146 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.131694  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.278964 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.131500  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.278777 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.131304  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.278594 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.131109  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.278403 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.130913  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.278227 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.130721  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.278039 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.130526  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.277864 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.130337  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.277670 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.130140  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.277492 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.129949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.277311 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.129757  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.277129 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.129565  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.276944 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.129373  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.276763 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.129182  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.276587 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.128993  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.276394 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.128800  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.276228 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.128614  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.276047 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.128426  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.275860 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.128235  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.275690 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.128049  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.275510 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.127861  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.275329 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.127673  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.275149 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.127486  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274976 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.127300  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274794 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.127113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274620 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.126928  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274446 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.126744  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274264 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.126559  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.274091 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.126376  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.273917 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.126192  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.273738 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.126009  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.273564 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.125826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.273386 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.125643  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.273209 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.125460  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.273032 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.125277  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.272855 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.125096  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.272676 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.124913  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.272511 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.124733  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.272329 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.124551  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.272154 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.124371  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271975 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.124190  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271801 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.124009  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271626 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.123829  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271450 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.123651  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271281 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.123472  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.271104 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.123293  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270929 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.123113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270756 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.122935  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270583 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.122757  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270408 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.122579  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270242 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.122403  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.270068 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.122227  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269899 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.122050  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269722 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.121874  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269553 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.121698  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269389 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.121525  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269214 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.121349  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.269042 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.121175  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268877 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.121002  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268704 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.120826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268538 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.120653  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268378 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.120484  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268201 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.120310  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.268035 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.120135  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267871 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.119964  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267704 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.119793  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267537 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.119623  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267368 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.119453  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267203 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.119282  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.267039 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.119113  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.266870 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.118943  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.266699 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.118773  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.266537 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.118603  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.266375 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.118435  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.266211 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.118268  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.266048 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.118102  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265882 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.117933  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265718 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.117765  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265552 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.117598  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265390 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.117433  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265224 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.117266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.265059 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.117100  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264901 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.116938  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264738 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.116771  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264573 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.116606  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264412 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.116443  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264246 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.116278  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.264088 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.116116  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263926 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.115952  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263762 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.115789  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263602 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.115627  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263435 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.115464  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263280 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.115303  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.263122 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.115142  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262954 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.114980  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262789 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.114819  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262636 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.114661  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262481 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.114501  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262312 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.114340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.262152 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.114181  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261992 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.114023  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261838 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.113867  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261678 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.113709  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261518 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.113549  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261356 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.113392  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261202 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.113236  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261047 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.113079  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260884 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.112921  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260729 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.112765  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260566 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.112610  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260410 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.112454  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260253 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.112299  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.260092 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.112142  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259943 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.111989  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259781 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.111834  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259620 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.111678  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259464 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.111524  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259315 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.111371  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.259152 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.111216  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258998 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.111065  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258846 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.110913  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258689 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.110760  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258532 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.110607  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258377 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.110454  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258224 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.110305  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.258068 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.110152  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.257914 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.110001  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.257764 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.109851  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.257611 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.109702  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.257458 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.109553  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.257301 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.109402  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.257159 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.109256  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.257008 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.109108  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256849 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.108959  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256696 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.108812  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256543 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.108664  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256399 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.108518  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256239 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.108369  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.256094 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.108223  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255943 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.108077  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255799 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.107933  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255641 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.107784  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255496 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.107641  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255347 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.107496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255197 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.107353  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.255048 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.107207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254890 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.107061  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254750 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.106921  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254598 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.106777  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254450 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.106631  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254298 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.106490  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254155 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.106346  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.254004 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.106205  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.253863 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.106063  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.253703 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.105919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.253560 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.105777  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.253417 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.105639  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.253275 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.105498  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.253120 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.105355  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252978 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.105217  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252832 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.105076  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252683 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.104936  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252544 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.104799  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252396 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.104657  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252252 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.104521  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.252108 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.104382  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251969 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.104244  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251824 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.104108  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251673 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.103969  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251536 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.103831  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251393 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.103695  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251246 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.103558  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.251111 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.103424  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250961 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.103285  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250824 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.103151  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250675 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.103013  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250541 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.102878  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250400 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.102745  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250251 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.102608  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.250116 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.102475  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249972 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.102340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249832 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.102207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249686 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.102072  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249552 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.101941  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249403 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.101805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249261 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.101674  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.249128 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.101542  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.248984 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.101409  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.248837 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.101276  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.248705 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.101148  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.248558 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.101013  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.248420 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.100883  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.248282 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.100752  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.248142 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.100619  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.248008 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.100493  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247864 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.100360  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247730 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.100231  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247587 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.100098  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247452 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.099970  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247311 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.099839  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247172 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.099712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.247028 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.099578  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246891 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.099451  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246755 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.099322  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246607 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.099193  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246474 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.099065  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246339 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.098938  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246204 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.098812  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.246061 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.098683  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245928 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.098556  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245795 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.098431  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245651 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.098302  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245531 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.098179  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245382 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.098051  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245247 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.097925  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.245120 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.097801  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244978 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.097675  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244855 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.097552  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244708 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.097424  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244584 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.097302  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244448 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.097177  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244313 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.097053  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244184 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.096930  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.244048 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.096805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243918 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.096683  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243784 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.096560  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243654 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.096438  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243520 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.096313  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243386 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.096192  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243260 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.096072  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.243126 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.095949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242995 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.095827  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242861 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.095704  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242737 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.095586  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242599 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.095463  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242468 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.095343  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242342 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.095225  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242200 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.095101  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.242079 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.094984  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.241947 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.094862  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.241805 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.094742  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.241679 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.094623  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.241557 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.094505  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.241425 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.094386  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.241303 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.094270  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.241162 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.094149  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.241044 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.094033  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.240912 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.093914  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.240779 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.093797  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.240657 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.093680  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240535 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.093564  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240401 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.093446  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240274 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.093331  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240146 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.093213  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.240023 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.093099  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239885 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.092982  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239764 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.092867  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239646 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.092754  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239517 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.092637  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239393 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.092524  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239260 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.092407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239138 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.092293  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.239008 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.092177  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238889 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.092065  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238759 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.091949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238635 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.091837  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238504 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.091721  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238383 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.091609  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238262 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.091497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238137 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.091382  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.238005 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.091269  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237880 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.091157  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237761 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.091044  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237629 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.090932  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237516 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.090820  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237384 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.090706  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237264 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.090597  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237145 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.090487  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.237016 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.090373  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236895 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.090262  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236770 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.090151  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236653 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.090042  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236530 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.089929  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236409 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.089820  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236287 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.089712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236165 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.089600  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.236043 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.089493  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235926 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.089383  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235804 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.089274  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235682 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.089165  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235557 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.089057  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235439 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.088949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235316 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.088839  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235197 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.088732  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.235076 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.088624  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234960 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.088516  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234836 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.088410  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234721 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.088302  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234606 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.088195  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234481 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.088088  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234360 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.087981  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234238 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.087875  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234120 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.087769  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.234002 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.087662  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233877 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.087557  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233758 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.087452  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233638 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.087345  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233521 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.087241  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233404 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.087137  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233281 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.087031  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233170 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.086928  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.233048 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.086824  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232933 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.086721  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232817 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.086617  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232691 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.086513  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232579 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.086410  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232465 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.086307  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232348 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.086204  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232233 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.086102  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.232115 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.086000  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231999 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.085897  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231883 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.085794  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231771 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.085693  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231650 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.085590  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231537 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.085489  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231425 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.085388  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231309 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.085287  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231188 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.085186  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.231078 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.085084  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230963 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.084984  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230849 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.084884  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230734 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.084785  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230621 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.084685  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230503 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.084584  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230384 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.084485  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230274 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.084386  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230159 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.084286  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.230047 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.084189  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229933 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.084089  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229817 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.083990  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229701 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.083893  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229586 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.083794  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229473 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.083696  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229362 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.083598  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229252 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.083503  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229135 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.083405  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.229021 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.083309  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228913 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.083211  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228794 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.083115  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228689 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.083019  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228569 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.082922  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228465 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.082826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228345 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.082731  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228237 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.082634  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228117 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.082537  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.228014 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.082444  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227899 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.082347  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227794 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.082252  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227680 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.082158  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227566 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.082062  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227460 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.081969  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227339 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.081872  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227230 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.081778  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227128 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.081684  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.227015 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.081591  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226901 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.081496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226802 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.081403  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226686 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.081308  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226581 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.081216  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226469 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.081121  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226360 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.081028  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226255 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.080936  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226145 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.080842  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.226032 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.080750  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225926 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.080658  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225815 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.080565  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225710 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.080472  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225602 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.080382  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225484 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.080289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225384 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.080199  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225270 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.080105  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225169 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.080017  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225060 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.079925  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224950 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.079835  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224845 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.079743  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224736 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.079653  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224630 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.079563  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224519 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.079473  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224415 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.079382  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224307 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.079292  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224205 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.079204  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.224094 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.079115  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.223990 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.079026  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.223889 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.078936  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.223772 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.078845  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223676 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.078759  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223561 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.078669  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223465 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.078581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223359 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.078493  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223252 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.078403  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223146 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.078317  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.223043 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.078228  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222926 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.078139  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222831 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.078052  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222722 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.077964  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222625 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.077876  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222517 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.077788  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222410 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.077701  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222311 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.077615  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222196 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.077526  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.222101 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.077441  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221994 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.077353  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221891 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.077266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221787 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.077181  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221686 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.077095  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221580 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.077008  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221478 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.076924  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221378 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.076838  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221268 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.076751  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221179 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.076667  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.221063 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.076580  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.220963 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.076496  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220862 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.076411  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220759 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.076327  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220658 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.076242  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220551 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.076158  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220459 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.076075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220352 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.075991  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220252 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.075906  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220147 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.075824  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.220051 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.075740  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219943 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.075657  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219850 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.075573  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219742 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.075489  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219646 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.075409  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219543 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.075327  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219444 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.075245  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219341 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.075163  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219247 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.075083  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219144 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.074997  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.219042 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.074918  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218948 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.074835  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218849 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.074754  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218739 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.074672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218647 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.074592  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218551 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.074511  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218448 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.074431  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218350 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.074350  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218255 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.074269  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218150 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.074188  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.218058 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.074108  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217953 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.074026  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217854 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.073946  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217759 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.073866  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217660 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.073788  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217565 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.073707  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217465 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.073627  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217368 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.073547  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217269 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.073469  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217170 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.073391  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.217077 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.073311  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216976 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.073232  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216873 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.073153  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216780 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.073075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216680 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.072996  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216582 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.072918  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216487 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.072840  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216386 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.072761  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216295 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.072683  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216194 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.072604  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216092 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.072527  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.216000 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.072448  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215901 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.072371  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215805 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.072294  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215711 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.072218  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215611 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.072140  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215516 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.072067  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215421 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.071992  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215333 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.071917  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215232 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.071842  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215137 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.071768  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.215038 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.071691  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214947 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.071617  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214855 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.071543  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214753 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.071469  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214670 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.071394  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214573 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.071319  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214481 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.071245  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.214391 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.071172  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.214294 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.071097  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.214202 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.071022  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.214109 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.070949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.214013 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.070874  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213928 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.070800  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213831 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.070729  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213747 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.070658  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213656 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.070585  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213556 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.070511  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213471 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.070439  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213373 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.070367  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213290 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.070294  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213190 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.070223  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213099 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.070149  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.213009 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.070075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212917 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.070003  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212828 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.069931  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212738 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.069859  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212644 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.069786  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212550 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.069712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212462 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.069642  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212371 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.069570  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212278 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.069497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212189 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.069426  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212098 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.069355  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.212008 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.069285  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211915 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.069215  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211827 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.069144  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211735 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.069073  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211646 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.069002  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211559 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.068932  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211462 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.068862  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211381 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.068794  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211281 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.068722  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211196 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.068653  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211106 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.068582  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.211010 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.068512  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210928 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.068442  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210836 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.068372  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210749 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.068305  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210662 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.068234  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210566 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.068165  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210484 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.068098  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210393 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.068029  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210310 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.067961  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210212 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.067892  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210132 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.067824  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.210039 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.067754  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209947 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.067685  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209865 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.067617  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209769 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.067550  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209689 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.067481  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209598 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.067414  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209504 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.067344  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209419 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.067278  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209329 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.067209  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209242 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.067142  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209154 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.067075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.209064 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.067006  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208978 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.066941  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208886 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.066872  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208799 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.066805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208716 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.066738  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208628 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.066671  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208540 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.066604  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208446 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.066536  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208360 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.066469  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208275 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.066402  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208190 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.066337  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208101 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.066271  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.208014 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.066204  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207924 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.066138  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207840 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.066069  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207753 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.066001  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207666 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.065938  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207585 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.065869  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207491 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.065803  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207410 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.065737  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207321 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.065672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207232 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.065605  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207148 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.065539  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.207062 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.065474  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206978 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.065407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206890 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.065341  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206806 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.065280  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206717 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.065211  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206636 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.065147  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206553 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.065082  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.206466 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.065016  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.206381 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.064951  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.206293 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.064886  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.206208 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.064823  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.206126 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.064757  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.206041 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.064694  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205952 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.064628  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205867 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.064564  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205783 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.064500  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205701 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.064435  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205615 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.064372  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205531 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.064308  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205445 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.064245  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205362 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.064179  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205282 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.064117  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205196 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.064055  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205114 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.063990  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.205034 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.063929  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204948 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.063865  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204860 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.063802  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204777 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.063740  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204693 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.063676  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204613 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.063614  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204527 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.063551  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204446 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.063488  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204362 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.063427  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204276 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.063364  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204200 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.063301  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204113 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.063241  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.204042 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.063180  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203958 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.063117  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203876 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.063057  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203796 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.062996  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203713 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.062934  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203631 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.062875  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203556 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.062813  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203473 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.062752  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203390 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.062693  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203308 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.062631  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203230 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.062570  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203154 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.062510  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.203066 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.062449  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202984 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.062389  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202915 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.062329  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202820 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.062268  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202744 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.062207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202663 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.062149  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202579 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.062088  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202507 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.062030  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202425 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.061969  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202335 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.061909  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202264 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.061851  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202183 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.061792  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202099 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.061733  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.202026 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.061674  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201936 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.061615  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201863 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.061557  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201778 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.061497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201699 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.061439  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201625 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.061381  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201541 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.061322  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201464 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.061266  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201385 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.061207  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201299 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.061150  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201237 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.061092  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201152 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.061033  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.201070 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.060974  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200996 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.060919  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200917 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.060862  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200839 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.060805  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200763 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.060748  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200682 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.060691  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200605 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.060634  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200533 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.060578  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200447 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.060520  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200373 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.060465  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200290 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.060407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200220 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.060352  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200134 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.060293  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.200064 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.060237  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199985 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.060180  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199908 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.060122  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199827 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.060067  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199755 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.060011  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199670 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.059952  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199589 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.059897  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199521 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.059839  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199437 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.059784  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199364 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.059729  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199288 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.059672  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199206 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.059617  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199131 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.059563  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.199051 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.059504  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198980 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.059449  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198903 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.059393  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198827 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.059340  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198744 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.059280  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198679 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.059229  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198596 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.059174  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198518 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.059117  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198443 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.059063  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198370 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.059009  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198291 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.058954  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198218 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.058900  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198145 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.058849  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.198065 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.058792  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197994 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.058740  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197918 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.058684  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197850 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.058632  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197772 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.058578  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197692 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.058526  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197623 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.058470  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197545 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.058417  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197473 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.058362  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197400 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.058310  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197324 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.058255  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197245 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.058200  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197180 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.058148  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197105 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.058094  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.197029 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.058040  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196955 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.057985  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196887 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.057933  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196809 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.057879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196740 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.057826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196667 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.057774  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196584 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.057718  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196519 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.057666  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196449 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.057616  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196376 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.057562  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196301 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.057509  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196228 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.057457  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196158 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.057406  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196089 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.057352  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.196015 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.057301  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195947 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.057248  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195873 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.057197  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195801 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.057146  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195730 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.057093  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195659 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.057043  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195584 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.056990  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195516 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.056942  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195439 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.056887  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195376 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.056839  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195296 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.056784  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195227 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.056736  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195150 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.056681  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195084 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.056633  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.195009 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.056581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194943 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.056531  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194870 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.056478  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194797 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.056429  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194725 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.056376  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194655 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.056329  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194581 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.056275  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194515 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.056227  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194438 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.056174  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194375 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.056127  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194302 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.056074  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194233 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.056027  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194158 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.055976  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194092 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.055927  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.194019 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.055879  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193950 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.055826  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193871 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.055778  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193809 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.055728  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193732 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.055678  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193672 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.055630  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193597 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.055581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193524 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.055533  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193455 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.055485  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193381 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.055433  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193314 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.055387  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193248 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.055337  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193175 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.055289  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193103 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.055241  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.193037 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.055192  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192968 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.055144  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192894 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.055095  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192830 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.055048  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192758 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.054997  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192677 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.054948  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192622 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.054902  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192544 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.054853  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192479 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.054804  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192414 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.054759  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192345 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.054707  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192281 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.054660  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192202 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.054612  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192141 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.054562  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192073 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.054517  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.192001 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.054467  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191933 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.054420  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191863 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.054375  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191791 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.054326  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191726 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.054278  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191658 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.054228  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191590 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.054186  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191526 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.054135  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191452 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.054090  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191385 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.054041  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191316 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.053997  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191250 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.053947  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191181 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.053905  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191114 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.053854  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.191046 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.053808  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.190977 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.053761  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.190914 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.053714  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.190846 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.053666  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.190781 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.053621  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.190711 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.053573  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190644 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.053529  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190577 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.053479  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190514 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.053436  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190448 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.053389  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190376 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.053344  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190311 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.053297  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190245 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.053253  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190181 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.053205  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190113 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.053162  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.190045 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.053114  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189984 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.053070  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189918 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.053025  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189854 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.052982  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189785 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.052936  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189721 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.052892  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189653 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.052846  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189587 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.052799  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189517 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.052757  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189461 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.052712  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189390 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.052668  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189316 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.052622  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189258 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.052581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189189 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.052533  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189132 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.052492  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.189058 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.052446  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188986 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.052404  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188931 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.052359  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188864 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.052312  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188793 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.052272  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188736 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.052226  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188671 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.052186  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188599 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.052140  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188544 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.052098  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188474 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.052052  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188409 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.052008  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188350 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.051968  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188283 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.051921  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188216 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.051881  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188151 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.051835  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188090 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.051797  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.188034 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.051751  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187960 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.051706  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187898 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.051666  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187836 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.051622  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187772 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.051581  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187702 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.051535  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187642 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.051497  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187585 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.051451  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187512 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.051407  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187450 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.051369  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187387 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.051326  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187324 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.051284  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187260 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.051240  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187201 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.051199  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187135 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.051158  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187071 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.051114  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.187016 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.051075  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186951 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.051030  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186879 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.050989  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186822 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.050949  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186761 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.050905  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186708 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.050866  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186637 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.050823  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186573 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.050780  [    0/  736]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.186513 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"benchmark/benchmark_data/1/train/ALL_train.csv\"\n",
    "validationset = pd.read_csv(val_path, delimiter=';')\n",
    "\n",
    "\n",
    "X_val = pd.concat([validationset[str(i)]\n",
    "                    for i in range(561)], axis=1)\n",
    "y_val = validationset['Y'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prediction = model(torch.Tensor(np.array(X_val.iloc[0])))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-6.1536,  0.2845, -4.8252,  7.5691, -1.3468,  4.5076],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cloudy-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"activityModel.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "increased-hostel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"activityModel.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "serious-response",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=561, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "atomic-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[-7.7226e-01, -7.5472e-01, -5.0456e+00,  5.5949e+00, -4.8194e-01,\n",
      "          1.9495e+00],\n",
      "        [-2.8752e+00, -2.6679e+00, -9.7879e+00,  8.6095e+00,  4.3282e+00,\n",
      "          2.9610e+00],\n",
      "        [-9.7386e-02, -7.0337e+00, -1.1441e+01,  1.0476e+01,  5.4010e+00,\n",
      "          3.0299e+00],\n",
      "        [-3.6360e+00, -6.9433e+00, -1.0246e+01,  1.0330e+01, -3.6380e+00,\n",
      "          1.4218e+01],\n",
      "        [-3.8141e+00,  3.4646e+00,  2.5424e+00, -6.6425e-02, -9.1583e+00,\n",
      "          7.2272e+00],\n",
      "        [ 7.0553e+00,  2.5782e+00,  1.4860e+00, -3.3337e+00, -1.5739e+00,\n",
      "         -5.6127e+00],\n",
      "        [ 7.2672e+00,  2.3639e+00,  1.2107e+00, -2.9552e+00, -1.4642e+00,\n",
      "         -5.8217e+00],\n",
      "        [ 8.1900e+00,  8.0431e-01,  2.0128e+00, -3.0263e+00, -2.1141e+00,\n",
      "         -5.3248e+00],\n",
      "        [ 7.5076e+00,  1.9323e+00,  1.3534e+00, -3.0191e+00, -1.7952e+00,\n",
      "         -5.4569e+00],\n",
      "        [ 8.3230e+00,  1.7555e+00, -1.2138e-01, -3.2671e+00,  4.7529e-01,\n",
      "         -6.7294e+00],\n",
      "        [ 7.2685e+00,  1.4491e+00,  4.2960e-01, -2.0661e+00, -1.0111e+00,\n",
      "         -5.5709e+00],\n",
      "        [ 3.7469e+00,  3.6252e+00,  7.5316e+00, -5.3192e+00, -3.5860e+00,\n",
      "         -5.3103e+00],\n",
      "        [ 1.6524e+00,  4.2692e+00,  8.1803e+00, -4.6766e+00, -4.2159e+00,\n",
      "         -4.4719e+00],\n",
      "        [ 1.5327e+00,  5.7249e+00, -2.0630e+00, -7.2515e-01, -1.5400e-02,\n",
      "         -3.7359e+00],\n",
      "        [ 1.3297e+00,  5.6523e+00, -1.4615e+00, -9.1241e-01,  9.7112e-02,\n",
      "         -3.9185e+00],\n",
      "        [ 1.3286e+00,  5.3173e+00,  1.6943e-01, -9.7084e-01, -1.7411e+00,\n",
      "         -3.4091e+00],\n",
      "        [ 1.0482e-01, -3.6799e+00, -9.0554e+00,  5.6953e+00,  8.0856e+00,\n",
      "         -5.4434e-01],\n",
      "        [-2.2219e+00, -4.2110e-01, -9.9933e+00,  5.4053e+00,  9.6151e+00,\n",
      "         -1.6274e+00],\n",
      "        [ 1.0056e+00, -5.8381e+00, -1.1074e+01,  7.2191e+00,  9.6577e+00,\n",
      "         -4.5889e-01],\n",
      "        [-1.5373e+00, -5.2858e+00, -1.1481e+01,  9.7263e+00,  5.1587e+00,\n",
      "          3.7930e+00],\n",
      "        [-3.1222e-01, -7.3537e+00, -1.1287e+01,  9.9527e+00,  4.1228e+00,\n",
      "          5.1480e+00],\n",
      "        [-3.9490e+00, -6.1642e+00, -9.1834e+00,  9.4858e+00, -2.2584e+00,\n",
      "          1.2210e+01],\n",
      "        [-3.7825e+00, -6.8031e+00, -9.5752e+00,  9.7607e+00, -2.6738e+00,\n",
      "          1.3116e+01],\n",
      "        [ 3.4411e-01, -6.7869e+00, -1.1519e+01,  9.3580e+00,  6.5713e+00,\n",
      "          2.4503e+00],\n",
      "        [-7.4862e+00, -1.0658e+00, -8.4987e+00,  7.2054e+00, -8.0010e-01,\n",
      "          1.1028e+01],\n",
      "        [ 7.9735e+00,  1.0249e+00,  9.6140e-01, -3.0038e+00, -5.2354e-01,\n",
      "         -5.9468e+00],\n",
      "        [ 9.1446e+00,  2.4630e-02,  5.6735e-01, -2.9563e+00, -2.4976e-01,\n",
      "         -6.0873e+00],\n",
      "        [ 7.6403e+00,  1.5086e+00,  2.5231e+00, -3.5518e+00, -2.1100e+00,\n",
      "         -5.4545e+00],\n",
      "        [ 7.6540e-01,  4.6722e+00,  5.5175e+00, -3.0144e+00, -4.3766e+00,\n",
      "         -2.7562e+00],\n",
      "        [ 1.1912e+00,  7.2420e+00, -1.0871e+00, -1.6219e+00, -8.7718e-01,\n",
      "         -4.1362e+00],\n",
      "        [ 2.0934e+00,  5.7563e+00,  5.8997e-01, -1.8280e+00, -1.8348e+00,\n",
      "         -4.0227e+00],\n",
      "        [ 1.4041e+00,  6.4716e+00,  7.8678e-01, -2.1515e+00, -1.5170e+00,\n",
      "         -4.1861e+00],\n",
      "        [ 2.8592e+00,  4.6970e+00,  6.3265e+00, -5.2511e+00, -2.8770e+00,\n",
      "         -5.0253e+00],\n",
      "        [ 1.6340e+00, -6.9573e-01, -4.0316e+00,  2.1480e+00,  5.4377e+00,\n",
      "         -3.9481e+00],\n",
      "        [-2.6156e+00, -1.1438e-01, -7.6271e+00,  4.7961e+00,  7.2696e+00,\n",
      "         -1.0138e+00],\n",
      "        [ 8.7771e-01, -4.5347e+00, -1.0103e+01,  6.4731e+00,  9.6037e+00,\n",
      "         -1.7341e+00],\n",
      "        [ 9.7600e-01, -6.2382e+00, -1.1424e+01,  7.6660e+00,  9.5873e+00,\n",
      "         -6.8162e-02],\n",
      "        [ 1.0018e+00, -4.2197e+00, -1.0466e+01,  6.4645e+00,  9.2480e+00,\n",
      "         -1.3814e+00],\n",
      "        [-4.1159e-01, -5.3992e+00, -1.0795e+01,  9.3422e+00,  7.4275e+00,\n",
      "          3.2940e-01],\n",
      "        [-2.1531e+00, -2.6712e+00, -9.2489e+00,  8.5714e+00,  5.7289e+00,\n",
      "          3.2664e-01],\n",
      "        [-5.7445e-03, -5.5180e+00, -1.0369e+01,  8.5557e+00,  8.1204e+00,\n",
      "         -2.8793e-01],\n",
      "        [ 4.3569e-01, -5.8702e+00, -1.0392e+01,  9.0576e+00,  6.9044e+00,\n",
      "          3.0397e-01],\n",
      "        [-4.0192e+00, -5.2073e+00, -8.8665e+00,  8.1038e+00, -2.6976e+00,\n",
      "          1.2813e+01],\n",
      "        [-4.0666e+00, -6.8918e+00, -8.9860e+00,  9.3737e+00, -3.8436e+00,\n",
      "          1.4425e+01],\n",
      "        [-3.0048e+00, -7.6759e+00, -9.6058e+00,  9.7100e+00, -3.2415e+00,\n",
      "          1.3846e+01],\n",
      "        [ 7.7623e+00,  1.6595e-02, -5.4235e-01, -1.5906e+00, -2.5651e-01,\n",
      "         -4.8724e+00],\n",
      "        [ 8.4067e+00, -4.3684e-01, -6.4271e-01, -1.5896e+00,  2.7219e-01,\n",
      "         -5.5075e+00],\n",
      "        [ 7.0560e+00,  1.4377e+00,  2.9378e+00, -3.7575e+00, -1.1172e+00,\n",
      "         -5.9627e+00],\n",
      "        [ 7.2307e+00,  5.2713e-01,  1.8011e+00, -2.6503e+00, -9.0319e-01,\n",
      "         -5.4944e+00],\n",
      "        [ 3.2067e+00,  3.1405e+00,  6.6210e+00, -4.1603e+00, -3.7310e+00,\n",
      "         -4.3403e+00],\n",
      "        [ 2.2969e+00,  4.0533e+00,  6.5036e+00, -4.2263e+00, -3.2014e+00,\n",
      "         -4.6762e+00],\n",
      "        [ 3.7914e+00,  3.0897e+00,  6.5336e+00, -4.9507e+00, -2.7013e+00,\n",
      "         -5.1190e+00],\n",
      "        [ 1.4260e+00,  5.3357e+00,  9.0718e-01, -2.0404e+00, -1.3390e+00,\n",
      "         -3.4506e+00],\n",
      "        [-1.4623e-01,  6.5930e+00,  2.6612e+00, -2.9658e+00, -1.8506e+00,\n",
      "         -3.3586e+00],\n",
      "        [ 1.5490e+00,  6.7685e+00,  3.0789e+00, -3.4696e+00, -2.5245e+00,\n",
      "         -4.4778e+00],\n",
      "        [ 3.2542e+00, -4.0345e+00, -1.0143e+01,  5.7371e+00,  8.5260e+00,\n",
      "         -2.7709e+00],\n",
      "        [ 8.1368e-01, -3.8780e+00, -9.5929e+00,  5.5848e+00,  9.1248e+00,\n",
      "         -1.4641e+00],\n",
      "        [-2.2860e-01, -6.1072e+00, -1.0829e+01,  9.5910e+00,  5.9717e+00,\n",
      "          2.0379e+00],\n",
      "        [-1.5448e-01, -5.5010e+00, -1.1133e+01,  8.7752e+00,  7.9425e+00,\n",
      "          5.8659e-01],\n",
      "        [-4.8119e+00, -4.7068e+00, -9.0012e+00,  9.3200e+00, -3.1012e+00,\n",
      "          1.2489e+01],\n",
      "        [-4.4934e+00, -3.0562e+00, -5.9892e+00,  6.5823e+00, -4.0915e+00,\n",
      "          1.1290e+01],\n",
      "        [-3.3968e+00, -6.7203e+00, -1.0058e+01,  9.7389e+00, -2.9111e+00,\n",
      "          1.3450e+01],\n",
      "        [ 5.9743e+00,  2.2618e+00,  1.5518e+00, -3.4150e+00,  2.1504e-01,\n",
      "         -5.9700e+00],\n",
      "        [ 7.8209e+00,  3.0704e-01,  2.4470e+00, -3.5953e+00, -6.5031e-01,\n",
      "         -5.8325e+00]])\n",
      "Predicted class: tensor([3, 3, 3, 5, 5, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 4, 4, 4, 3, 3, 5, 5, 3,\n",
      "        5, 0, 0, 0, 2, 1, 1, 1, 2, 4, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 0, 0, 0,\n",
      "        0, 2, 2, 2, 1, 1, 1, 4, 4, 3, 3, 5, 5, 5, 0, 0])\n",
      "match: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "Probabilities: tensor([[  8.3772,  -0.1949,   0.3029,  -2.2236,  -0.3661,  -5.4004],\n",
      "        [  3.4453,   2.2680,   5.3052,  -3.2358,  -2.9051,  -4.1234],\n",
      "        [  2.2919,   3.7395,   5.4701,  -4.0868,  -1.9441,  -4.7466],\n",
      "        [  2.5957,   3.9200,   7.9352,  -5.3051,  -3.0458,  -5.4577],\n",
      "        [  0.5331,   6.1483,   2.4237,  -2.9427,  -1.7399,  -3.5425],\n",
      "        [ -0.3832,   7.1786,   0.8208,  -2.5583,  -0.1720,  -3.9350],\n",
      "        [  1.5476,   3.9303,   0.0687,  -0.3004,  -2.5865,  -1.9242],\n",
      "        [  1.1158,  -4.9301,  -9.9991,   7.6786,   7.8388,  -1.2152],\n",
      "        [  1.3616,  -5.3792, -10.2803,   7.8106,   8.3908,  -1.3572],\n",
      "        [ -2.5563,   2.4468,  -4.9178,   3.0621,   4.0270,  -1.2517],\n",
      "        [  1.8006,  -6.7969, -10.1626,   6.9384,   9.6556,  -0.9690],\n",
      "        [  0.6594,  -5.7595, -10.5574,   9.0985,   6.2135,   0.7155],\n",
      "        [ -3.9094,  -6.8837,  -8.6804,   9.3306,  -5.3295,  15.3600],\n",
      "        [ -2.4085,  -8.0360,  -9.3552,   8.7162,  -3.5666,  14.4821],\n",
      "        [ -3.2847,  -6.9273,  -9.4660,   8.7081,  -2.7133,  13.5952],\n",
      "        [  6.5205,  -0.1259,  -1.3938,  -0.1247,  -0.2235,  -4.1267],\n",
      "        [  6.4339,   1.1432,   1.3995,  -2.2037,  -1.5694,  -4.5908],\n",
      "        [  2.5279,   2.7826,   9.5239,  -5.2681,  -4.6405,  -4.2828],\n",
      "        [  1.3806,   4.0646,   8.8701,  -5.1978,  -3.3038,  -5.1046],\n",
      "        [  1.3911,   6.3144,   1.1641,  -2.2850,  -1.6593,  -4.1362],\n",
      "        [  1.5274,   6.9018,   1.7894,  -2.7608,  -1.9446,  -4.6383],\n",
      "        [  2.9159,   5.3750,   2.2293,  -3.0067,  -2.1119,  -4.6071],\n",
      "        [  2.7276,  -4.5279,  -5.8331,   4.8654,   5.5178,  -2.2738],\n",
      "        [ -0.2268,  -4.2840, -10.6439,   7.9417,   7.4604,   0.3212],\n",
      "        [  0.3222,  -5.0962, -10.3157,   7.5736,   9.1895,  -1.0906],\n",
      "        [ -0.4896,  -3.3855,  -8.5203,   7.2172,   5.8586,  -0.1229],\n",
      "        [ -2.6084,   0.2019,  -8.4055,   7.0426,   4.0671,   0.3674],\n",
      "        [  1.4028,  -6.6545, -11.2851,   9.5719,   5.8431,   1.5082],\n",
      "        [ -3.4260,  -6.6944,  -9.3393,   9.1790,  -4.0579,  14.3233],\n",
      "        [ -3.3045,  -7.1063,  -9.0147,   8.8259,  -3.5061,  14.0306],\n",
      "        [  7.4842,   0.7604,   3.1338,  -3.4825,  -1.8980,  -5.4494],\n",
      "        [  7.0216,   1.4362,   2.7830,  -3.3277,  -1.9815,  -5.3232],\n",
      "        [  6.5726,   0.8419,   3.1367,  -3.0466,  -1.7112,  -5.2441],\n",
      "        [  1.6517,   3.7502,  11.5545,  -6.4193,  -4.7935,  -5.1019],\n",
      "        [  2.4259,   3.0404,  10.2856,  -6.0965,  -4.4200,  -4.7262],\n",
      "        [  1.5690,   4.1536,   9.7478,  -5.5483,  -4.4304,  -4.7749],\n",
      "        [  2.0118,   6.2855,   3.5850,  -3.6996,  -2.5772,  -4.7639],\n",
      "        [  3.9765,   4.2562,   3.6419,  -4.1754,  -1.6089,  -5.4365],\n",
      "        [  1.7953,   6.6533,   3.7750,  -3.9739,  -2.7019,  -4.6103],\n",
      "        [  0.6817,  -5.4226, -10.4895,   8.1985,   8.4756,  -0.9283],\n",
      "        [  2.7001,  -3.1118,  -8.1520,   4.5800,   7.8775,  -3.2714],\n",
      "        [  1.2059,  -4.9745, -10.3283,   7.4575,   8.8186,  -1.6349],\n",
      "        [  2.8188,  -6.2022,  -9.2304,   6.5718,   4.5816,   1.8197],\n",
      "        [  1.4611,  -4.9850,  -9.4904,   7.6256,   6.3196,  -0.4418],\n",
      "        [ -2.9908,  -6.4279,  -7.5780,   8.0939,  -5.4287,  14.3426],\n",
      "        [ -2.0156,  -6.9987,  -8.8106,   8.1336,  -3.5036,  13.1493],\n",
      "        [ -3.2701,  -6.8230,  -9.1297,   8.1952,  -2.1404,  13.1239],\n",
      "        [  5.1912,   2.3601,   2.3497,  -2.6859,  -0.9799,  -5.5349],\n",
      "        [  6.7414,   1.8710,   2.8483,  -3.9408,  -0.9556,  -6.0322],\n",
      "        [  1.4832,   3.4277,   9.7310,  -5.1666,  -4.4665,  -4.2513],\n",
      "        [  0.4560,   4.9639,   9.7717,  -5.8751,  -3.8299,  -4.7319],\n",
      "        [  0.5734,   5.0138,   9.7492,  -6.1404,  -3.6750,  -4.8050],\n",
      "        [  1.1143,   4.9341,   9.8894,  -6.7493,  -2.9350,  -5.5935],\n",
      "        [  1.7363,   6.1176,   3.6749,  -4.1082,  -1.7749,  -4.7600],\n",
      "        [  3.2867,   4.7546,   2.3545,  -3.4145,  -1.3751,  -4.8330],\n",
      "        [  1.7798,  -4.9766, -11.8081,   7.1696,   9.7383,  -1.3851],\n",
      "        [  0.1457,  -5.1093, -10.6796,   7.9036,   7.2073,   1.0445],\n",
      "        [  1.4367,  -4.6019,  -9.2890,   6.5483,   7.0251,  -0.6217],\n",
      "        [ -4.4429,  -6.2827,  -8.0326,   9.0287,  -6.1796,  15.8831],\n",
      "        [  7.7778,   0.7890,   3.5217,  -4.3073,  -1.2528,  -6.0428],\n",
      "        [  7.8525,   0.5140,   2.5605,  -3.0176,  -2.2884,  -5.0276],\n",
      "        [  8.2144,   0.1627,   2.3488,  -3.0456,  -1.9650,  -5.1328],\n",
      "        [  4.1035,   0.6573,   7.8484,  -5.1286,  -2.5526,  -4.7177],\n",
      "        [  3.0608,   2.1622,   9.5524,  -5.7544,  -3.9039,  -4.7101]])\n",
      "Predicted class: tensor([0, 2, 2, 2, 1, 1, 1, 4, 4, 4, 4, 3, 5, 5, 5, 0, 0, 2, 2, 1, 1, 1, 4, 3,\n",
      "        4, 3, 3, 3, 5, 5, 0, 0, 0, 2, 2, 2, 1, 1, 1, 4, 4, 4, 3, 3, 5, 5, 5, 0,\n",
      "        0, 2, 2, 2, 2, 1, 1, 4, 3, 4, 5, 0, 0, 0, 2, 2])\n",
      "match: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[  3.9595,   4.7437,   4.8273,  -5.0006,  -2.5393,  -5.3049],\n",
      "        [  3.0654,   5.3071,   5.0396,  -5.0676,  -2.2259,  -5.4730],\n",
      "        [ -1.2151,  -3.5900, -10.9681,   7.7384,   8.4100,   0.1721],\n",
      "        [  0.1596,  -2.7289,  -9.9121,   5.4193,  10.2251,  -2.5355],\n",
      "        [  1.4222,  -4.4355, -10.2858,   6.5473,   8.2184,  -0.9398],\n",
      "        [  0.8414,  -3.8705,  -9.3662,   6.1672,   7.4388,  -0.6837],\n",
      "        [ -1.4744,  -3.6570, -10.0213,   7.9438,   7.7122,   0.1192],\n",
      "        [  0.9342,  -6.9818, -11.1332,   8.6977,   7.8820,   1.0219],\n",
      "        [  2.2628,  -5.6646,  -8.9358,   7.0107,   6.9779,  -1.1788],\n",
      "        [  1.4332,  -7.0688, -11.4205,   8.8391,   7.0858,   1.5195],\n",
      "        [ -5.1745,  -5.7174,  -8.4466,   8.9213,  -4.3989,  14.8642],\n",
      "        [ -5.6785,  -3.6693,  -6.9028,   7.6400,  -5.0023,  13.7792],\n",
      "        [  6.3567,   0.4330,  -1.2890,  -1.2140,   0.4600,  -4.2349],\n",
      "        [  8.4531,   0.3539,   1.6054,  -3.2901,  -0.9012,  -5.7422],\n",
      "        [  8.9590,  -0.1151,   2.1969,  -3.3433,  -1.5108,  -5.7072],\n",
      "        [  8.4585,  -0.2913,   1.2870,  -2.8674,  -0.4335,  -5.7071],\n",
      "        [  7.3070,   1.6680,   1.1455,  -3.4471,  -0.5444,  -5.6234],\n",
      "        [  7.9657,   0.3074,   2.1796,  -3.9349,  -0.4484,  -5.6971],\n",
      "        [  2.8334,   3.8386,   8.4472,  -5.6303,  -3.2942,  -5.5606],\n",
      "        [ -0.1314,   5.0373,   1.2339,  -1.0621,  -2.0689,  -2.1719],\n",
      "        [  1.7588,   4.2009,   1.3178,  -1.9742,  -2.0041,  -2.5568],\n",
      "        [  3.2733,  -4.5849,  -8.9810,   5.3599,   8.2842,  -2.7337],\n",
      "        [ -0.7843,  -3.7265, -10.9510,   6.9383,  10.4221,  -1.2910],\n",
      "        [ -0.0188,  -4.5111,  -9.3809,   7.1463,   7.4782,  -0.1720],\n",
      "        [ -1.3859,   1.3074,  -5.8532,   4.7167,   3.6745,  -1.8041],\n",
      "        [ -2.5617,  -3.2317,  -9.3096,   8.7423,   5.9446,   1.0052],\n",
      "        [ -6.3478,  -3.5767,  -8.0390,   8.5718,  -5.3270,  14.9268],\n",
      "        [ -5.8297,  -4.6197,  -8.3361,   8.9683,  -5.4538,  15.3476],\n",
      "        [ -5.3058,  -5.7194,  -7.8638,   9.2005,  -6.3535,  16.0134],\n",
      "        [ -5.8614,  -5.3902,  -8.4791,   9.5116,  -5.8184,  16.0173],\n",
      "        [  6.3720,   1.1595,   2.5133,  -2.5791,  -1.4581,  -5.4015],\n",
      "        [  7.9023,   1.3434,   2.0197,  -3.7676,  -0.6588,  -6.3321],\n",
      "        [  9.3173,  -1.1265,   2.9524,  -3.8585,  -0.5204,  -6.3646],\n",
      "        [  1.8932,   3.6098,   9.8241,  -5.2989,  -3.7841,  -5.4819],\n",
      "        [  1.8284,   3.3248,  11.2343,  -6.5725,  -3.7979,  -5.4690],\n",
      "        [  0.5466,   4.2487,  10.0333,  -5.1922,  -4.5608,  -4.2720],\n",
      "        [  2.1097,   3.7643,   9.6378,  -5.9006,  -4.1329,  -4.9233],\n",
      "        [  0.3065,   5.8391,   2.0403,  -2.0315,  -1.7043,  -3.5839],\n",
      "        [  1.2652,   5.6908,   0.7080,  -2.5801,   0.5536,  -4.7818],\n",
      "        [  1.3081,   5.4122,   4.9217,  -4.3623,  -1.2611,  -5.2615],\n",
      "        [ -0.7650,  -4.3977, -11.2400,   8.2238,   9.9431,  -1.1580],\n",
      "        [  0.5800,  -5.3890, -11.1960,   7.5796,   9.6009,  -0.6531],\n",
      "        [ -6.1413,   1.0960,  -5.1121,   7.0045,   0.0665,   3.7354],\n",
      "        [ -1.3668,  -4.2768, -11.0801,   9.1534,   5.6399,   2.4174],\n",
      "        [ -0.0467,  -6.3878, -10.5203,   9.4071,   5.3261,   2.6571],\n",
      "        [ -4.0299,  -6.4749, -10.1479,   9.6771,  -2.7002,  13.7442],\n",
      "        [ -3.9259,  -6.3500,  -9.3368,   8.8925,  -3.3468,  14.1388],\n",
      "        [  7.8442,   2.2153,   0.8944,  -3.5387,  -0.8036,  -6.0424],\n",
      "        [  7.4742,   1.6746,   1.6775,  -3.7033,  -1.2656,  -5.2900],\n",
      "        [  5.0555,   1.1327,   6.7467,  -4.9708,  -2.6476,  -5.0499],\n",
      "        [  3.3689,   6.5889,  -0.4493,  -2.4484,  -1.3797,  -4.8154],\n",
      "        [  3.8361,   6.7541,   0.1688,  -3.2698,  -1.4672,  -5.2546],\n",
      "        [  3.0358,   6.8407,   1.1462,  -3.3505,  -1.9174,  -5.0116],\n",
      "        [  0.6187,  -6.4104, -11.4001,   8.0658,   9.2591,   0.3098],\n",
      "        [  0.0687,  -6.1510, -10.9140,   8.5072,   8.4845,   0.4602],\n",
      "        [  0.6464,  -3.7552,  -9.7528,   6.2034,   8.5624,  -1.2847],\n",
      "        [ -4.6118,  -2.6862, -10.3736,   9.4905,   4.5572,   4.1580],\n",
      "        [ -0.4291,  -3.4820,  -8.0134,   7.8508,   4.1042,   0.4244],\n",
      "        [ -2.4859,  -4.9569,  -6.8802,   6.7631,  -5.4258,  12.9984],\n",
      "        [ -6.5552,  -3.3206,  -7.9786,   8.4317,  -5.1357,  14.7661],\n",
      "        [ -6.0179,  -4.8901,  -8.2575,   8.8677,  -5.4935,  15.8581],\n",
      "        [ -6.1442,  -4.4713,  -7.5515,   8.2897,  -5.4268,  15.4146],\n",
      "        [  5.6151,   4.4167,   1.4001,  -3.6188,  -2.1931,  -4.9569],\n",
      "        [  6.3643,   3.4865,   1.4203,  -3.5135,  -2.4854,  -4.6472]])\n",
      "Predicted class: tensor([2, 1, 4, 4, 4, 4, 3, 3, 3, 3, 5, 5, 0, 0, 0, 0, 0, 0, 2, 1, 1, 4, 4, 4,\n",
      "        3, 3, 5, 5, 5, 5, 0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 4, 4, 3, 3, 3, 5, 5, 0,\n",
      "        0, 2, 1, 1, 1, 4, 3, 4, 3, 3, 5, 5, 5, 5, 0, 0])\n",
      "match: tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[ 5.8540e+00,  3.6635e+00,  2.2727e+00, -3.7709e+00, -2.5247e+00,\n",
      "         -4.8630e+00],\n",
      "        [ 4.0839e+00,  3.6843e+00,  6.2921e+00, -4.8082e+00, -3.7343e+00,\n",
      "         -4.8514e+00],\n",
      "        [ 4.0115e+00,  3.4634e+00,  7.1608e+00, -5.7171e+00, -2.9281e+00,\n",
      "         -5.5398e+00],\n",
      "        [ 2.2300e+00,  7.6073e+00,  1.3969e+00, -3.4905e+00, -2.2701e+00,\n",
      "         -4.6173e+00],\n",
      "        [ 2.8639e+00,  6.9281e+00,  6.1412e-01, -2.7968e+00, -2.6001e+00,\n",
      "         -4.1878e+00],\n",
      "        [ 5.1748e-01, -5.1046e+00, -1.0125e+01,  6.9081e+00,  1.0136e+01,\n",
      "         -1.7379e+00],\n",
      "        [-4.9606e+00, -1.2577e+00, -6.6737e+00,  7.5576e+00,  2.1534e+00,\n",
      "          3.7704e+00],\n",
      "        [ 4.5233e-01, -7.6779e+00, -1.1796e+01,  9.4128e+00,  6.0425e+00,\n",
      "          3.8612e+00],\n",
      "        [-4.7974e-01, -5.9380e+00, -1.0691e+01,  8.9116e+00,  6.0664e+00,\n",
      "          2.5378e+00],\n",
      "        [-2.8376e+00, -6.8680e+00, -9.4191e+00,  9.0282e+00, -1.9655e+00,\n",
      "          1.2087e+01],\n",
      "        [-5.1955e+00, -3.5650e+00, -7.0582e+00,  7.6829e+00, -4.3169e+00,\n",
      "          1.2705e+01],\n",
      "        [-3.1743e+00, -6.9813e+00, -9.8258e+00,  8.7387e+00, -8.3517e-01,\n",
      "          1.2079e+01],\n",
      "        [-4.2302e+00, -6.5443e+00, -8.7470e+00,  8.8564e+00, -2.6414e+00,\n",
      "          1.3339e+01],\n",
      "        [ 5.0959e+00,  1.5553e+00, -3.7511e-01, -1.3774e+00,  4.2556e-02,\n",
      "         -4.3505e+00],\n",
      "        [ 5.3356e+00,  1.5409e+00, -6.9264e-01, -8.3028e-01,  2.6697e-01,\n",
      "         -4.9815e+00],\n",
      "        [ 6.2426e+00, -1.3726e-02, -1.8525e+00, -1.8287e-01,  5.2069e-01,\n",
      "         -4.1828e+00],\n",
      "        [ 4.7017e+00,  1.5715e+00, -1.4306e+00, -5.4672e-01,  8.1783e-01,\n",
      "         -4.4613e+00],\n",
      "        [ 3.7964e-01,  5.4185e+00,  8.5092e+00, -5.3973e+00, -4.1878e+00,\n",
      "         -3.9000e+00],\n",
      "        [-5.7926e-01,  6.2472e+00,  7.9433e-01, -9.9890e-01, -2.0084e+00,\n",
      "         -2.6867e+00],\n",
      "        [ 8.7227e-01,  4.0739e+00, -6.1813e-01,  3.5730e-01, -2.2811e+00,\n",
      "         -1.7419e+00],\n",
      "        [ 5.3320e-02,  5.4738e+00,  1.0892e+00, -1.2482e+00, -1.5462e+00,\n",
      "         -3.0737e+00],\n",
      "        [-1.3653e-02,  5.9123e+00,  2.2437e+00, -2.2340e+00, -1.7672e+00,\n",
      "         -3.2951e+00],\n",
      "        [ 1.2063e+00, -5.7112e+00, -1.1602e+01,  6.7547e+00,  1.0329e+01,\n",
      "         -4.9242e-01],\n",
      "        [ 2.5521e+00, -7.7278e+00, -1.0590e+01,  7.8695e+00,  8.5685e+00,\n",
      "         -2.3689e-01],\n",
      "        [ 2.1010e+00, -6.6576e+00, -1.0544e+01,  7.3022e+00,  9.5030e+00,\n",
      "         -1.2295e+00],\n",
      "        [-4.3476e+00, -1.8497e+00, -8.0688e+00,  8.2414e+00,  2.8639e+00,\n",
      "          3.7753e+00],\n",
      "        [ 8.7906e-01, -7.1489e+00, -8.9530e+00,  8.5077e+00,  4.0353e+00,\n",
      "          3.0344e+00],\n",
      "        [-1.7765e+00, -6.2793e+00, -7.8808e+00,  7.2364e+00, -3.7092e+00,\n",
      "          1.2344e+01],\n",
      "        [ 6.4176e+00,  1.0670e+00, -2.3112e-01, -1.4727e+00, -8.0450e-01,\n",
      "         -4.3846e+00],\n",
      "        [ 6.1241e+00,  1.8008e+00,  8.3888e-01, -2.3312e+00, -4.1733e-01,\n",
      "         -5.3477e+00],\n",
      "        [ 2.0199e+00,  5.0817e+00,  7.3670e+00, -5.6267e+00, -2.2567e+00,\n",
      "         -5.8188e+00],\n",
      "        [ 9.8441e-02,  5.7752e+00,  9.7022e+00, -5.9883e+00, -3.9287e+00,\n",
      "         -4.8319e+00],\n",
      "        [ 4.7524e-01,  6.0532e+00,  7.8780e+00, -5.4042e+00, -3.5546e+00,\n",
      "         -4.5837e+00],\n",
      "        [-4.0092e-01,  6.7925e+00,  1.7588e+00, -2.4002e+00, -7.4479e-01,\n",
      "         -4.1264e+00],\n",
      "        [-1.0978e+00,  5.4337e+00,  1.4165e+00, -4.8972e-01, -2.7456e+00,\n",
      "         -1.7891e+00],\n",
      "        [ 4.0588e+00, -3.4130e+00, -8.6416e+00,  4.3315e+00,  6.9546e+00,\n",
      "         -2.8425e+00],\n",
      "        [-1.4421e+00, -3.7244e+00, -1.1535e+01,  8.0705e+00,  9.4238e+00,\n",
      "         -1.8312e-01],\n",
      "        [-4.1097e-01, -4.0101e+00, -1.1145e+01,  7.1236e+00,  9.4081e+00,\n",
      "         -3.7152e-01],\n",
      "        [ 3.8183e-01, -5.1212e+00, -9.5826e+00,  7.9748e+00,  6.3192e+00,\n",
      "          4.9071e-01],\n",
      "        [ 2.2416e-01, -5.5226e+00, -1.0237e+01,  8.2603e+00,  7.2603e+00,\n",
      "          4.8403e-01],\n",
      "        [-4.5964e-02, -5.2866e+00, -1.0086e+01,  8.5998e+00,  6.3977e+00,\n",
      "          8.9477e-01],\n",
      "        [-4.9351e+00, -5.0950e+00, -8.0412e+00,  8.5123e+00, -3.2686e+00,\n",
      "          1.2996e+01],\n",
      "        [-3.6178e+00, -5.7480e+00, -8.6808e+00,  8.2944e+00, -2.3952e+00,\n",
      "          1.2294e+01],\n",
      "        [ 5.1150e+00,  2.4986e+00, -2.0634e+00, -1.0251e+00, -3.3488e-01,\n",
      "         -3.6095e+00],\n",
      "        [ 5.0199e+00,  3.0571e+00, -2.0025e+00, -1.0410e+00, -8.5154e-01,\n",
      "         -3.5375e+00],\n",
      "        [ 1.8508e+00,  5.4017e+00,  5.8404e+00, -4.4700e+00, -3.1704e+00,\n",
      "         -4.6379e+00],\n",
      "        [ 1.9757e+00,  5.1124e+00,  7.3464e+00, -5.8585e+00, -2.3924e+00,\n",
      "         -5.6223e+00],\n",
      "        [ 7.8510e-01,  5.4501e+00,  8.3799e+00, -5.7309e+00, -3.1780e+00,\n",
      "         -5.1025e+00],\n",
      "        [ 8.9594e-02,  8.5310e+00,  9.1375e-01, -2.0227e+00, -3.5341e+00,\n",
      "         -3.0239e+00],\n",
      "        [ 1.3387e+00,  8.1884e+00, -1.4801e+00, -1.4211e+00, -2.8606e+00,\n",
      "         -2.8955e+00],\n",
      "        [ 7.2527e-01, -5.0366e+00, -1.0853e+01,  6.5455e+00,  9.7238e+00,\n",
      "         -5.9637e-01],\n",
      "        [-5.2109e-03, -1.6117e+00, -9.0570e+00,  4.3787e+00,  8.5242e+00,\n",
      "         -1.6272e+00],\n",
      "        [ 1.1461e+00, -1.5464e+00, -7.3270e+00,  3.2826e+00,  7.1252e+00,\n",
      "         -2.0630e+00],\n",
      "        [ 3.6692e-01, -3.0544e+00, -9.9141e+00,  4.6883e+00,  1.0586e+01,\n",
      "         -2.0846e+00],\n",
      "        [ 3.5220e-01, -5.9609e+00, -1.0559e+01,  8.4728e+00,  7.3383e+00,\n",
      "          8.3664e-01],\n",
      "        [-1.7698e+00,  9.1140e-01, -7.6567e+00,  5.3574e+00,  4.1056e+00,\n",
      "         -2.2420e-01],\n",
      "        [-5.6272e+00, -3.7006e+00, -8.7205e+00,  8.5888e+00, -2.5962e+00,\n",
      "          1.2361e+01],\n",
      "        [-5.9809e+00, -3.8842e+00, -8.7623e+00,  8.7496e+00, -2.9785e+00,\n",
      "          1.3111e+01],\n",
      "        [-4.9627e+00, -3.2917e+00, -6.5135e+00,  7.8276e+00, -3.0303e+00,\n",
      "          1.0272e+01],\n",
      "        [-3.0329e+00, -4.3051e+00, -7.1812e+00,  6.8294e+00, -2.5719e+00,\n",
      "          1.0416e+01],\n",
      "        [ 5.1707e+00,  3.9331e+00, -1.1534e-01, -2.5093e+00, -1.5034e+00,\n",
      "         -4.3683e+00],\n",
      "        [ 5.1827e+00,  3.0017e+00, -7.9163e-01, -1.4431e+00, -1.9864e+00,\n",
      "         -3.3533e+00],\n",
      "        [ 4.7494e+00,  3.8409e+00,  7.4774e-01, -2.7443e+00, -2.0863e+00,\n",
      "         -3.8407e+00],\n",
      "        [ 1.3588e+00,  5.4251e+00,  7.2787e+00, -5.3989e+00, -3.0730e+00,\n",
      "         -4.9613e+00]])\n",
      "Predicted class: tensor([0, 2, 2, 1, 1, 4, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 0, 2, 1, 1, 1, 1, 4, 4,\n",
      "        4, 3, 3, 5, 0, 0, 2, 2, 2, 1, 1, 4, 4, 4, 3, 3, 3, 5, 5, 0, 0, 2, 2, 2,\n",
      "        1, 1, 4, 4, 4, 4, 3, 3, 5, 5, 5, 5, 0, 0, 0, 2])\n",
      "match: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "Probabilities: tensor([[ 1.5450e+00,  5.0936e+00,  8.2591e+00, -5.8183e+00, -3.5396e+00,\n",
      "         -4.9431e+00],\n",
      "        [ 1.3881e+00,  7.9420e+00, -6.1338e-01, -1.7460e+00, -2.7868e+00,\n",
      "         -3.4084e+00],\n",
      "        [ 8.5925e-01,  8.2771e+00, -3.8051e-01, -2.0730e+00, -3.0046e+00,\n",
      "         -2.8577e+00],\n",
      "        [ 9.0457e-01, -5.2742e+00, -1.0507e+01,  7.1281e+00,  9.2098e+00,\n",
      "         -9.5275e-01],\n",
      "        [ 1.3077e+00, -4.0036e+00, -1.0199e+01,  5.5659e+00,  1.0884e+01,\n",
      "         -2.9294e+00],\n",
      "        [ 6.7811e-01, -6.4307e+00, -1.1335e+01,  8.6027e+00,  9.9126e+00,\n",
      "         -9.2315e-01],\n",
      "        [-6.2307e-01, -6.6353e+00, -1.1467e+01,  9.8591e+00,  5.1290e+00,\n",
      "          4.0581e+00],\n",
      "        [-1.3084e+00, -6.3354e+00, -1.0515e+01,  9.8509e+00,  4.3101e+00,\n",
      "          4.3604e+00],\n",
      "        [-4.0076e-02, -4.7195e+00, -9.4215e+00,  7.8489e+00,  7.4712e+00,\n",
      "         -5.9166e-01],\n",
      "        [-2.3556e-01, -5.7179e+00, -1.0337e+01,  9.1278e+00,  6.2292e+00,\n",
      "          1.3587e+00],\n",
      "        [-3.7562e+00, -6.3092e+00, -9.3209e+00,  8.7300e+00, -2.2424e+00,\n",
      "          1.2987e+01],\n",
      "        [-3.6303e+00, -6.8698e+00, -9.6782e+00,  9.4913e+00, -2.7792e+00,\n",
      "          1.3505e+01],\n",
      "        [-5.3110e+00, -3.3743e+00, -6.4987e+00,  7.6178e+00, -4.1709e+00,\n",
      "          1.1991e+01],\n",
      "        [-3.4506e+00, -6.7789e+00, -9.1213e+00,  9.5465e+00, -3.0683e+00,\n",
      "          1.2888e+01],\n",
      "        [ 8.1289e+00,  7.1759e-01, -3.4653e-01, -2.2860e+00,  3.6750e-01,\n",
      "         -6.0072e+00],\n",
      "        [ 5.9783e+00,  2.3617e+00,  3.3780e-01, -2.7873e+00,  3.5790e-01,\n",
      "         -5.5754e+00],\n",
      "        [ 6.2354e+00,  1.9054e+00, -2.7415e-02, -2.3017e+00,  1.7243e-01,\n",
      "         -5.3501e+00],\n",
      "        [-3.0660e-02,  4.6889e+00,  1.0370e+01, -5.2798e+00, -5.0377e+00,\n",
      "         -3.9222e+00],\n",
      "        [-1.0570e+00,  7.1717e+00,  4.1043e+00, -3.0988e+00, -1.6391e+00,\n",
      "         -4.4723e+00],\n",
      "        [-5.8416e-01,  6.7727e+00,  3.8923e+00, -3.6055e+00, -1.3829e+00,\n",
      "         -4.1655e+00],\n",
      "        [ 5.9790e-01, -3.3061e+00, -1.0095e+01,  5.8026e+00,  1.0516e+01,\n",
      "         -2.9025e+00],\n",
      "        [ 1.5475e+00, -6.2260e+00, -1.0546e+01,  7.3737e+00,  8.7265e+00,\n",
      "         -3.8971e-01],\n",
      "        [-1.0565e-02, -6.2243e+00, -1.1086e+01,  8.9971e+00,  5.2492e+00,\n",
      "          3.4776e+00],\n",
      "        [ 3.4637e-01, -6.5566e+00, -1.1391e+01,  8.6737e+00,  6.4722e+00,\n",
      "          2.8096e+00],\n",
      "        [ 5.7543e-01, -5.9170e+00, -1.1158e+01,  8.8181e+00,  7.0675e+00,\n",
      "          1.0234e+00],\n",
      "        [ 5.3599e-01, -7.1995e+00, -1.1845e+01,  1.0096e+01,  5.9794e+00,\n",
      "          2.8448e+00],\n",
      "        [-4.0247e+00, -6.0801e+00, -9.4864e+00,  9.5117e+00, -1.7637e+00,\n",
      "          1.2016e+01],\n",
      "        [-3.9477e+00, -3.1897e+00, -7.3572e+00,  6.7961e+00, -1.4502e+00,\n",
      "          9.3978e+00],\n",
      "        [ 5.2462e+00,  2.4460e+00,  3.1499e+00, -3.2282e+00, -1.9930e+00,\n",
      "         -5.0209e+00],\n",
      "        [ 5.1344e+00,  3.0126e+00,  2.1707e+00, -3.2934e+00, -9.0116e-01,\n",
      "         -5.4904e+00],\n",
      "        [ 6.0866e+00,  1.5375e+00,  1.7944e+00, -2.4850e+00, -6.7532e-01,\n",
      "         -5.6823e+00],\n",
      "        [ 4.1365e-01,  4.3206e+00,  1.0208e+01, -5.4889e+00, -4.6162e+00,\n",
      "         -4.1002e+00],\n",
      "        [ 1.2117e+00,  3.7192e+00,  1.1196e+01, -6.1857e+00, -4.7970e+00,\n",
      "         -4.5099e+00],\n",
      "        [ 3.2918e-01,  7.3228e+00,  4.6071e+00, -4.4211e+00, -1.8731e+00,\n",
      "         -5.1477e+00],\n",
      "        [ 1.2298e+00,  6.7806e+00,  3.1050e+00, -3.4537e+00, -2.7589e+00,\n",
      "         -4.1228e+00],\n",
      "        [ 1.5235e+00,  6.1960e+00,  3.1145e+00, -3.3652e+00, -1.9818e+00,\n",
      "         -4.7214e+00],\n",
      "        [ 1.2420e+00, -6.3613e+00, -1.1531e+01,  7.4951e+00,  1.0166e+01,\n",
      "         -5.7723e-01],\n",
      "        [ 1.1003e+00, -6.5479e+00, -1.1210e+01,  7.8076e+00,  9.0590e+00,\n",
      "          2.4872e-01],\n",
      "        [-1.8578e-01, -4.8172e+00, -1.1623e+01,  7.8225e+00,  9.0048e+00,\n",
      "          3.1638e-01],\n",
      "        [-4.1311e-01, -5.4538e+00, -1.1665e+01,  8.4064e+00,  8.9772e+00,\n",
      "          6.6554e-01],\n",
      "        [-4.1780e+00,  2.5537e-01, -7.0763e+00,  6.8276e+00,  4.8950e+00,\n",
      "          1.7346e-02],\n",
      "        [-1.7800e-02, -6.2263e+00, -1.1633e+01,  8.8000e+00,  7.7225e+00,\n",
      "          1.7194e+00],\n",
      "        [ 6.6462e-01, -6.2241e+00, -1.1323e+01,  8.3280e+00,  8.4949e+00,\n",
      "          4.8454e-01],\n",
      "        [-4.9153e+00, -4.3935e+00, -9.5169e+00,  8.4830e+00, -1.3263e+00,\n",
      "          1.1909e+01],\n",
      "        [-4.4641e+00, -4.7157e+00, -1.0395e+01,  9.0399e+00, -1.5395e+00,\n",
      "          1.2282e+01],\n",
      "        [-3.9990e+00, -5.2534e+00, -1.0017e+01,  8.3561e+00, -5.1003e-01,\n",
      "          1.1557e+01],\n",
      "        [ 6.2964e+00,  1.2479e+00,  3.2603e-01, -2.0565e+00, -4.0229e-01,\n",
      "         -4.7852e+00],\n",
      "        [ 4.4142e+00,  1.3186e+00, -3.2364e+00,  1.2395e-01,  1.8134e+00,\n",
      "         -3.7868e+00],\n",
      "        [ 6.9548e+00,  3.1981e-01, -4.4761e-02, -1.6982e+00, -6.4561e-01,\n",
      "         -4.3022e+00],\n",
      "        [ 6.6489e-01,  5.7521e+00,  8.5548e+00, -5.4943e+00, -3.7943e+00,\n",
      "         -4.7891e+00],\n",
      "        [ 2.1492e+00,  3.0228e+00,  9.1656e+00, -5.5232e+00, -4.2581e+00,\n",
      "         -3.8767e+00],\n",
      "        [ 8.1622e-01,  5.0918e+00, -2.7275e-02, -7.9012e-01, -1.5410e+00,\n",
      "         -2.6787e+00],\n",
      "        [-1.9493e-01,  6.4294e+00,  1.1509e-01, -2.1782e+00,  2.4062e-01,\n",
      "         -3.5156e+00],\n",
      "        [ 1.3504e+00,  4.8989e+00, -3.2720e-01, -1.4007e+00, -9.1114e-01,\n",
      "         -2.7888e+00],\n",
      "        [ 6.0501e-02, -5.1389e+00, -1.1058e+01,  8.1320e+00,  7.4512e+00,\n",
      "          1.0631e+00],\n",
      "        [ 6.4264e-01, -5.9635e+00, -1.1312e+01,  8.4968e+00,  7.4876e+00,\n",
      "          1.1128e+00],\n",
      "        [-5.1262e+00,  7.6743e-02, -8.6136e+00,  7.5920e+00,  4.1366e+00,\n",
      "          2.7495e+00],\n",
      "        [-1.1969e+00, -1.9143e+00, -6.9723e+00,  5.5801e+00,  6.8856e+00,\n",
      "         -1.7439e+00],\n",
      "        [ 1.4267e-02, -6.3585e+00, -1.0529e+01,  8.6325e+00,  6.8438e+00,\n",
      "          1.8286e+00],\n",
      "        [ 2.7815e-01, -4.4792e+00, -1.0243e+01,  7.4009e+00,  7.2805e+00,\n",
      "          2.4995e-01],\n",
      "        [-5.2964e+00, -4.5827e+00, -8.1775e+00,  8.5114e+00, -1.7929e+00,\n",
      "          1.1509e+01],\n",
      "        [-4.8294e+00, -4.8504e+00, -8.8834e+00,  8.8593e+00, -1.7451e+00,\n",
      "          1.1597e+01],\n",
      "        [-5.0420e+00, -3.7371e+00, -6.7255e+00,  7.2537e+00, -1.9489e+00,\n",
      "          1.0428e+01],\n",
      "        [-4.0143e+00, -5.2434e+00, -8.8215e+00,  7.9708e+00, -4.3067e-01,\n",
      "          1.0697e+01]])\n",
      "Predicted class: tensor([2, 1, 1, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 2, 1, 1, 4, 4, 3, 3,\n",
      "        3, 3, 5, 5, 0, 0, 0, 2, 2, 1, 1, 1, 4, 4, 4, 4, 3, 3, 4, 5, 5, 5, 0, 0,\n",
      "        0, 2, 2, 1, 1, 1, 3, 3, 3, 4, 3, 3, 5, 5, 5, 5])\n",
      "match: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False, False, False,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[  4.1205,   1.9316,   0.7011,  -0.9830,  -2.2335,  -2.9426],\n",
      "        [  5.8612,   0.9360,   0.1746,  -1.1829,  -1.3219,  -3.8966],\n",
      "        [  4.7873,   0.7451,   0.5002,  -0.5223,  -1.6153,  -3.3117],\n",
      "        [ -0.1807,   4.6532,   9.8755,  -4.7800,  -5.8416,  -2.9058],\n",
      "        [  1.0479,   4.1795,  10.3165,  -5.7350,  -5.1595,  -3.9556],\n",
      "        [  1.4969,   3.1599,   0.8868,  -0.2223,  -3.8954,  -0.7276],\n",
      "        [  0.6221,   5.0159,   0.4189,  -0.5662,  -2.5072,  -2.1557],\n",
      "        [  1.4981,   4.0230,   1.6141,  -0.5472,  -3.9003,  -1.9447],\n",
      "        [  0.7452,   4.1541,   2.6411,  -0.5884,  -5.1563,  -1.0130],\n",
      "        [ -0.6761,  -3.4975, -10.7679,   6.8503,   9.5601,  -0.8437],\n",
      "        [ -0.0414,  -5.0243, -11.5778,   7.6162,   9.8664,  -0.2763],\n",
      "        [  0.8609,  -5.9576, -11.5231,   7.8023,   9.1773,   0.1764],\n",
      "        [ -1.7656,  -4.4134, -11.7100,   9.2093,   7.6450,   1.5364],\n",
      "        [  0.0216,  -6.8290, -11.4255,   9.7326,   6.1028,   2.7669],\n",
      "        [ -2.0517,  -2.6372, -10.2596,   7.6942,   6.4804,   1.3340],\n",
      "        [  0.0644,  -6.5136, -10.8577,   8.4701,   7.2147,   2.0317],\n",
      "        [ -4.7620,  -5.9336,  -8.7112,   9.2244,  -3.1470,  13.4525],\n",
      "        [ -4.0202,  -3.9807,  -7.4907,   7.1181,  -4.1072,  12.6377],\n",
      "        [ -4.2700,  -5.8164, -10.2123,   9.3301,  -1.7796,  12.8323],\n",
      "        [ -4.0647,  -5.9779, -10.4147,   9.2291,  -0.8662,  12.2125],\n",
      "        [  8.5519,  -0.1510,  -1.0872,  -1.7240,   0.0286,  -5.1738],\n",
      "        [  8.3206,   0.2217,  -0.5248,  -1.5293,  -1.4674,  -4.4980],\n",
      "        [  8.9301,  -0.2136,  -1.4271,  -1.7067,   0.1498,  -5.2649],\n",
      "        [  1.0720,   4.6405,   7.4024,  -4.5104,  -3.9678,  -3.8375],\n",
      "        [ -0.7162,   7.2742,   3.7957,  -2.8936,  -3.4541,  -3.0464],\n",
      "        [ -0.4196,   5.5868,   8.5934,  -4.9455,  -4.0309,  -3.9284],\n",
      "        [ -1.2703,   7.9079,   6.3550,  -4.4100,  -3.5002,  -4.0978],\n",
      "        [  0.4072,   7.1596,   4.9313,  -4.2643,  -2.6744,  -4.6415],\n",
      "        [  0.8828,  -2.9453, -11.2047,   5.5835,  11.9522,  -3.6166],\n",
      "        [ -3.1398,  -1.1476, -10.5564,   6.9800,   8.9575,  -0.3151],\n",
      "        [  1.2425,  -4.7283, -10.1788,   6.1426,   9.5433,  -1.4471],\n",
      "        [ -0.6696,  -4.5807, -10.6161,   8.8140,   7.4940,   0.0750],\n",
      "        [ -0.7670,  -4.8414, -11.1768,   8.3100,   8.9150,   0.1469],\n",
      "        [ -0.4486,  -5.3700, -12.3315,   9.0994,   9.2958,   0.2813],\n",
      "        [ -3.2309,  -7.1659,  -9.8365,   9.5431,  -3.1861,  13.9326],\n",
      "        [ -4.6818,  -4.4719,  -7.2701,   7.7000,  -3.0318,  11.9677],\n",
      "        [ -4.7504,  -5.4278, -10.5890,   9.9065,  -2.7831,  13.7660],\n",
      "        [  5.3846,   3.2834,   0.1103,  -2.2330,  -1.2752,  -4.5810],\n",
      "        [  6.3102,   2.3868,   0.5669,  -2.7633,  -0.6410,  -5.2218],\n",
      "        [  7.6657,   1.1450,  -0.1690,  -1.9268,  -1.0426,  -5.0958],\n",
      "        [  5.8669,   2.8967,   0.9011,  -3.1977,  -0.3928,  -5.4273],\n",
      "        [ -1.9978,   7.5532,   1.5523,  -1.1531,  -3.0407,  -1.8882],\n",
      "        [ -1.1067,   7.4341,   4.3705,  -2.9724,  -4.0350,  -2.6853],\n",
      "        [ -0.9319,   6.4163,   9.9971,  -5.8622,  -4.4041,  -4.3684],\n",
      "        [  1.7307,  -4.9293,  -9.2848,   6.1865,   9.7625,  -2.8399],\n",
      "        [  1.1123,  -5.8428, -10.4477,   7.8694,   9.1801,  -1.3503],\n",
      "        [  0.3318,  -4.8708, -10.3197,   7.2700,   9.3761,  -1.2460],\n",
      "        [  0.2274,  -5.3779, -11.6717,   7.9547,   9.9728,  -0.6096],\n",
      "        [  1.2612,  -6.0290, -12.1222,   7.8383,   9.8076,  -0.3053],\n",
      "        [ -3.0152,  -4.8447,  -9.2923,   8.9047,   0.1112,   8.4381],\n",
      "        [ -2.9504,  -6.1737,  -9.9120,  10.5917,  -0.0330,   8.6687],\n",
      "        [ -4.3506,  -0.9962,  -6.7687,   7.7454,   1.5936,   3.3220],\n",
      "        [ -2.3081,  -5.2103, -10.9224,   9.9872,   4.3867,   4.3902],\n",
      "        [ -4.5216,  -5.1366,  -8.9393,   8.4688,  -3.5039,  13.7440],\n",
      "        [ -3.1783,  -7.0401,  -9.1009,   8.7352,  -4.0847,  14.6355],\n",
      "        [ -3.9488,  -6.9017,  -8.8646,   9.4445,  -4.3287,  14.5791],\n",
      "        [ -3.0228,  -7.2584,  -9.8091,   8.8091,  -2.8360,  13.9989],\n",
      "        [ -3.0184,  -7.1281,  -9.9222,   9.2993,  -3.5086,  14.3050],\n",
      "        [  7.8287,   1.2432,   3.2187,  -4.2580,  -1.8890,  -5.7117],\n",
      "        [  6.6263,   2.9478,   2.9577,  -4.4418,  -0.9229,  -6.6140],\n",
      "        [  6.5470,   1.6378,   5.0272,  -5.0192,  -1.7967,  -5.9385],\n",
      "        [  0.1109,   4.7749,  10.5722,  -6.3544,  -3.6695,  -4.7845],\n",
      "        [  0.7653,   7.5434,   2.7485,  -3.6208,  -2.5493,  -3.9784],\n",
      "        [  0.3980,  -4.5742, -10.0394,   7.1576,   9.3946,  -1.7598]])\n",
      "Predicted class: tensor([0, 0, 0, 2, 2, 1, 1, 1, 1, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 2,\n",
      "        1, 2, 1, 1, 4, 4, 4, 3, 4, 4, 5, 5, 5, 0, 0, 0, 0, 1, 1, 2, 4, 4, 4, 4,\n",
      "        4, 3, 3, 3, 3, 5, 5, 5, 5, 5, 0, 0, 0, 2, 1, 4])\n",
      "match: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False, False,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[  0.1399,  -5.0027, -10.8027,   7.1578,  10.4420,  -1.3353],\n",
      "        [  2.3621,  -7.0881, -10.5039,   7.5315,  10.0679,  -1.8568],\n",
      "        [  1.3820,  -2.8974,  -9.2138,   5.8842,   9.1471,  -3.7215],\n",
      "        [ -0.6968,  -2.2197,  -9.6044,   5.7354,   9.8500,  -2.3802],\n",
      "        [ -3.2467,  -5.7213,  -9.5690,   9.5960,  -0.4594,   9.6100],\n",
      "        [  0.2616,  -4.8107,  -8.3760,   7.5259,   4.9740,   0.9462],\n",
      "        [ -5.2545,  -4.3206,  -7.4389,   8.0609,  -5.8000,  14.7637],\n",
      "        [ -5.9258,  -4.3647,  -8.1856,   8.7194,  -6.2178,  15.9936],\n",
      "        [ -6.5796,  -4.0686,  -7.9333,   8.8300,  -6.7260,  16.4916],\n",
      "        [ -5.9870,  -4.6595,  -8.0688,   8.9576,  -7.1618,  16.8683],\n",
      "        [ -5.9362,  -4.9085,  -7.6856,   9.1118,  -7.6969,  17.0511],\n",
      "        [  7.0275,   1.4269,   4.3897,  -4.5169,  -2.1209,  -5.8095],\n",
      "        [  5.7550,   2.4959,   5.1426,  -4.9361,  -2.2216,  -5.8141],\n",
      "        [  1.3349,   1.6421,   8.7959,  -4.7954,  -3.0347,  -3.6046],\n",
      "        [  1.0823,   0.5517,   5.7418,  -2.8341,  -2.1353,  -2.1891],\n",
      "        [  4.5609,   4.8947,   1.2316,  -3.3729,  -2.3659,  -4.1452],\n",
      "        [  1.1490,   3.3107,   9.5654,  -5.4095,  -3.8665,  -4.1188],\n",
      "        [  3.1874,   5.9377,   1.7490,  -3.4275,  -3.1210,  -3.5119],\n",
      "        [  2.1000,  -3.4402,  -8.9285,   4.9808,   7.1588,  -1.3412],\n",
      "        [ -1.0992,  -4.0697, -11.1866,   7.8038,   8.8994,   0.2271],\n",
      "        [  1.1558,  -6.1765, -10.7363,   7.6158,   8.1375,   0.4499],\n",
      "        [  0.5728,  -4.4655, -10.9207,   7.2023,   8.8004,  -0.5861],\n",
      "        [  0.7372,  -4.7022, -11.2820,   6.6607,  10.0196,  -0.9151],\n",
      "        [  1.9358,  -7.4866, -11.1416,   8.3603,   7.4867,   1.1841],\n",
      "        [  0.3765,  -5.4243, -10.5423,   8.4266,   5.9915,   1.6130],\n",
      "        [  0.2688,  -5.2072,  -9.8330,   8.0965,   6.4165,   0.7211],\n",
      "        [  0.8998,  -6.3497, -10.9124,   8.8637,   6.0532,   1.8310],\n",
      "        [  1.8521,  -6.6732, -11.7294,   8.5571,   8.4289,  -0.0270],\n",
      "        [  1.1371,  -6.5933, -11.2652,   8.7829,   7.6381,   0.7105],\n",
      "        [ -5.3101,  -4.6402,  -9.8897,   9.4928,  -3.4618,  13.9748],\n",
      "        [ -5.9654,  -2.1833,  -6.7629,   7.8485,  -4.3256,  11.6467],\n",
      "        [ -5.3347,  -5.1550,  -9.3735,   9.8194,  -4.0471,  14.1949],\n",
      "        [ -4.6016,  -5.5980,  -9.0477,   8.9543,  -3.8088,  14.2065],\n",
      "        [  6.4772,   2.5544,   0.4985,  -2.5648,  -1.2741,  -5.0343],\n",
      "        [  8.0231,   1.1804,  -0.1725,  -2.2480,  -1.3517,  -4.9171],\n",
      "        [  2.2125,   4.2878,   8.8757,  -6.1245,  -3.1046,  -5.5375],\n",
      "        [ -1.0488,   6.8276,   8.1827,  -4.9443,  -4.1514,  -3.9304],\n",
      "        [  1.4324,   6.2358,  -0.0627,  -1.9357,  -1.3821,  -3.4358],\n",
      "        [  1.7087,   5.8626,   0.9089,  -2.2594,  -1.6421,  -3.6896],\n",
      "        [  1.4148,   5.9602,   0.5778,  -1.7589,  -2.1485,  -3.1603],\n",
      "        [  0.1021,  -2.9006,  -8.9960,   5.4673,   8.1504,  -1.2229],\n",
      "        [ -0.6679,  -0.9400, -10.3643,   6.0219,   7.7077,  -1.1032],\n",
      "        [  1.1209,  -3.7539, -10.6796,   5.7715,   9.9192,  -1.8171],\n",
      "        [  0.2510,  -3.6841, -10.6062,   6.4003,   9.8893,  -1.6124],\n",
      "        [  0.8445,  -7.3187, -10.2102,   8.9394,   5.5446,   2.5813],\n",
      "        [  0.5902,  -3.7278,  -9.4477,   6.8285,   6.3088,  -0.0282],\n",
      "        [  1.2965,  -5.6510, -10.3658,   7.6538,   7.6203,  -0.0691],\n",
      "        [ -1.3034,  -4.1234, -10.5826,   8.7920,   6.1141,   1.6167],\n",
      "        [ -3.5922,  -6.1501,  -9.1793,   8.8838,  -2.2752,  12.3935],\n",
      "        [ -3.9168,  -5.1147,  -8.2313,   8.3409,  -3.9011,  12.9697],\n",
      "        [ -0.2053,  -5.1994,  -6.0821,   5.7937,  -5.1326,  10.9642],\n",
      "        [ -6.0310,  -4.4873,  -8.8670,   9.3758,  -4.5959,  14.8074],\n",
      "        [ -5.7760,  -4.8372,  -8.7066,   9.1564,  -4.4390,  14.7855],\n",
      "        [  5.5849,   3.4873,   3.8868,  -4.5476,  -2.2592,  -5.5092],\n",
      "        [  7.5746,   1.9087,   1.3206,  -3.4067,  -1.1878,  -5.6677],\n",
      "        [  3.0916,   3.5205,   7.6597,  -5.6607,  -2.7913,  -5.2428],\n",
      "        [ -0.2964,   6.0762,   9.3738,  -6.0615,  -3.7076,  -4.5998],\n",
      "        [  1.9947,   6.0247,   0.7142,  -1.8310,  -3.0078,  -2.9410],\n",
      "        [  1.0675,   6.6997,   1.1125,  -2.2595,  -2.1152,  -3.5521],\n",
      "        [  0.1093,  -4.9767,  -9.5857,   7.6737,   8.6825,  -1.2838],\n",
      "        [  1.2410,  -4.6643, -10.3086,   6.5058,   9.7841,  -1.9740],\n",
      "        [ -2.5575,  -4.7336,  -9.8521,   9.0532,   3.4620,   5.0894],\n",
      "        [  0.0784,  -6.8828, -10.4315,   9.6278,   5.2108,   2.7431],\n",
      "        [ -6.3095,  -3.1620,  -8.0409,   8.5461,  -4.3810,  13.6070]])\n",
      "Predicted class: tensor([4, 4, 4, 4, 5, 3, 5, 5, 5, 5, 5, 0, 0, 2, 2, 1, 2, 1, 4, 4, 4, 4, 4, 3,\n",
      "        3, 3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 2, 2, 1, 1, 1, 4, 4, 4, 4, 3, 3, 3, 3,\n",
      "        5, 5, 5, 5, 5, 0, 0, 2, 2, 1, 1, 4, 4, 3, 3, 5])\n",
      "match: tensor([ True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[-3.8450e+00, -7.0856e+00, -9.2242e+00,  9.0769e+00, -2.9085e+00,\n",
      "          1.3969e+01],\n",
      "        [-3.3600e+00, -7.1306e+00, -9.8412e+00,  9.2306e+00, -2.0941e+00,\n",
      "          1.3185e+01],\n",
      "        [-3.0865e+00, -7.1180e+00, -9.7507e+00,  9.1474e+00, -2.4910e+00,\n",
      "          1.3284e+01],\n",
      "        [-3.1859e+00, -6.7670e+00, -9.2539e+00,  8.7983e+00, -3.1683e+00,\n",
      "          1.3556e+01],\n",
      "        [ 8.6236e+00, -2.7288e-01,  2.0391e+00, -3.5309e+00, -5.2898e-01,\n",
      "         -5.8989e+00],\n",
      "        [ 7.3357e+00,  1.2194e+00,  3.4853e+00, -3.7112e+00, -3.0887e+00,\n",
      "         -4.6445e+00],\n",
      "        [ 8.8732e-01,  4.5661e+00,  9.8441e+00, -6.0634e+00, -3.8379e+00,\n",
      "         -4.7478e+00],\n",
      "        [ 1.6853e+00,  6.9076e+00,  3.3715e+00, -4.3167e+00, -1.0585e+00,\n",
      "         -5.7673e+00],\n",
      "        [ 2.0156e+00,  6.2858e+00,  2.7314e+00, -3.2430e+00, -1.9894e+00,\n",
      "         -4.9505e+00],\n",
      "        [ 3.3714e+00, -2.7162e+00, -7.0343e+00,  3.0536e+00,  7.2900e+00,\n",
      "         -3.3792e+00],\n",
      "        [ 1.6302e+00, -6.0612e+00, -1.1620e+01,  7.1282e+00,  1.0535e+01,\n",
      "         -1.1269e+00],\n",
      "        [ 5.1846e-01, -4.4486e+00, -1.1602e+01,  7.0542e+00,  1.0297e+01,\n",
      "         -1.2651e+00],\n",
      "        [ 6.7637e-02, -7.0097e+00, -1.0297e+01,  9.2702e+00,  4.9287e+00,\n",
      "          3.3982e+00],\n",
      "        [-2.6384e-01, -3.0173e+00, -6.5270e+00,  6.3920e+00,  4.4810e+00,\n",
      "         -4.9415e-01],\n",
      "        [ 6.4933e-01, -4.2264e+00, -8.1613e+00,  6.6580e+00,  6.5248e+00,\n",
      "         -8.8643e-01],\n",
      "        [-5.9758e+00,  1.2571e+00, -2.3688e+00,  3.9580e+00, -7.5889e+00,\n",
      "          1.1083e+01],\n",
      "        [-3.6348e+00, -6.9549e+00, -9.6795e+00,  9.0648e+00, -2.7959e+00,\n",
      "          1.3959e+01],\n",
      "        [-3.6746e+00, -4.2307e-01, -2.7511e+00,  4.2019e+00, -8.5542e+00,\n",
      "          1.1392e+01],\n",
      "        [-3.6513e+00, -1.6229e+00, -2.2528e+00,  3.8017e+00, -7.0475e+00,\n",
      "          1.0891e+01],\n",
      "        [-3.2983e+00, -5.9532e+00, -7.6786e+00,  7.7626e+00, -3.9337e+00,\n",
      "          1.3103e+01],\n",
      "        [-3.6086e+00, -6.1744e+00, -7.1526e+00,  8.1223e+00, -4.1660e+00,\n",
      "          1.3029e+01],\n",
      "        [ 7.7443e+00,  1.7340e+00,  2.6022e+00, -4.1852e+00, -1.4471e+00,\n",
      "         -5.9340e+00],\n",
      "        [ 7.8833e+00,  1.4271e-01,  2.7203e+00, -3.2035e+00, -1.9408e+00,\n",
      "         -5.1251e+00],\n",
      "        [ 3.6025e-01,  5.7404e+00,  9.7886e+00, -6.1883e+00, -3.7998e+00,\n",
      "         -5.1328e+00],\n",
      "        [ 7.8981e-01,  4.9330e+00,  8.7950e+00, -5.3095e+00, -3.6830e+00,\n",
      "         -4.6976e+00],\n",
      "        [ 3.1770e+00,  5.2835e+00,  4.3307e+00, -4.0676e+00, -3.6931e+00,\n",
      "         -4.2196e+00],\n",
      "        [ 1.1939e+00,  6.8531e+00,  3.3005e+00, -3.5006e+00, -2.8888e+00,\n",
      "         -3.9964e+00],\n",
      "        [ 2.0620e+00, -3.1827e+00, -7.4581e+00,  5.3800e+00,  6.7104e+00,\n",
      "         -2.9343e+00],\n",
      "        [ 1.9684e+00, -6.6903e+00, -1.0421e+01,  7.4705e+00,  8.4761e+00,\n",
      "         -3.8746e-01],\n",
      "        [-9.7529e-01, -8.8512e-01, -8.2331e+00,  4.7804e+00,  6.9522e+00,\n",
      "         -1.0285e+00],\n",
      "        [ 1.3039e+00, -5.7748e+00, -1.1006e+01,  7.5152e+00,  8.6252e+00,\n",
      "         -2.1919e-01],\n",
      "        [ 6.6862e-01, -1.9118e+00, -8.4549e+00,  4.4547e+00,  8.7787e+00,\n",
      "         -2.8857e+00],\n",
      "        [-5.2569e-01, -7.0802e+00, -1.0517e+01,  9.6585e+00,  5.0088e+00,\n",
      "          3.7796e+00],\n",
      "        [ 1.3086e+00, -8.1224e+00, -1.1485e+01,  9.4662e+00,  5.7949e+00,\n",
      "          3.3384e+00],\n",
      "        [ 1.7557e+00, -6.9439e+00, -1.0470e+01,  7.8377e+00,  7.6070e+00,\n",
      "          5.9995e-01],\n",
      "        [-3.7396e+00, -5.9972e+00, -9.2274e+00,  8.5916e+00, -3.3284e+00,\n",
      "          1.3733e+01],\n",
      "        [-5.4673e+00, -5.2484e+00, -8.9851e+00,  9.5425e+00, -5.2642e+00,\n",
      "          1.5458e+01],\n",
      "        [-5.0298e+00, -5.4877e+00, -8.4486e+00,  8.9710e+00, -4.9679e+00,\n",
      "          1.5060e+01],\n",
      "        [-4.8139e+00, -5.7498e+00, -8.7313e+00,  9.1058e+00, -4.9338e+00,\n",
      "          1.5143e+01],\n",
      "        [ 9.7827e+00, -1.3792e+00,  1.9842e+00, -3.2076e+00, -1.2452e+00,\n",
      "         -5.4235e+00],\n",
      "        [ 9.0099e+00, -4.0635e-01,  2.4944e+00, -3.7223e+00, -1.5611e+00,\n",
      "         -5.3944e+00],\n",
      "        [ 8.5543e+00,  6.5296e-01,  2.0934e+00, -3.5705e+00, -1.4385e+00,\n",
      "         -5.9013e+00],\n",
      "        [ 9.8732e+00, -8.2337e-01,  1.6532e+00, -3.5742e+00, -9.6820e-01,\n",
      "         -5.7486e+00],\n",
      "        [ 4.1305e+00,  2.7826e+00,  6.6443e+00, -4.9132e+00, -2.7563e+00,\n",
      "         -5.3331e+00],\n",
      "        [ 4.2273e+00,  2.3827e+00,  8.0297e+00, -5.4908e+00, -3.4334e+00,\n",
      "         -5.2780e+00],\n",
      "        [ 2.1268e+00,  5.7821e+00,  5.1342e-01, -2.2943e+00, -1.2833e+00,\n",
      "         -4.0352e+00],\n",
      "        [ 2.9070e+00,  5.2109e+00, -2.5970e-01, -2.4021e+00, -8.6232e-02,\n",
      "         -4.6028e+00],\n",
      "        [ 4.3636e+00,  2.9938e+00,  5.3608e+00, -4.5785e+00, -2.1086e+00,\n",
      "         -5.5016e+00],\n",
      "        [ 2.4534e+00,  3.9583e+00,  6.6553e+00, -4.8329e+00, -2.8389e+00,\n",
      "         -4.8659e+00],\n",
      "        [ 1.8279e+00, -6.4746e+00, -1.1258e+01,  7.2833e+00,  9.5316e+00,\n",
      "         -4.7174e-01],\n",
      "        [ 1.2681e+00, -5.3131e+00, -1.0559e+01,  6.9736e+00,  9.0474e+00,\n",
      "         -8.8295e-01],\n",
      "        [-1.3209e-01, -3.0963e+00, -1.0888e+01,  6.1315e+00,  9.6428e+00,\n",
      "         -1.0580e+00],\n",
      "        [-8.2335e-01, -5.8192e+00, -1.0394e+01,  9.0812e+00,  5.9872e+00,\n",
      "          2.3460e+00],\n",
      "        [ 1.2155e-03, -4.9399e+00, -8.6304e+00,  7.1575e+00,  5.2702e+00,\n",
      "          1.5297e+00],\n",
      "        [-1.3639e+00, -1.8003e+00, -1.0362e+01,  7.7597e+00,  7.0614e+00,\n",
      "         -6.8375e-01],\n",
      "        [-4.6663e+00, -6.2372e+00, -8.6276e+00,  9.4872e+00, -5.5524e+00,\n",
      "          1.5604e+01],\n",
      "        [-5.2898e+00, -5.1808e+00, -8.5579e+00,  8.7399e+00, -4.9295e+00,\n",
      "          1.5275e+01],\n",
      "        [-6.1372e+00, -4.3938e+00, -8.3432e+00,  9.0548e+00, -5.6871e+00,\n",
      "          1.5544e+01],\n",
      "        [-4.1589e+00, -6.5695e+00, -8.9050e+00,  9.8038e+00, -5.0573e+00,\n",
      "          1.4884e+01],\n",
      "        [ 9.8014e+00, -1.0760e+00,  5.1053e-01, -2.5635e+00, -1.0061e+00,\n",
      "         -5.1999e+00],\n",
      "        [ 9.3262e+00, -7.2149e-01,  1.6705e+00, -3.0432e+00, -1.0126e+00,\n",
      "         -5.7551e+00],\n",
      "        [ 9.3649e+00,  3.7173e-01,  5.7014e-01, -3.4128e+00, -2.1792e-01,\n",
      "         -6.2095e+00],\n",
      "        [ 9.8331e+00, -1.2082e+00,  1.8442e+00, -3.6269e+00, -4.2513e-01,\n",
      "         -6.0676e+00],\n",
      "        [ 3.2361e+00,  2.8546e+00,  7.7529e+00, -4.9360e+00, -3.2072e+00,\n",
      "         -5.1862e+00]])\n",
      "Predicted class: tensor([5, 5, 5, 5, 0, 0, 2, 1, 1, 4, 4, 4, 3, 3, 3, 5, 5, 5, 5, 5, 5, 0, 0, 2,\n",
      "        2, 1, 1, 4, 4, 4, 4, 4, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 0, 2, 2, 1, 1, 2,\n",
      "        2, 4, 4, 4, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 0, 2])\n",
      "match: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "Probabilities: tensor([[  3.2630,   2.5373,   6.8883,  -4.6782,  -2.6481,  -4.9665],\n",
      "        [  1.8253,   6.5999,  -0.1790,  -2.3481,  -0.7681,  -4.3001],\n",
      "        [  1.2019,   6.8206,   2.9046,  -3.3772,  -2.7884,  -3.8824],\n",
      "        [  4.4402,  -7.2215,  -8.5275,   5.0664,   7.7145,  -1.1049],\n",
      "        [  1.3254,  -6.1662, -10.8637,   7.2268,   9.5496,  -0.5769],\n",
      "        [  0.8427,  -5.3309,  -8.4913,   6.4251,   6.0898,   0.8914],\n",
      "        [ -0.7854,  -5.4839, -10.9211,   8.6505,   6.9902,   2.0110],\n",
      "        [ -0.5428,  -7.0622, -10.0298,   9.6993,   1.7565,   6.3417],\n",
      "        [ -3.7922,  -1.0362,  -7.3248,   7.7965,   2.4326,   2.4918],\n",
      "        [ -0.2658,  -6.5064, -10.8397,   9.7266,   4.9651,   3.2716],\n",
      "        [ -7.8018,   2.9471,  -3.1700,   4.1214,  -5.9485,  10.3530],\n",
      "        [ -2.8484,  -5.8552,  -6.8009,   7.3799,  -3.7834,  11.9600],\n",
      "        [ -4.1643,  -7.1160,  -8.7797,   9.8683,  -5.4357,  15.5752],\n",
      "        [  6.3848,  -0.1071,  -1.4871,  -0.7998,   0.3518,  -3.8342],\n",
      "        [  4.0533,   1.8365,   0.0224,  -0.8645,  -1.5476,  -2.8705],\n",
      "        [  4.3932,   1.0357,  -1.3351,  -0.2981,   0.1662,  -3.4473],\n",
      "        [  0.9940,   2.7543,   4.7335,  -1.7179,  -4.0699,  -2.0280],\n",
      "        [  0.1061,   2.9309,   4.3603,  -1.2959,  -3.9625,  -1.4628],\n",
      "        [  1.5812,   2.1122,   3.2058,  -0.9806,  -3.2427,  -2.0028],\n",
      "        [ -1.0146,   4.6160,   1.1932,  -0.0947,  -1.7411,  -2.1182],\n",
      "        [ -0.8152,   4.6675,   0.4753,  -0.5191,  -1.1365,  -1.8483],\n",
      "        [ -0.6005,   3.9382,  -1.0889,   0.3250,   0.2083,  -1.9681],\n",
      "        [ -0.5071,  -3.4777,  -8.6775,   6.4556,   8.9930,  -2.1758],\n",
      "        [  0.4468,  -5.6277, -11.2091,   7.7940,   9.8071,  -0.6794],\n",
      "        [  1.1395,  -6.1265, -10.8125,   7.4753,   9.8998,  -1.0895],\n",
      "        [ -0.4293,  -3.7398, -10.6213,   8.3536,   6.4794,   0.5005],\n",
      "        [ -0.1905,  -5.3352,  -9.1837,   7.9284,   6.8591,   0.4532],\n",
      "        [ -0.8299,  -5.3289, -11.2209,   9.1722,   7.9791,   0.8014],\n",
      "        [ -3.7268,  -5.7952,  -8.9611,   8.4040,  -2.7512,  12.9019],\n",
      "        [ -7.4444,  -0.6818,  -6.9066,   7.0371,  -2.3829,  10.7546],\n",
      "        [ -6.5149,  -1.6512,  -5.9661,   6.6689,  -5.3737,  13.0779],\n",
      "        [  5.3374,   0.6043,  -1.5373,  -0.2831,   0.1030,  -3.6285],\n",
      "        [  5.5975,   0.1791,  -1.0628,  -0.6031,   0.4026,  -3.8882],\n",
      "        [  5.2273,   0.9476,  -1.4684,  -0.2927,   0.4945,  -4.2947],\n",
      "        [ -0.3077,   5.1130,   2.8941,  -1.6999,  -2.0393,  -3.0907],\n",
      "        [  1.3972,   2.9650,   4.6089,  -1.9821,  -3.1302,  -3.1193],\n",
      "        [  1.7375,   3.5639,   4.8812,  -2.5782,  -3.4190,  -3.3891],\n",
      "        [ -1.0250,   5.7172,  -1.1750,   0.4436,  -0.6753,  -2.4346],\n",
      "        [  1.0640,   4.8315,  -2.0799,  -0.2632,   0.5354,  -3.3195],\n",
      "        [  0.3165,   5.3111,  -1.0669,  -0.1835,  -0.4356,  -3.1191],\n",
      "        [ -1.0325,   6.7134,  -0.7830,  -0.4539,  -0.5830,  -2.9163],\n",
      "        [  2.7111,  -5.9687,  -9.6080,   6.6890,   7.8093,  -1.1527],\n",
      "        [  1.9770,  -4.1493,  -8.4592,   4.8286,   9.4810,  -3.0513],\n",
      "        [  0.5214,  -5.6525, -11.5588,   7.8700,   9.5137,  -0.1952],\n",
      "        [ -2.0743,  -6.6293, -10.5793,  10.0031,   0.5086,   8.9408],\n",
      "        [ -1.8603,  -6.5014, -10.0992,   9.4358,   0.8762,   8.3655],\n",
      "        [ -0.2191,  -5.6378, -10.5205,   8.7429,   7.2507,   0.8698],\n",
      "        [  0.1055,  -6.8328, -10.5312,   9.6447,   6.6769,   1.3905],\n",
      "        [ -0.4064,  -5.7882, -10.7668,   8.8250,   7.3407,   1.2715],\n",
      "        [ -5.4164,  -5.2428,  -8.8522,   8.9148,  -5.3747,  15.9906],\n",
      "        [ -4.0981,  -6.4907,  -9.1197,   8.9092,  -4.6836,  15.4621],\n",
      "        [ -2.9980,  -7.8904,  -9.0555,   9.1266,  -4.2429,  14.9542],\n",
      "        [ -5.0706,  -5.3750,  -8.2195,   8.5933,  -5.2548,  15.3945],\n",
      "        [ -5.5245,  -5.5319,  -8.0427,   9.2464,  -6.7976,  16.5949],\n",
      "        [  6.5406,  -0.1928,   2.0963,  -2.1259,  -1.2012,  -4.5704],\n",
      "        [  7.0725,   0.6799,   1.9671,  -3.0957,  -1.0522,  -5.0455],\n",
      "        [  6.5647,   1.3020,   2.0641,  -3.4252,  -0.1703,  -5.7833],\n",
      "        [  3.2198,   2.3428,   9.3319,  -5.4616,  -4.3893,  -4.4381],\n",
      "        [  2.8148,   2.2765,   9.3262,  -4.8799,  -5.0726,  -3.7476],\n",
      "        [ -0.9799,   5.8919,   3.4068,  -1.1233,  -3.6885,  -2.5110],\n",
      "        [  1.3068,   5.0761,   3.8921,  -2.2204,  -3.7864,  -3.4257],\n",
      "        [  0.5515,  -5.5636, -11.2082,   8.0787,  10.1081,  -1.4327],\n",
      "        [  2.1845,  -3.8639,  -7.6132,   4.9313,   8.4437,  -3.4585],\n",
      "        [  1.8667,  -5.2740,  -9.7526,   5.6797,  10.5379,  -2.5410]])\n",
      "Predicted class: tensor([2, 1, 1, 4, 4, 3, 3, 3, 3, 3, 5, 5, 5, 0, 0, 0, 2, 2, 2, 1, 1, 1, 4, 4,\n",
      "        4, 3, 3, 3, 5, 5, 5, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 4, 4, 4, 3, 3, 3, 3,\n",
      "        3, 5, 5, 5, 5, 5, 0, 0, 0, 2, 2, 1, 1, 4, 4, 4])\n",
      "match: tensor([ True,  True,  True,  True,  True, False, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[  1.7719,  -7.1237, -11.2402,   7.6306,   9.9909,  -0.6247],\n",
      "        [  2.3092,  -6.0318,  -9.2712,   6.5635,   8.7388,  -1.8148],\n",
      "        [ -5.2434,  -2.2878,  -9.6496,   9.7202,   3.3650,   4.6973],\n",
      "        [ -1.4911,  -6.0838,  -9.8373,   9.7251,   3.9584,   4.1287],\n",
      "        [  0.3796,  -7.3655, -10.3732,   9.2805,   6.2548,   2.1970],\n",
      "        [ -2.6005,  -4.2680,  -9.8274,   9.9479,   4.5400,   2.6709],\n",
      "        [ -4.8443,  -6.2322,  -9.0524,   9.5293,  -5.5544,  16.0969],\n",
      "        [ -4.7425,  -6.7480,  -8.4978,   9.4981,  -5.8596,  16.2771],\n",
      "        [ -4.4830,  -6.8267,  -8.9197,   9.6124,  -5.2213,  15.7897],\n",
      "        [ -4.6716,  -6.4371,  -9.2788,   9.5069,  -4.6877,  15.5614],\n",
      "        [  7.0590,  -0.2080,   0.7036,  -1.5688,  -1.9519,  -3.4466],\n",
      "        [  7.0160,   0.4473,   1.0662,  -1.8714,  -1.5626,  -4.5358],\n",
      "        [  4.1270,   2.3249,   7.0113,  -4.5569,  -3.4491,  -4.8088],\n",
      "        [  1.6494,   5.5909,   4.0862,  -3.2635,  -2.8222,  -4.3244],\n",
      "        [  0.3312,   6.2914,   4.3213,  -2.7470,  -3.4899,  -3.7729],\n",
      "        [  4.1102,   2.3094,   8.2521,  -4.9611,  -4.4074,  -4.6980],\n",
      "        [  0.0868,   5.4021,   3.8252,  -2.2241,  -3.4207,  -2.7571],\n",
      "        [  0.3010,   6.1314,   5.6447,  -3.6224,  -3.5547,  -3.9516],\n",
      "        [  0.3867,  -5.0287, -10.4378,   7.4595,   9.4877,  -1.2723],\n",
      "        [  0.9904,  -4.8971, -11.7283,   7.4000,  10.9017,  -2.0907],\n",
      "        [ -0.2223,  -4.1115, -11.7945,   7.7898,  10.3770,  -1.4301],\n",
      "        [  0.1066,  -5.3895, -10.2979,   8.1216,   8.7999,  -0.7986],\n",
      "        [ -0.6316,  -7.5303, -10.4948,   9.8010,   3.2286,   5.8462],\n",
      "        [ -2.8777,  -3.4059,  -9.1965,   8.9085,   5.2308,   1.8657],\n",
      "        [  0.3374,  -5.9798, -10.6586,   8.8346,   7.1046,   0.8302],\n",
      "        [ -5.0811,  -4.6629,  -8.4010,   8.5167,  -4.1549,  13.9425],\n",
      "        [ -4.0128,  -6.9822,  -9.4819,   9.2886,  -3.6776,  14.8133],\n",
      "        [ -3.7563,  -6.8824,  -9.3431,   9.1311,  -3.3410,  14.1719],\n",
      "        [ -4.0538,  -6.7043,  -9.1716,   8.5597,  -2.6859,  13.9887],\n",
      "        [  8.2751,  -0.8747,   0.2915,  -1.5063,  -1.3406,  -4.3549],\n",
      "        [  8.4432,  -0.4218,   0.1398,  -2.4149,   0.8918,  -6.0903],\n",
      "        [  2.1777,   3.5968,   9.7090,  -5.8836,  -3.5908,  -5.3378],\n",
      "        [  0.8335,   3.6298,  10.0114,  -4.8953,  -5.6944,  -3.1276],\n",
      "        [  1.5441,   4.2259,  10.1762,  -6.2374,  -3.9179,  -5.0489],\n",
      "        [  1.8637,   5.3659,   2.1446,  -3.2326,  -0.8934,  -4.4363],\n",
      "        [  1.1206,  -5.9246, -11.1623,   7.3593,  10.8898,  -1.7405],\n",
      "        [  1.1652,  -5.6637, -10.5687,   6.8583,   9.8943,  -1.1391],\n",
      "        [  1.5477,  -7.1862, -10.9265,   8.1577,   9.4059,  -0.5709],\n",
      "        [  1.2477,  -6.1701, -11.5632,   7.7451,  10.0133,  -0.7993],\n",
      "        [  1.7759,  -1.6927,  -7.6795,   3.9186,   7.3485,  -3.0041],\n",
      "        [ -2.1506,  -5.9267, -10.0778,  10.4923,   2.9834,   5.0510],\n",
      "        [ -0.1494,  -6.2566, -10.3553,   8.8057,   5.3743,   2.9644],\n",
      "        [ -1.0713,  -5.4793, -10.6980,   9.5135,   6.9644,   1.2888],\n",
      "        [ -4.9842,  -5.7395,  -8.1086,   8.8498,  -4.5151,  14.5071],\n",
      "        [ -5.2669,  -5.4402,  -8.1334,   8.7277,  -5.8503,  15.8976],\n",
      "        [ -4.7854,  -5.6626,  -8.5484,   9.1242,  -5.5538,  15.4255],\n",
      "        [  4.6418,   2.3941,   1.3335,  -2.1711,  -1.3629,  -4.1693],\n",
      "        [  8.3132,   0.1145,  -0.5495,  -2.3295,  -0.0618,  -4.9980],\n",
      "        [  8.4055,  -0.1047,  -0.7561,  -1.5327,  -1.2100,  -4.2955],\n",
      "        [  1.8598,   4.1281,   9.0239,  -5.5371,  -3.6682,  -5.0643],\n",
      "        [ -0.2432,   5.9877,   9.1231,  -5.2832,  -4.5295,  -4.1428],\n",
      "        [  2.0979,   3.8738,   7.6379,  -4.8253,  -3.5960,  -4.4695],\n",
      "        [  1.3994,   6.2821,  -0.8546,  -1.9459,  -0.3017,  -3.7976],\n",
      "        [  0.6256,   6.0862,  -0.8187,  -1.2378,  -1.0118,  -2.8198],\n",
      "        [  2.2723,  -3.9538,  -9.5208,   5.0328,   9.8051,  -3.0507],\n",
      "        [ -0.6142,  -1.3989,  -8.6472,   5.0686,   8.7589,  -2.4667],\n",
      "        [  1.9451,  -1.1102,  -7.5483,   3.4531,   6.7862,  -2.8910],\n",
      "        [ -2.4264,  -2.0503,  -6.3652,   6.9107,   2.9410,   1.5077],\n",
      "        [  0.3954,  -6.4631, -10.0694,   8.9587,   5.0934,   2.4509],\n",
      "        [  2.6870,  -5.0600,  -7.9727,   6.3607,   3.1835,   1.2011],\n",
      "        [  2.6113,  -5.5780, -10.4811,   7.0534,   7.0031,  -0.1708],\n",
      "        [ -3.0519,  -5.1025, -10.5622,   7.2644,   2.8203,   8.8755],\n",
      "        [ -0.5371,  -2.4361,  -7.1641,   3.5622,  -0.3122,   7.1506],\n",
      "        [ -2.7646,  -5.7356,  -8.0184,   8.0145,  -4.3449,  12.8731]])\n",
      "Predicted class: tensor([4, 4, 3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 2, 1, 1, 2, 1, 1, 4, 4, 4, 4, 3, 3,\n",
      "        3, 5, 5, 5, 5, 0, 0, 2, 2, 2, 1, 4, 4, 4, 4, 4, 3, 3, 3, 5, 5, 5, 0, 0,\n",
      "        0, 2, 2, 2, 1, 1, 4, 4, 4, 3, 3, 3, 3, 5, 5, 5])\n",
      "match: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "Probabilities: tensor([[ -4.5305,  -5.4371,  -9.3152,   9.0947,  -3.4856,  13.7844],\n",
      "        [  6.2278,   0.9140,  -0.8149,  -0.7099,  -1.3127,  -3.7290],\n",
      "        [  6.0367,   1.8230,   1.0986,  -2.3607,  -1.1773,  -4.7405],\n",
      "        [  6.1440,   1.7391,   0.2679,  -2.2819,  -0.4513,  -4.8023],\n",
      "        [  2.0581,   3.3449,   5.8873,  -3.4097,  -3.4287,  -3.6446],\n",
      "        [  2.1156,   4.6086,   7.4495,  -5.4472,  -2.3457,  -5.7075],\n",
      "        [  0.2709,   6.2818,   1.2922,  -1.7971,  -2.2463,  -2.9269],\n",
      "        [  2.0816,   3.9570,   7.8676,  -4.6506,  -4.1914,  -4.2823],\n",
      "        [  0.6748,   6.1877,   2.1152,  -2.5360,  -2.2253,  -3.2835],\n",
      "        [  1.4476,   4.9415,   2.1657,  -2.2798,  -2.0317,  -3.3900],\n",
      "        [  0.7081,  -2.7650,  -9.5713,   5.2116,   9.8572,  -2.7802],\n",
      "        [  1.3164,  -2.5545,  -9.4863,   4.8419,   9.2886,  -2.7559],\n",
      "        [  1.5655,  -4.2093,  -9.2913,   5.8933,   7.6997,  -1.0424],\n",
      "        [  2.4817,  -5.3997,  -7.9646,   6.6349,   4.0797,   0.6266],\n",
      "        [ -0.9485,  -1.5182,  -9.2479,   5.8730,   7.1872,  -0.7397],\n",
      "        [  1.3058,  -4.4464, -11.0213,   6.4568,   9.4620,  -1.2421],\n",
      "        [  0.0859,  -3.8905, -10.1426,   7.4764,   7.0760,  -0.0663],\n",
      "        [ -4.3263,  -4.0524,  -9.0785,   6.6794,   0.7840,  10.1866],\n",
      "        [ -5.2731,  -5.0022,  -8.8419,   8.9466,  -4.5860,  14.8095],\n",
      "        [  5.6571,   2.9147,   2.8117,  -4.0461,  -1.2940,  -5.4310],\n",
      "        [  5.8489,   1.5771,   1.6596,  -2.1905,  -1.6521,  -4.6225],\n",
      "        [  4.1331,   2.0795,   8.5425,  -4.9651,  -4.2397,  -4.8744],\n",
      "        [  3.3360,   2.5133,  10.1661,  -6.0282,  -4.2956,  -5.2146],\n",
      "        [  2.3101,   4.0205,   8.6425,  -5.5187,  -3.9161,  -4.9786],\n",
      "        [  1.7708,   6.2132,   3.4346,  -3.5597,  -2.7206,  -4.2448],\n",
      "        [  1.4310,   6.7899,   2.7443,  -3.6199,  -1.9560,  -4.4653],\n",
      "        [  1.5517,  -4.1925,  -8.9567,   5.9622,   8.3723,  -2.1014],\n",
      "        [  0.3745,  -4.4380,  -7.9950,   6.3154,   8.0649,  -1.7578],\n",
      "        [  0.6566,  -6.4850, -10.4775,   8.2768,   8.5890,  -0.0726],\n",
      "        [ -0.7280,  -6.0402, -10.2581,   9.4013,   5.3031,   2.7129],\n",
      "        [  0.2794,  -7.4269, -10.8356,   9.4322,   5.5544,   3.3557],\n",
      "        [ -0.3319,  -6.2406, -10.5226,   9.2561,   6.3742,   1.9263],\n",
      "        [ -4.2688,  -6.6292,  -9.3706,   9.0919,  -2.8043,  13.9636],\n",
      "        [ -5.8528,  -4.4336,  -7.6177,   9.1271,  -4.0212,  12.9595],\n",
      "        [ -3.1302,  -7.4098,  -9.9807,   9.4412,  -2.7162,  13.7301],\n",
      "        [  7.4700,   1.0266,   0.7744,  -2.1497,  -1.0810,  -5.4918],\n",
      "        [  7.6213,   0.6326,   2.0513,  -2.4638,  -1.9812,  -5.3004],\n",
      "        [  2.9014,   2.6906,   8.4403,  -5.1200,  -3.2187,  -5.1358],\n",
      "        [  1.7568,   3.9136,   9.2172,  -5.3438,  -4.0501,  -4.7511],\n",
      "        [  3.4245,   2.1749,   7.5719,  -3.9195,  -4.2438,  -4.4403],\n",
      "        [  0.2441,   5.3637,  10.2423,  -6.3573,  -3.5725,  -5.2217],\n",
      "        [  1.7485,   3.1937,   7.8125,  -4.1140,  -3.8699,  -4.0843],\n",
      "        [  1.1836,   6.4023,   2.9130,  -3.2695,  -1.5771,  -4.9691],\n",
      "        [ -0.2394,   7.6105,   3.9336,  -3.7494,  -1.9444,  -4.7914],\n",
      "        [  1.9152,  -7.1699, -11.3609,   8.0516,   9.6651,  -0.6326],\n",
      "        [ -0.9433,  -2.3574,  -9.5275,   5.9874,   8.9163,  -1.4299],\n",
      "        [  1.2899,  -4.9380, -11.2616,   6.7459,  11.4201,  -2.6771],\n",
      "        [  0.0933,  -5.7358, -10.6646,   7.9706,   9.3384,  -0.4832],\n",
      "        [ -0.8650,  -4.9167,  -9.7923,   8.3560,   6.2243,   1.4855],\n",
      "        [  0.7387,  -7.3564, -10.5640,   9.1246,   5.9248,   2.4825],\n",
      "        [  0.0838,  -6.9647, -11.0039,   9.9466,   6.2629,   2.0490],\n",
      "        [ -7.8613,  -1.8316,  -6.1753,   8.1683,  -5.7507,  13.6516],\n",
      "        [ -2.7869,  -7.8459,  -9.5886,   9.4423,  -3.0592,  13.7996],\n",
      "        [ -5.7747,  -3.9768,  -8.5079,   8.6709,  -4.5080,  14.3252],\n",
      "        [  5.3199,   2.4141,   2.7663,  -2.7841,  -1.3710,  -5.7059],\n",
      "        [  6.8399,   0.4912,   1.6613,  -1.7188,  -1.8186,  -4.9206],\n",
      "        [  6.3297,   1.1872,   3.1195,  -2.6722,  -2.4796,  -4.8927],\n",
      "        [  6.5962,   1.0384,   0.8197,  -1.6985,  -1.3780,  -4.8111],\n",
      "        [  1.6854,   3.6363,   9.8511,  -5.2915,  -4.6508,  -4.5030],\n",
      "        [  2.0311,   3.1685,  10.3086,  -5.9430,  -4.3686,  -4.6502],\n",
      "        [  0.4185,   7.6739,   2.7919,  -3.4862,  -1.8886,  -4.7045],\n",
      "        [  0.2784,   6.9302,   4.8956,  -3.4967,  -3.1282,  -4.6687],\n",
      "        [ -0.5886,   7.8626,   3.9451,  -2.9664,  -3.3224,  -4.1629],\n",
      "        [  1.1908,   5.3910,   2.8321,  -2.0584,  -3.0371,  -3.6349]])\n",
      "Predicted class: tensor([5, 0, 0, 0, 2, 2, 1, 2, 1, 1, 4, 4, 4, 3, 4, 4, 3, 5, 5, 0, 0, 2, 2, 2,\n",
      "        1, 1, 4, 4, 4, 3, 3, 3, 5, 5, 5, 0, 0, 2, 2, 2, 2, 2, 1, 1, 4, 4, 4, 4,\n",
      "        3, 3, 3, 5, 5, 5, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1])\n",
      "match: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True, False, False,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n",
      "Probabilities: tensor([[  0.3562,  -5.3489, -10.5917,   7.4415,   9.1291,  -0.4569],\n",
      "        [  0.4034,  -2.6258,  -9.2545,   5.1263,   9.1065,  -2.1192],\n",
      "        [ -1.4272,  -2.5796, -10.6788,   6.2833,  10.8051,  -1.7004],\n",
      "        [ -6.4666,   2.8038,  -4.4577,   6.6716,  -0.5923,   2.8593],\n",
      "        [ -2.4045,  -0.8526,  -7.5826,   6.9110,   3.7477,   0.8262],\n",
      "        [ -0.1362,  -5.8217, -10.5865,   9.0363,   6.9230,   1.0331],\n",
      "        [ -3.9281,  -7.2278,  -8.8901,   9.0762,  -3.0533,  13.9696],\n",
      "        [ -3.6643,  -2.1189,  -4.6835,   5.2140,  -6.0060,  11.4564],\n",
      "        [ -3.7784,  -6.5113,  -9.9071,   9.4248,  -2.9278,  13.7768],\n",
      "        [ -2.9092,  -8.0397,  -9.1806,   9.8384,  -3.5252,  13.7535],\n",
      "        [  6.2965,   1.8299,  -0.7739,  -1.2089,  -0.6219,  -5.0322],\n",
      "        [  6.1467,   1.5025,  -0.9027,  -1.1160,  -0.2989,  -4.8538],\n",
      "        [  6.9900,   1.6404,  -1.0639,  -1.2370,  -0.6602,  -5.2038],\n",
      "        [  2.9060,   3.0330,   6.4222,  -3.7636,  -3.6972,  -4.1839],\n",
      "        [ -0.3737,   5.9796,  -0.3069,  -0.6915,  -0.7920,  -2.9726],\n",
      "        [ -0.2951,   6.0851,  -0.4929,  -0.4394,  -1.4820,  -2.5328],\n",
      "        [  2.3667,   3.3976,   7.3202,  -4.4413,  -3.5330,  -4.3185],\n",
      "        [  3.0229,   2.9026,   5.6962,  -4.2511,  -1.4418,  -5.2151],\n",
      "        [ -1.0016,   6.0619,  -0.2912,  -0.4913,  -0.7701,  -2.5818],\n",
      "        [ -0.0567,  -4.1828,  -9.3591,   7.3485,   7.2486,  -0.4285],\n",
      "        [  0.3318,  -2.7235,  -8.2937,   5.2289,   9.7338,  -3.6454],\n",
      "        [ -1.1054,  -4.9693, -10.7469,   8.4541,   7.0630,   1.7578],\n",
      "        [ -0.2015,  -4.2869,  -9.8822,   7.5916,   6.4916,   0.7807],\n",
      "        [ -0.2482,  -5.6490, -10.3843,   9.0630,   6.6804,   1.0093],\n",
      "        [ -0.9849,  -7.8454,  -8.6602,   8.2275,  -3.8368,  12.9834],\n",
      "        [ -3.8633,  -4.9451,  -6.6775,   6.9371,  -4.6476,  13.2294],\n",
      "        [  8.4753,   0.6868,   0.3052,  -2.7242,  -0.3236,  -6.0153],\n",
      "        [  7.3376,   1.6499,   0.8009,  -2.9290,  -1.1456,  -5.2075],\n",
      "        [  3.6306,   2.8772,   6.6789,  -4.2202,  -3.7901,  -4.5072],\n",
      "        [  1.5882,   4.7855,   9.3120,  -6.1561,  -3.1733,  -5.6860],\n",
      "        [ -0.5393,   6.5967,  -0.2941,  -0.2356,  -2.2551,  -2.4411],\n",
      "        [ -0.0694,   8.2091,   2.5321,  -2.8179,  -2.8628,  -4.0242]])\n",
      "Predicted class: tensor([4, 4, 4, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 2, 1, 1, 2, 2, 1, 3, 4, 3, 3, 3,\n",
      "        5, 5, 0, 0, 2, 2, 1, 1])\n",
      "match: tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True])\n"
     ]
    }
   ],
   "source": [
    "# Let's do some predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X,y in test_dataloader:\n",
    "        pred = model(X)\n",
    "        print(\"Probabilities:\",pred)\n",
    "        print(\"Predicted class:\",torch.argmax(pred, dim=1))\n",
    "        print(\"match:\",torch.argmax(pred, dim=1)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "outstanding-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joeri/UN-PML-Pilot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-divorce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "interpreter": {
   "hash": "97a145eaf0e3f554864ed20cbb791f864530a3c9a69256b4acc43ebf1a046342"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
