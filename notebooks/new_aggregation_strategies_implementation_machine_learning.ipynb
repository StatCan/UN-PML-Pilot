{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BCtZONh3yU4"
      },
      "source": [
        "#**Definizione di Nuove Strategie di Federated Learning con  Flower e Pytorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrYSzFamz37m"
      },
      "source": [
        "#**Installazione dei Pacchetti Richiesti**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q69zTMh2dRH"
      },
      "source": [
        "*   Installazione di PyTorch (Torch)\n",
        "*   Installazione di Torchvision per Computer Vision \n",
        "*   Installazione di Flower per l'Implementazione del Federated Learning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "7GwEkQ0Jz37n"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qls8qd8Iz37p"
      },
      "source": [
        "#**All General Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "yu-1yvWzz37p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timeit\n",
        "import glob\n",
        "import pandas as pd \n",
        "import platform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "216WwsYEXg2j"
      },
      "source": [
        "#**All Machine Learning Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "NMhXiHTAXhbQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o51lANbXqun"
      },
      "source": [
        "#**All Federated Learning Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "4sB9T5rcXjK8"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQQ--21w4ImG"
      },
      "source": [
        "#**All Globals**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "AQRPcxbv4HEh"
      },
      "outputs": [],
      "source": [
        "n_clients = 4\n",
        "strategy_colors = ['red', 'green', 'blue', 'cyan']\n",
        "strategy_list = ['fedavg', 'fedadagrad', 'fedadam', 'fedyogi']\n",
        "strategy_type = 'fedavg'\n",
        "loop_on_strategies = True     # se True \n",
        "dataset = \"har\"                # cifar10, har"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4cXeVEF91j7"
      },
      "source": [
        "#**Hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "j2BhNjhC94dt"
      },
      "outputs": [],
      "source": [
        "n_epochs = 50\n",
        "n_rounds = 25\n",
        "validation_split = 0.2\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "save_path = \"epochs_\"+str(n_epochs)+\"_number_rounds_\"+str(n_rounds)+\"_learning_rate_\"+str(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p9VHdJ-2-gu"
      },
      "source": [
        "#**Initializations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDtG-ecZ2_Rl",
        "outputId": "ffb6cbba-25f6-4c3f-ff97-2da0aa8c063f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.0.1+cu118 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "start_global_time = timeit.default_timer()\n",
        "\n",
        "if not os.path.exists(\"./Outputs\"):\n",
        "    os.makedirs(\"./Outputs\")\n",
        "\n",
        "if not os.path.exists(\"./Outputs/\"+save_path):\n",
        "    os.makedirs(\"./Outputs/\"+save_path)\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Prova \"cuda\" per addestramento su GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")\n",
        "\n",
        "OS = platform.system()           # Sistema Operativo\n",
        "\n",
        "strategies_acc = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3-9cMBkbAsq"
      },
      "source": [
        "#**All General Functions Definitions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "c9EGcGI8bNeq"
      },
      "outputs": [],
      "source": [
        "def data_download(file_to_download, gdrive_code, OS, uncompress = True):\n",
        "  if not os.path.exists(file_to_download):\n",
        "    os.system('gdown --id \"'+gdrive_code+'\" --output '+file_to_download)\n",
        "    if OS == \"Linux\" and uncompress:\n",
        "        os.system('unzip -o -n \"./'+file_to_download+'\" -d '+os.path.dirname(file_to_download))\n",
        "    return True\n",
        "  else: \n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw7qNz4k6g-P"
      },
      "source": [
        "#**Data Download**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "Tj3J-tRF6ebG"
      },
      "outputs": [],
      "source": [
        "if dataset == \"cifar10\":\n",
        "  transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "  )\n",
        "  trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "  testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "  print(\"Training Set size: \", len(trainset))\n",
        "  print(\"Test Set size: \", len(testset))\n",
        "elif dataset == \"har\": \n",
        "  out = data_download(\"./har_datasets_fl.zip\", \"1LUjU4yvBRh6FPBlIHRCD2uf5zMH6l9tC\", OS) \n",
        "  #urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\", filename=\"har-data.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGxcJLB06v-9"
      },
      "source": [
        "#**Ripartizione del Training Set per il Federated Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf9hdLuk9DIf"
      },
      "source": [
        "Il **Dataset** principale viene splittato **in N parti** tante quante il numero di client. Ciascun pezzo è costituito da differenti training e validation set, mentre il test set viene condiviso tra tutti i clients, di modo tale che esso sia sempre lo stesso e possa garantire confronti affidabili. Questo test set comune infatti permette di fare dei confronti tra differenti client con un unico e stabile test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "PBQj-WxC6tZl"
      },
      "outputs": [],
      "source": [
        "if dataset == \"cifar10\":\n",
        "  partition_size = len(trainset) // n_clients\n",
        "  lengths = [partition_size] * n_clients\n",
        "  datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "  print(\"Size of each Dataset Partition: \", partition_size)\n",
        "  print(\"All Dataset Partitions sizes: \", lengths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6xA5e_C4Xjw"
      },
      "source": [
        "#**Preparazione dei Dati**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC1yY16X4bNP"
      },
      "source": [
        "Per ciascun sottoinsieme, estraiamo un training set e un validation set e li wrappiamo all'interno di DataLoader, definendo il batch size, lo shuffle, ecc. Il testset viene condiviso tra tutti i client, mentre train e validation set sono specifici per ogni client: questo è vero sia per il dataset di benchmark cifar10 che per il dataset di human activity recognition (har). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UZNdtuIz37s",
        "outputId": "f5a9b046-94c0-4bb8-953c-0111de22e416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading :  ./har_datasets_fl/3 - STATCAN\n",
            "Reading :  ./har_datasets_fl/1 - ISTAT\n",
            "Reading :  ./har_datasets_fl/2 - ONS\n",
            "Reading :  ./har_datasets_fl/0 - CBS\n"
          ]
        }
      ],
      "source": [
        "trainloaders = []\n",
        "valloaders = []\n",
        "\n",
        "if dataset == \"cifar10\": \n",
        "  for ds in datasets:\n",
        "      len_val = len(ds) // validation_rate\n",
        "      len_train = len(ds) - len_val\n",
        "      lengths = [len_train, len_val]\n",
        "      ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "      trainloaders.append(DataLoader(ds_train, batch_size = batch_size, shuffle=True))\n",
        "      valloaders.append(DataLoader(ds_val, batch_size = batch_size))\n",
        "\n",
        "  testloader = DataLoader(testset, batch_size = batch_size)\n",
        "elif dataset == \"har\":\n",
        "  subdirectories = [f.path for f in os.scandir('./har_datasets_fl') if f.is_dir()]\n",
        "\n",
        "  global_X_testset = pd.DataFrame()\n",
        "  global_y_testset = pd.DataFrame()\n",
        " \n",
        "  for subdirectory in subdirectories:\n",
        "    fold_number = os.path.basename(subdirectory).split('-')[0].strip()    \n",
        "    print(\"Reading : \", subdirectory)\n",
        "    \n",
        "    trainset = pd.read_csv(subdirectory+'/train/'+fold_number+'_ALL_train.csv', delimiter = ';')\n",
        "    valset = trainset[-int(len(trainset)*validation_split):]\n",
        "    trainset = trainset[0:-int(len(trainset)*validation_split)]\n",
        "    testset = pd.read_csv(subdirectory+'/test/'+fold_number+'_ALL_test.csv', delimiter = ';')\n",
        "\n",
        "    '''\n",
        "    print(trainset.shape)\n",
        "    print(valset.shape)\n",
        "    print(testset.shape)\n",
        "    '''\n",
        "\n",
        "    X_train = pd.concat([trainset[str(i)] for i in range(561)], axis = 1)\n",
        "    y_train = trainset['Y'] - 1\n",
        "\n",
        "    X_val = pd.concat([valset[str(i)] for i in range(561)], axis = 1)\n",
        "    y_val = valset['Y'] - 1\n",
        "\n",
        "    X_test = pd.concat([testset[str(i)] for i in range(561)], axis = 1)\n",
        "    y_test = testset['Y'] - 1\n",
        "\n",
        "    global_X_testset = pd.concat([global_X_testset, X_test], axis=0)\n",
        "    global_y_testset = pd.concat([global_y_testset, y_test], axis=0)\n",
        "\n",
        "    training_data = torch.utils.data.TensorDataset(torch.tensor(X_train.values).float(), torch.as_tensor(y_train.values).squeeze())\n",
        "    val_data = torch.utils.data.TensorDataset(torch.tensor(X_val.values).float(), torch.as_tensor(y_val.values).squeeze())\n",
        "    trainloaders.append(DataLoader(training_data, batch_size=batch_size))\n",
        "    valloaders.append(DataLoader(val_data, batch_size=batch_size))\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(torch.tensor(global_X_testset.values).float(), torch.as_tensor(global_y_testset.values).squeeze())\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQOgZcsK-3tV",
        "outputId": "48e90fc3-73e3-4d61-8919-4109b6765f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Subsets:  4\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Training Subsets: \", len(trainloaders))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR1YC_uO_QGr",
        "outputId": "1834ddfb-c1a6-44af-e1cf-1780c2a881c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Validation Subsets:  4\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of Validation Subsets: \", len(trainloaders))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKD91sIrBEQS"
      },
      "source": [
        "#**Definizione del Modello**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "eP6FFTRKBBzt"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\" Multi Layer Perceptron \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        super(MLP, self).__init__()\n",
        "        #self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(561, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 6)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        #x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "# Crea un'istanza del modello e ne ottiene i parametri\n",
        "if dataset == \"cifar10\":\n",
        "  Net = ConvNet\n",
        "elif dataset == \"har\":\n",
        "  Net = MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSAcBk-Wz37t"
      },
      "source": [
        "#**Addestramento del Modello**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXWvpXhQkZSg"
      },
      "source": [
        "Nel **federated learning**, il server manda i parametri globali del modello ai suoi client, e i client aggiornano il modello locale mediante i parametri ricevuti dal server. \n",
        "\n",
        "Dunque i client addestrano il modello sui dati locali (i quali influenza i parametri del modello localmente) e mandano i parametri del modello cambiati/aggiornati di nuovo indietro verso il server (o in alternativa, mandano i gradienti verso il server, non in questo caso i parametri completi del modello). \n",
        "\n",
        "Abbiamo bisogno pertanto di due funzioni di supporto per aggiornare il modello locale con i parametri ricevuti dal server (set_parameters) e ottenere i parametri aggiornati dal modello locale (get_parameters). Le seguenti funzioni eseguno queste operazioni per il modello Pytorch precedentemente definito. \n",
        "\n",
        "In sostanza usuamo **state_dict** per accedere ai tensori dei parametri del modello PyTorch. I tensori del parametro sono poi convertiti a/da una lista di array Numpy (che Flower è in grado di serializzare/deserializzare)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNebBoMmixaR"
      },
      "source": [
        "##**Aggiornamento dei Parametri del Modello**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "0JS7mbiACzyq"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXUpy6XEmnXV"
      },
      "source": [
        "##**Addestramento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "RYr_By50z37u"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metriche\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKu2WdJwB0TL"
      },
      "source": [
        "#**Model Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "FKSlyuX2ByI7"
      },
      "outputs": [],
      "source": [
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return accuracy, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8mEMZEQz37v"
      },
      "source": [
        "#**Implementazione del Client Flower**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95OU1bivpGs1"
      },
      "source": [
        "Come sappiamo i sistemi di Federated learning sono costituiti da una parte client e una parte serve. In Flower, creiamo i client implementando delle sottoclassi di `flwr.client.Client` o `flwr.client.NumPyClient`. \n",
        "\n",
        "Usiamo adesso `NumPyClient` dal momento che è più facile da implementare. \n",
        "\n",
        "Per implementare il client, creiamo una sottoclasse `flwr.client.NumPyClient` e implementiamo 3 metodi `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Ritorna i parametri del modello attuale. \n",
        "* `fit`: Riceve i parametri del modello dal server, addestra i parametri sui dati locali, e ritorna i parametri del modello aggiornati verso il server. \n",
        "* `evaluate`: Receve i parametri del modello dal server, valuta i parametri del modello sui dati locali, e ritorna il risultato della valutazione al server. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "elxhgUFIz37y"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=n_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        \n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCpI45pCyIkM"
      },
      "source": [
        "Flower, di default, inizializza il modello gobale richiedendo un client casuale per l'inizializzazione dei parametri. In molti casi, vogliamo più controllo sull'inizializzazione dei parametri. Flower quindi permette quindi di passare i parametri inziali alla Strategia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKPR4AsTvUbP"
      },
      "source": [
        "Quando chiamiamo **start_simulation**, diciamo a Flower che ci sono 4 client. Flower aòòpra va avanti e richiede la strategia  FedAvg per selezionare i client. FedAvg sa che dovrebbe selezionalre il 100% dei client disponibili (fraction_fit=1.0), così va avanti e seleziona 4 client casualmente (cioè 100% dei 4)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjKKveUJ2ny9"
      },
      "source": [
        "#**Selezione della Strategia di Aggregazione Built-In**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADMtlWBEzEhO",
        "outputId": "433d79ad-6ecd-4021-d10e-1d0214a978e0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-06-08 15:23:19,674 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing Strategy... :  Fedavg\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50708)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=50707)\u001b[0m Epoch 1: train loss 0.0030662829522043467, accuracy 0.9428959891230455\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=50708)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=50708)\u001b[0m 2023-06-08 15:06:17.308651: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-08 15:23:25,172\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-08 15:23:26,930 | app.py:180 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3923648102.0, 'CPU': 2.0, 'memory': 7847296206.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3923648102.0, 'CPU': 2.0, 'memory': 7847296206.0}\n",
            "INFO flwr 2023-06-08 15:23:26,938 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-08 15:23:26,945 | server.py:269 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-06-08 15:23:26,947 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-08 15:23:26,949 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-08 15:23:26,957 | server.py:218 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "\u001b[2m\u001b[36m(pid=55795)\u001b[0m 2023-06-08 15:23:29.643824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 1: train loss 0.02526571974158287, accuracy 0.3664174031271244\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 15: train loss 0.004546018783003092, accuracy 0.9014276002719238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 16: train loss 0.0042570652440190315, accuracy 0.9061862678450034\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 0.002374900970607996, accuracy 0.9592114208021754\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 38: train loss 0.0015492341481149197, accuracy 0.9762066621346023\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 50: train loss 0.0010878092143684626, accuracy 0.981645139360979\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.006079749204218388, accuracy 0.8701563562202583\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 11: train loss 0.006079749204218388, accuracy 0.8701563562202583\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 21: train loss 0.0032144177239388227, accuracy 0.9320190346702923\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 34: train loss 0.0019054122967645526, accuracy 0.964649898028552\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 44: train loss 0.001357842586003244, accuracy 0.9741672331747111\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:24:21,336 | server.py:232 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-06-08 15:24:21,359 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 15:24:21,364 | server.py:168 | evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:24:21,623 | server.py:182 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-06-08 15:24:21,630 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 15:24:21,638 | server.py:218 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 3: train loss 0.0015056305564939976, accuracy 0.9714479945615228\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 0.0009386578458361328, accuracy 0.9836845683208701\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 17: train loss 0.0008487221784889698, accuracy 0.9850441876274643\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 28: train loss 0.000623991887550801, accuracy 0.990482664853841\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 39: train loss 0.0005096913664601743, accuracy 0.991162474507138\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 3: train loss 0.0014903686242178082, accuracy 0.9700883752549286\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 0.001023847609758377, accuracy 0.9802855200543847\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 0.0009629272390156984, accuracy 0.9809653297076818\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 26: train loss 0.0007302223239094019, accuracy 0.982324949014276\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 41: train loss 0.000572096323594451, accuracy 0.9898028552005439\u001b[32m [repeated 29x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:25:03,236 | server.py:232 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:25:03,266 | server.py:168 | evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:25:03,652 | server.py:182 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:25:03,656 | server.py:218 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 50: train loss 0.0006239877548068762, accuracy 0.9884432358939497\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m Epoch 10: train loss 0.0008361405343748629, accuracy 0.982324949014276\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0008670792449265718, accuracy 0.9802855200543847\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0008670792449265718, accuracy 0.9802855200543847\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 0.0007345738704316318, accuracy 0.9789259007477906\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 38: train loss 0.0006444499013014138, accuracy 0.981645139360979\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 49: train loss 0.0003645711694844067, accuracy 0.9932019034670292\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 0.0005905037978664041, accuracy 0.9891230455472467\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 0.0005787871778011322, accuracy 0.9891230455472467\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 26: train loss 0.0007029961561784148, accuracy 0.9850441876274643\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 37: train loss 0.0005718157044611871, accuracy 0.9870836165873556\u001b[32m [repeated 23x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:25:44,001 | server.py:232 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:25:44,024 | server.py:168 | evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:25:44,250 | server.py:182 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:25:44,253 | server.py:218 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 50: train loss 0.0004394912102725357, accuracy 0.991162474507138\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0004755121481139213, accuracy 0.9870836165873556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0004755121481139213, accuracy 0.9870836165873556\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 22: train loss 0.0003971369587816298, accuracy 0.9898028552005439\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 36: train loss 0.00029910236480645835, accuracy 0.9945615227736234\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 48: train loss 0.0005583033198490739, accuracy 0.9796057104010877\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 7: train loss 0.0004095998883713037, accuracy 0.9891230455472467\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 11: train loss 0.0003442533779889345, accuracy 0.9918422841604351\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 21: train loss 0.00030028956825844944, accuracy 0.9952413324269205\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 33: train loss 0.00036342767998576164, accuracy 0.9925220938137321\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 43: train loss 0.00047222577268257737, accuracy 0.991162474507138\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:26:27,697 | server.py:232 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:26:27,720 | server.py:168 | evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:26:27,962 | server.py:182 | evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:26:27,970 | server.py:218 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 5: train loss 0.0008235127897933125, accuracy 0.9748470428280082\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 0.0005309227854013443, accuracy 0.9870836165873556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 17: train loss 0.00038142522680573165, accuracy 0.9898028552005439\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 0.000334837386617437, accuracy 0.990482664853841\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 40: train loss 0.00029013754101470113, accuracy 0.9938817131203264\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 5: train loss 0.0005165468319319189, accuracy 0.9870836165873556\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 9: train loss 0.00044607403106056154, accuracy 0.991162474507138\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 0.0005848017754033208, accuracy 0.981645139360979\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 26: train loss 0.00022661582625005394, accuracy 0.9952413324269205\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 42: train loss 5.172441160539165e-05, accuracy 0.9993201903467029\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:27:11,527 | server.py:232 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 49: train loss 5.656423672917299e-05, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:27:11,550 | server.py:168 | evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:27:11,795 | server.py:182 | evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:27:11,799 | server.py:218 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 0.00013089562708046287, accuracy 0.9972807613868117\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 0.00012083369074389338, accuracy 0.9972807613868117\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 25: train loss 0.0003628167905844748, accuracy 0.9891230455472467\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 34: train loss 0.000355255528120324, accuracy 0.9918422841604351\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 48: train loss 0.00012591893028002232, accuracy 0.9966009517335146\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 10: train loss 0.00019928101391997188, accuracy 0.9972807613868117\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 0.0002704186481423676, accuracy 0.9945615227736234\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 20: train loss 0.0002595298574306071, accuracy 0.9945615227736234\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 33: train loss 0.00022727939358446747, accuracy 0.9972807613868117\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 48: train loss 0.00028867649962194264, accuracy 0.9938817131203264\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:27:54,603 | server.py:232 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:27:54,628 | server.py:168 | evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:27:54,983 | server.py:182 | evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:27:54,991 | server.py:218 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 4: train loss 0.00020723593479488045, accuracy 0.9952413324269205\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 0.0003456942504271865, accuracy 0.990482664853841\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 18: train loss 9.525266068521887e-05, accuracy 0.9986403806934059\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 32: train loss 8.063215500442311e-05, accuracy 0.9986403806934059\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 39: train loss 2.111769026669208e-05, accuracy 1.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 2: train loss 0.0002470772305969149, accuracy 0.9925220938137321\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 11: train loss 0.00012237351620569825, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 15: train loss 0.000106083694845438, accuracy 0.9979605710401088\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 28: train loss 2.718431642279029e-05, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 42: train loss 1.2308442819630727e-05, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:28:37,422 | server.py:232 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:28:37,442 | server.py:168 | evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:28:37,684 | server.py:182 | evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:28:37,691 | server.py:218 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 1: train loss 0.0004132678441237658, accuracy 0.9898028552005439\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 8: train loss 5.9616679209284484e-05, accuracy 0.9993201903467029\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 9: train loss 5.9570218581939116e-05, accuracy 0.9986403806934059\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 23: train loss 6.668398327747127e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 37: train loss 4.332992375566391e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 44: train loss 1.0429107533127535e-05, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 8: train loss 0.0001008448816719465, accuracy 0.9986403806934059\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 13: train loss 5.276606680126861e-05, accuracy 0.9993201903467029\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 22: train loss 2.282043897139374e-05, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 30: train loss 1.4463097613770515e-05, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 45: train loss 7.553204795840429e-06, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:29:21,694 | server.py:232 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:29:21,720 | server.py:168 | evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:29:21,952 | server.py:182 | evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:29:21,957 | server.py:218 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 7: train loss 1.3708275218959898e-05, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0005784927634522319, accuracy 0.9830047586675731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 0.00026382171199657023, accuracy 0.9938817131203264\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 29: train loss 1.5001799511082936e-05, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 43: train loss 2.7654557470668806e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 1: train loss 0.00032751954859122634, accuracy 0.991162474507138\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 7.951989573484752e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 15: train loss 6.366356956277741e-06, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 29: train loss 3.5863374705513706e-06, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 37: train loss 2.854258127626963e-06, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:30:05,514 | server.py:232 | fit_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:30:05,534 | server.py:168 | evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:30:05,780 | server.py:182 | evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:30:05,786 | server.py:218 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 50: train loss 2.0859069991274737e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 13: train loss 3.353280135343084e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 3.1870981729298364e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 22: train loss 2.3055445126374252e-06, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 35: train loss 1.4986695759944269e-06, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 49: train loss 1.018467287394742e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 9: train loss 9.361935371998698e-05, accuracy 0.9986403806934059\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 8: train loss 0.0006721168174408376, accuracy 0.9830047586675731\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 23: train loss 3.816439402726246e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 38: train loss 2.588913957879413e-06, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 46: train loss 4.576958872348769e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:30:48,820 | server.py:232 | fit_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:30:48,841 | server.py:168 | evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:30:49,068 | server.py:182 | evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:30:49,077 | server.py:218 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 8: train loss 0.0001408190291840583, accuracy 0.9959211420802175\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 7.19124946044758e-05, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 22: train loss 6.4560504142718855e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 32: train loss 4.3928989725827705e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 45: train loss 2.868450110327103e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 8: train loss 8.601184526924044e-05, accuracy 0.9972807613868117\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 5.159963166079251e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 19: train loss 4.0961049307952635e-06, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 32: train loss 2.6547663765086327e-06, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 44: train loss 1.1518617384354002e-06, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:31:30,020 | server.py:232 | fit_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:31:30,044 | server.py:168 | evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:31:30,433 | server.py:182 | evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:31:30,440 | server.py:218 | fit_round 12: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 4: train loss 0.00019247781892772764, accuracy 0.9952413324269205\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 9: train loss 0.0001026498430292122, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 16: train loss 4.021931545139523e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 31: train loss 2.246999883936951e-06, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 41: train loss 1.753049446051591e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 3: train loss 3.5086839488940313e-05, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 1.6340640058842837e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 17: train loss 1.422174364051898e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 1.0245789781038184e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 39: train loss 1.8721307242230978e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:32:12,863 | server.py:232 | fit_round 12 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:32:12,883 | server.py:168 | evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:32:13,126 | server.py:182 | evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:32:13,133 | server.py:218 | fit_round 13: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 2: train loss 3.0004199288669042e-05, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 1.338158426733571e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 2.3964439606061205e-05, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 24: train loss 8.220071094910963e-07, accuracy 1.0\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 38: train loss 5.81791596232506e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 49: train loss 4.58077352050168e-07, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 10: train loss 0.00011174897372256964, accuracy 0.9972807613868117\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 4.505715878622141e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 25: train loss 1.8224476434625103e-06, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 37: train loss 1.3799740372633096e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 47: train loss 1.2779921689798357e-06, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:32:55,540 | server.py:232 | fit_round 13 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:32:55,565 | server.py:168 | evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:32:55,797 | server.py:182 | evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:32:55,805 | server.py:218 | fit_round 14: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 11: train loss 1.288721523451386e-05, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 5.743105248257052e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 23: train loss 3.3134224395325873e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 33: train loss 6.598576192118344e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 48: train loss 4.7198847141771694e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 11: train loss 7.5751609983854e-05, accuracy 0.9993201903467029\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 7.507798727601767e-05, accuracy 0.9966009517335146\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 21: train loss 2.8747961096087238e-06, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 34: train loss 1.802379529181053e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 47: train loss 8.009565704014676e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:33:36,512 | server.py:232 | fit_round 14 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:33:36,538 | server.py:168 | evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:33:36,890 | server.py:182 | evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:33:36,896 | server.py:218 | fit_round 15: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 6: train loss 3.864030986733269e-06, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 7.635368888259109e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 21: train loss 5.509691618499346e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 31: train loss 4.2948036593770667e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 38: train loss 9.864141929938341e-07, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 2: train loss 0.00019526509277056903, accuracy 0.9938817131203264\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 4.7465964598814026e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 17: train loss 3.87371164833894e-06, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 26: train loss 1.6754513580963248e-06, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 39: train loss 1.043819224832987e-06, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:34:19,952 | server.py:232 | fit_round 15 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:34:19,976 | server.py:168 | evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:34:20,199 | server.py:182 | evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:34:20,208 | server.py:218 | fit_round 16: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 2: train loss 1.4279354218160734e-05, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 10: train loss 0.00035449740244075656, accuracy 0.9918422841604351\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 4.310787517169956e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 25: train loss 1.787808855624462e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 39: train loss 9.60578859121597e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 49: train loss 7.786643436702434e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 1.5304684666261892e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 1.2739014891849365e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 6.851945499875001e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 37: train loss 8.851387178765435e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:35:02,761 | server.py:232 | fit_round 16 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:35:02,782 | server.py:168 | evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:35:03,023 | server.py:182 | evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:35:03,026 | server.py:218 | fit_round 17: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 50: train loss 3.570816033970914e-07, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 1.96352880266204e-06, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m Epoch 14: train loss 1.96352880266204e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 1.8137429833586793e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 23: train loss 4.276494962596189e-07, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 36: train loss 8.428428941442689e-07, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 1: train loss 8.870061719790101e-05, accuracy 0.9972807613868117\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 9: train loss 3.129715423710877e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 10: train loss 2.4821449642331572e-06, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 23: train loss 1.0326027677365346e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 37: train loss 9.030479759530863e-07, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 48: train loss 5.340487518878945e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:35:45,018 | server.py:232 | fit_round 17 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:35:45,045 | server.py:168 | evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:35:45,279 | server.py:182 | evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:35:45,283 | server.py:218 | fit_round 18: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 9: train loss 5.577784349952708e-07, accuracy 1.0\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 4.1968729647123837e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 24: train loss 3.036137741219136e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 34: train loss 2.636344618167641e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 47: train loss 1.6232860389209236e-07, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 9.178851314572967e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 15: train loss 1.861646296674735e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 21: train loss 1.487152303525363e-06, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 33: train loss 1.091017452381493e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 49: train loss 3.409176656532509e-07, accuracy 1.0\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:36:24,646 | server.py:232 | fit_round 18 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:36:24,666 | server.py:168 | evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:36:24,908 | server.py:182 | evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:36:24,915 | server.py:218 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 8: train loss 3.3535748116264585e-06, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 9: train loss 3.5770051454164786e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 20: train loss 1.6187713072213228e-06, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 34: train loss 5.121771664562402e-07, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 45: train loss 6.945334121155611e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 6: train loss 8.023499731280026e-07, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 4.220358391648915e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 20: train loss 3.55917251226856e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 30: train loss 2.5963859684452473e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 40: train loss 2.0780488796390273e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:37:08,514 | server.py:232 | fit_round 19 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:37:08,539 | server.py:168 | evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:37:08,792 | server.py:182 | evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:37:08,799 | server.py:218 | fit_round 20: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 3: train loss 2.4537281205994077e-05, accuracy 0.9993201903467029\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 5.456621693156194e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 4.305831851070252e-07, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 24: train loss 1.9448475541139487e-06, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 39: train loss 1.9081609536897304e-07, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 50: train loss 1.5341146308855969e-07, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 10: train loss 3.8279598811641335e-05, accuracy 0.9993201903467029\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 10: train loss 3.8279598811641335e-05, accuracy 0.9993201903467029\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 24: train loss 9.251622259398573e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 36: train loss 6.385193955793511e-07, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 47: train loss 4.921681693303981e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:37:53,091 | server.py:232 | fit_round 20 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:37:53,120 | server.py:168 | evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:37:53,382 | server.py:182 | evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:37:53,387 | server.py:218 | fit_round 21: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 21: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 9: train loss 1.2453149338398362e-06, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 13: train loss 1.0061995681098779e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 19: train loss 7.816367428858939e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 29: train loss 5.557259896704636e-07, accuracy 1.0\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 43: train loss 3.1706673553344444e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 4: train loss 6.407091404980747e-06, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 8: train loss 1.048610329235089e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 3.022381406481145e-06, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 1.2437770919859759e-06, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 37: train loss 8.542433533875737e-07, accuracy 1.0\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 46: train loss 6.695541969747865e-07, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:38:39,610 | server.py:232 | fit_round 21 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 21 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:38:39,637 | server.py:168 | evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:38:39,903 | server.py:182 | evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:38:39,914 | server.py:218 | fit_round 22: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 22: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 9: train loss 4.478625896808808e-07, accuracy 1.0\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 13: train loss 3.1957893042999785e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 20: train loss 7.337757210734708e-07, accuracy 1.0\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 26: train loss 6.023643095431908e-07, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 35: train loss 4.7516812173853396e-07, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 48: train loss 8.539746687574734e-08, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 8: train loss 0.0003476988058537245, accuracy 0.991162474507138\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 9: train loss 1.3812237739330158e-05, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 19: train loss 7.545310722889553e-07, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 33: train loss 4.856376563111553e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 43: train loss 6.147408839751733e-07, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:39:28,225 | server.py:232 | fit_round 22 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 22 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:39:28,258 | server.py:168 | evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:39:28,511 | server.py:182 | evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:39:28,517 | server.py:218 | fit_round 23: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 23: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 1: train loss 3.252961323596537e-05, accuracy 0.9986403806934059\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 14: train loss 6.263069280976197e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 15: train loss 6.013231086399173e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 27: train loss 4.158775652740587e-07, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 35: train loss 3.501235994463059e-07, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 49: train loss 2.712238256208366e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 12: train loss 2.4253438368759817e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 2.4253438368759817e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 20: train loss 9.011240535983234e-07, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 33: train loss 1.3731403214478632e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 46: train loss 1.0116575310803455e-07, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:40:13,048 | server.py:232 | fit_round 23 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 23 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:40:13,073 | server.py:168 | evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:40:13,409 | server.py:182 | evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:40:13,416 | server.py:218 | fit_round 24: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 24: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 3: train loss 7.095624459907413e-05, accuracy 0.9986403806934059\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 11: train loss 0.0002672506670933217, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 16: train loss 1.2028724540869007e-06, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 31: train loss 3.360210882874526e-07, accuracy 1.0\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 38: train loss 2.8606814339582343e-07, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 2: train loss 1.4368657502927817e-05, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 12: train loss 3.741653813449375e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 3.4103317148037604e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 22: train loss 2.577083932919777e-07, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 35: train loss 1.9032457032608363e-07, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 49: train loss 1.0853293019863486e-07, accuracy 1.0\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:40:57,086 | server.py:232 | fit_round 24 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 24 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:40:57,113 | server.py:168 | evaluate_round 24: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 24: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:40:57,484 | server.py:182 | evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:40:57,494 | server.py:218 | fit_round 25: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 25: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 5: train loss 2.7229554689256474e-05, accuracy 0.9986403806934059\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 7: train loss 2.290468046339811e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 17: train loss 4.053118118463317e-06, accuracy 1.0\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 30: train loss 1.125248445532634e-06, accuracy 1.0\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 39: train loss 7.191072768364393e-07, accuracy 1.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 50: train loss 1.3461730929975602e-07, accuracy 1.0\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 13: train loss 6.866799822091707e-07, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 14: train loss 6.482086405412701e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 24: train loss 4.0863977801564033e-07, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=55795)\u001b[0m Epoch 37: train loss 2.8749460057042597e-07, accuracy 1.0\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:41:42,676 | server.py:232 | fit_round 25 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 25 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:41:42,697 | server.py:168 | evaluate_round 25: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 25: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:41:42,921 | server.py:182 | evaluate_round 25 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 25 received 3 results and 0 failures\n",
            "INFO flwr 2023-06-08 15:41:42,929 | server.py:147 | FL finished in 1095.9725066849996\n",
            "INFO:flwr:FL finished in 1095.9725066849996\n",
            "INFO flwr 2023-06-08 15:41:42,935 | app.py:218 | app_fit: losses_distributed [(1, 0.9309718437783832), (2, 0.9436875567665758), (3, 0.9518619436875567), (4, 0.9527702089009991), (5, 0.950045413260672), (6, 0.9518619436875567), (7, 0.9564032697547683), (8, 0.958219800181653), (9, 0.9509536784741144), (10, 0.9527702089009991), (11, 0.9564032697547683), (12, 0.9591280653950953), (13, 0.9545867393278837), (14, 0.9518619436875567), (15, 0.9591280653950953), (16, 0.9573115349682106), (17, 0.958219800181653), (18, 0.9536784741144414), (19, 0.9564032697547683), (20, 0.9564032697547683), (21, 0.955495004541326), (22, 0.9618528610354223), (23, 0.9564032697547683), (24, 0.9573115349682106), (25, 0.96094459582198)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.9309718437783832), (2, 0.9436875567665758), (3, 0.9518619436875567), (4, 0.9527702089009991), (5, 0.950045413260672), (6, 0.9518619436875567), (7, 0.9564032697547683), (8, 0.958219800181653), (9, 0.9509536784741144), (10, 0.9527702089009991), (11, 0.9564032697547683), (12, 0.9591280653950953), (13, 0.9545867393278837), (14, 0.9518619436875567), (15, 0.9591280653950953), (16, 0.9573115349682106), (17, 0.958219800181653), (18, 0.9536784741144414), (19, 0.9564032697547683), (20, 0.9564032697547683), (21, 0.955495004541326), (22, 0.9618528610354223), (23, 0.9564032697547683), (24, 0.9573115349682106), (25, 0.96094459582198)]\n",
            "INFO flwr 2023-06-08 15:41:42,944 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-08 15:41:42,945 | app.py:220 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-06-08 15:41:42,947 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-08 15:41:42,951 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=55796)\u001b[0m Epoch 50: train loss 2.2304438118680991e-07, accuracy 1.0\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55795)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-06-08 15:41:43,525 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing Strategy... :  Fedadagrad\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=55796)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=55796)\u001b[0m 2023-06-08 15:23:29.788162: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-08 15:41:48,995\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-08 15:41:50,827 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7847220020.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3923610009.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7847220020.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'object_store_memory': 3923610009.0}\n",
            "INFO flwr 2023-06-08 15:41:50,840 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-08 15:41:50,848 | server.py:269 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-06-08 15:41:50,850 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-08 15:41:50,856 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-08 15:41:50,861 | server.py:218 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "\u001b[2m\u001b[36m(pid=66074)\u001b[0m 2023-06-08 15:41:53.364571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 1: train loss 0.02485586889088154, accuracy 0.451393609789259\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 8: train loss 0.007703953422605991, accuracy 0.840244731475187\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.00671473378315568, accuracy 0.8592794017675051\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 24: train loss 0.0027630471158772707, accuracy 0.9490142760027193\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 35: train loss 0.0018148858798667789, accuracy 0.9639700883752549\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 43: train loss 0.0014145411550998688, accuracy 0.972807613868117\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.00897154863923788, accuracy 0.8334466349422162\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 14: train loss 0.004825903102755547, accuracy 0.9000679809653297\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 21: train loss 0.0031862736213952303, accuracy 0.9299796057104011\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 28: train loss 0.0022206308785825968, accuracy 0.9544527532290958\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.001462406711652875, accuracy 0.9707681849082257\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:42:44,384 | server.py:232 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-06-08 15:42:44,410 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 15:42:44,423 | server.py:168 | evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:42:44,704 | server.py:182 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-06-08 15:42:44,714 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 15:42:44,716 | server.py:218 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 2.8411920070648193, accuracy 0.6872875594833446\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 6: train loss 0.09781674295663834, accuracy 0.9347382732834806\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 6: train loss 0.09205490350723267, accuracy 0.9422161794697484\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 8: train loss 0.07927879691123962, accuracy 0.947654656696125\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 19: train loss 0.058373089879751205, accuracy 0.9537729435757988\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 29: train loss 0.04983871057629585, accuracy 0.9537729435757988\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 0.03831348195672035, accuracy 0.9632902787219578\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 49: train loss 0.03681228682398796, accuracy 0.9571719918422842\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 8: train loss 0.07969515770673752, accuracy 0.9320190346702923\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.07599319517612457, accuracy 0.9326988443235894\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 13: train loss 0.05921926721930504, accuracy 0.9503738953093134\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 24: train loss 0.048144999891519547, accuracy 0.95581237253569\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 36: train loss 0.0421011708676815, accuracy 0.9510537049626104\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 44: train loss 0.0330871120095253, accuracy 0.9592114208021754\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:43:43,307 | server.py:232 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:43:43,340 | server.py:168 | evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:43:43,614 | server.py:182 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:43:43,618 | server.py:218 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 50: train loss 0.031007926911115646, accuracy 0.9653297076818491\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 118.67050170898438, accuracy 0.4357579877634262\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 10: train loss 118.67050170898438, accuracy 0.4357579877634262\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 17: train loss 64.72259521484375, accuracy 0.4636301835486064\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 28: train loss 16.58389663696289, accuracy 0.681169272603671\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 7.166759014129639, accuracy 0.7185588035350102\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 42: train loss 2.4544780254364014, accuracy 0.7260367097212781\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 50: train loss 0.33077800273895264, accuracy 0.8178110129163834\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 12: train loss 101.7762680053711, accuracy 0.44391570360299115\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 12: train loss 101.7762680053711, accuracy 0.44391570360299115\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 19: train loss 49.66718673706055, accuracy 0.4806254248810333\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 29: train loss 15.459410667419434, accuracy 0.6940856560163154\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 4.5936479568481445, accuracy 0.7226376614547927\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 48: train loss 0.3773653507232666, accuracy 0.8157715839564922\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:44:44,247 | server.py:232 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:44:44,279 | server.py:168 | evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:44:44,569 | server.py:182 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:44:44,573 | server.py:218 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 7: train loss 31.122081756591797, accuracy 0.3222297756628144\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 12: train loss 19.5134334564209, accuracy 0.36777702243371857\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 13: train loss 17.889284133911133, accuracy 0.38273283480625425\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 20: train loss 9.289653778076172, accuracy 0.4065261726716519\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 26: train loss 3.8629112243652344, accuracy 0.4357579877634262\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 1.496492624282837, accuracy 0.6879673691366417\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 48: train loss 0.08920539915561676, accuracy 0.8116927260367097\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 3: train loss 48.8586311340332, accuracy 0.3256288239292998\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 30.904706954956055, accuracy 0.32290958531611147\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 15: train loss 15.061040878295898, accuracy 0.39972807613868117\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 29: train loss 2.805462598800659, accuracy 0.6702923181509177\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 36: train loss 1.6220111846923828, accuracy 0.6879673691366417\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 46: train loss 0.21148638427257538, accuracy 0.7144799456152278\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:45:37,187 | server.py:232 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:45:37,215 | server.py:168 | evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:45:37,463 | server.py:182 | evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:45:37,471 | server.py:218 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 4: train loss 4.6020636558532715, accuracy 0.44255608429639703\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 8: train loss 1.188942551612854, accuracy 0.4813052345343304\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.5129315257072449, accuracy 0.7124405166553365\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 18: train loss 0.054155588150024414, accuracy 0.8456832087015635\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 27: train loss 0.029423058032989502, accuracy 0.8783140720598233\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 32: train loss 0.024152671918272972, accuracy 0.8891910265125765\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 41: train loss 0.017255503684282303, accuracy 0.9034670292318151\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 49: train loss 0.012355350889265537, accuracy 0.9123045547246771\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 5: train loss 3.624511480331421, accuracy 0.44119646498980286\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 7: train loss 1.7888089418411255, accuracy 0.4418762746430999\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 14: train loss 0.11782985925674438, accuracy 0.8035350101971448\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 23: train loss 0.03223893418908119, accuracy 0.868116927260367\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 27: train loss 0.027913620695471764, accuracy 0.8837525492861998\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 36: train loss 0.019103482365608215, accuracy 0.8987083616587356\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 45: train loss 0.013434282504022121, accuracy 0.9068660774983005\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 50: train loss 0.011265034787356853, accuracy 0.9157036029911625\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:46:49,161 | server.py:232 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:46:49,190 | server.py:168 | evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:46:49,461 | server.py:182 | evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:46:49,468 | server.py:218 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.037446070462465286, accuracy 0.8817131203263087\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.02330278977751732, accuracy 0.8993881713120326\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 17: train loss 0.014577450230717659, accuracy 0.9163834126444595\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 24: train loss 0.010895809158682823, accuracy 0.9299796057104011\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 33: train loss 0.008306797593832016, accuracy 0.9394969408565602\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 39: train loss 0.00738933589309454, accuracy 0.9517335146159075\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 46: train loss 0.0064853159710764885, accuracy 0.9551325628823929\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 6: train loss 1.0546685457229614, accuracy 0.5676410605030592\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.024456949904561043, accuracy 0.893949694085656\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 13: train loss 0.018198002129793167, accuracy 0.9123045547246771\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 21: train loss 0.012134231626987457, accuracy 0.9333786539768865\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 30: train loss 0.00835003238171339, accuracy 0.938817131203263\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 35: train loss 0.007070369087159634, accuracy 0.9503738953093134\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 43: train loss 0.005917329341173172, accuracy 0.9571719918422842\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:47:58,295 | server.py:232 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:47:58,321 | server.py:168 | evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:47:58,580 | server.py:182 | evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:47:58,584 | server.py:218 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 50: train loss 0.006189210340380669, accuracy 0.9483344663494222\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.971676766872406, accuracy 0.6295037389530931\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.3360671401023865, accuracy 0.7117607070020394\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 14: train loss 0.006934737786650658, accuracy 0.9415363698164514\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 23: train loss 0.005294730421155691, accuracy 0.9496940856560163\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 28: train loss 0.00513831852003932, accuracy 0.9551325628823929\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 0.004268130287528038, accuracy 0.95581237253569\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 46: train loss 0.0036855642683804035, accuracy 0.9626104690686608\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 1: train loss 6.216245651245117, accuracy 0.33242692046227057\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 11: train loss 0.011138022877275944, accuracy 0.9272603670972128\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.011138022877275944, accuracy 0.9272603670972128\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 17: train loss 0.00857976358383894, accuracy 0.9462950373895309\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 25: train loss 0.006401308812201023, accuracy 0.9415363698164514\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 34: train loss 0.0053534009493887424, accuracy 0.9442556084296397\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.005239305552095175, accuracy 0.9524133242692047\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 47: train loss 0.004112049005925655, accuracy 0.9510537049626104\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:49:09,802 | server.py:232 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:49:09,830 | server.py:168 | evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:49:10,053 | server.py:182 | evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:49:10,061 | server.py:218 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.04383727163076401, accuracy 0.8647178789938818\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 10: train loss 0.007396058179438114, accuracy 0.947654656696125\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.007283891551196575, accuracy 0.947654656696125\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 13: train loss 0.00547473318874836, accuracy 0.9517335146159075\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 19: train loss 0.004407838452607393, accuracy 0.9544527532290958\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 24: train loss 0.004267077427357435, accuracy 0.9571719918422842\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 32: train loss 0.003190735587850213, accuracy 0.9619306594153637\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 39: train loss 0.0027585632633417845, accuracy 0.9666893269884432\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 48: train loss 0.0026984973810613155, accuracy 0.9680489462950373\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.013349783606827259, accuracy 0.9408565601631543\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 7: train loss 0.00970900896936655, accuracy 0.9490142760027193\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 14: train loss 0.004286591894924641, accuracy 0.964649898028552\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 24: train loss 0.0030367602594196796, accuracy 0.9687287559483345\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 31: train loss 0.002860965207219124, accuracy 0.9687287559483345\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.00239670742303133, accuracy 0.972807613868117\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 48: train loss 0.002049797447398305, accuracy 0.9768864717878993\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:50:16,782 | server.py:232 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:50:16,812 | server.py:168 | evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:50:17,034 | server.py:182 | evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:50:17,038 | server.py:218 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 4: train loss 0.015503942035138607, accuracy 0.9313392250169953\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 6: train loss 0.0037317010574042797, accuracy 0.9707681849082257\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 13: train loss 0.0020902659744024277, accuracy 0.9748470428280082\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 23: train loss 0.0016582370735704899, accuracy 0.9789259007477906\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 29: train loss 0.0020309370011091232, accuracy 0.9687287559483345\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 38: train loss 0.0017762081697583199, accuracy 0.9707681849082257\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 48: train loss 0.0014767262618988752, accuracy 0.9714479945615228\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 4: train loss 0.015286579728126526, accuracy 0.9360978925900748\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.006048860028386116, accuracy 0.9619306594153637\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 14: train loss 0.001945107476785779, accuracy 0.973487423521414\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 22: train loss 0.0021546236239373684, accuracy 0.9694085656016316\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 30: train loss 0.0015560068422928452, accuracy 0.9762066621346023\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 38: train loss 0.0016624280251562595, accuracy 0.9741672331747111\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 47: train loss 0.0014823954552412033, accuracy 0.9768864717878993\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:51:22,288 | server.py:232 | fit_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:51:22,320 | server.py:168 | evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:51:22,643 | server.py:182 | evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:51:22,647 | server.py:218 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 4: train loss 0.006755786016583443, accuracy 0.9612508497620667\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.001854122499935329, accuracy 0.9802855200543847\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 14: train loss 0.0014893426559865475, accuracy 0.981645139360979\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 22: train loss 0.0017038504593074322, accuracy 0.9721278042148198\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 29: train loss 0.0015176251763477921, accuracy 0.972807613868117\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 41: train loss 0.0011529921321198344, accuracy 0.9809653297076818\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 48: train loss 0.001063709962181747, accuracy 0.9809653297076818\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 3: train loss 0.01617293991148472, accuracy 0.9129843643779741\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 10: train loss 0.0023475689813494682, accuracy 0.9755268524813052\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 14: train loss 0.0015524730551987886, accuracy 0.9782460910944936\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 21: train loss 0.0014468432636931539, accuracy 0.9802855200543847\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 30: train loss 0.0013896505115553737, accuracy 0.981645139360979\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.0013520948123186827, accuracy 0.9802855200543847\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 46: train loss 0.0013274259399622679, accuracy 0.9789259007477906\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:52:26,181 | server.py:232 | fit_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:52:26,211 | server.py:168 | evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:52:26,438 | server.py:182 | evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:52:26,444 | server.py:218 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 5: train loss 0.001417724066413939, accuracy 0.9755268524813052\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 10: train loss 0.0011564192827790976, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0011564192827790976, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 15: train loss 0.0010691072093322873, accuracy 0.9775662814411965\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 20: train loss 0.0010803967015817761, accuracy 0.9789259007477906\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 30: train loss 0.0008322359644807875, accuracy 0.9802855200543847\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.0007410632679238915, accuracy 0.9843643779741672\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 45: train loss 0.000715704751200974, accuracy 0.9843643779741672\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 5: train loss 0.001726334448903799, accuracy 0.9748470428280082\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.0012423633597791195, accuracy 0.9789259007477906\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 14: train loss 0.0011551521020010114, accuracy 0.9789259007477906\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 20: train loss 0.0009719064692035317, accuracy 0.9830047586675731\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 30: train loss 0.0011498547391965985, accuracy 0.9782460910944936\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 38: train loss 0.0007635526126250625, accuracy 0.9850441876274643\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 46: train loss 0.0009540722239762545, accuracy 0.9802855200543847\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:53:29,970 | server.py:232 | fit_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:53:30,001 | server.py:168 | evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:53:30,233 | server.py:182 | evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:53:30,241 | server.py:218 | fit_round 12: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 3: train loss 0.0020297567825764418, accuracy 0.9789259007477906\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0011619905708357692, accuracy 0.981645139360979\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 12: train loss 0.001092681661248207, accuracy 0.982324949014276\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 18: train loss 0.0007461493951268494, accuracy 0.982324949014276\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 0.0006365685258060694, accuracy 0.9843643779741672\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 37: train loss 0.0005796843906864524, accuracy 0.9870836165873556\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 43: train loss 0.0004690159694291651, accuracy 0.9857239972807614\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 3: train loss 0.0015452997758984566, accuracy 0.9789259007477906\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 9: train loss 0.0009992425329983234, accuracy 0.982324949014276\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 11: train loss 0.0010262937285006046, accuracy 0.9809653297076818\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 20: train loss 0.0009916059207171202, accuracy 0.9782460910944936\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 30: train loss 0.0008313987054862082, accuracy 0.9836845683208701\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 34: train loss 0.0006179676856845617, accuracy 0.9864038069340585\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 41: train loss 0.0006403586594387889, accuracy 0.9850441876274643\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:54:33,796 | server.py:232 | fit_round 12 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:54:33,824 | server.py:168 | evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:54:34,060 | server.py:182 | evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:54:34,070 | server.py:218 | fit_round 13: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 1: train loss 0.049305323511362076, accuracy 0.8484024473147519\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 7: train loss 0.001013685017824173, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 0.001013685017824173, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 8: train loss 0.0007314741960726678, accuracy 0.981645139360979\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 15: train loss 0.0007369574741460383, accuracy 0.982324949014276\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 26: train loss 0.0005382433300837874, accuracy 0.9864038069340585\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 0.0005168409552425146, accuracy 0.9884432358939497\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 34: train loss 0.0006022067391313612, accuracy 0.9857239972807614\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 43: train loss 0.0005534107913263142, accuracy 0.9864038069340585\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.000675212882924825, accuracy 0.9870836165873556\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 3: train loss 0.0013417572481557727, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 13: train loss 0.0006941097672097385, accuracy 0.9857239972807614\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 17: train loss 0.0006089369999244809, accuracy 0.9836845683208701\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 25: train loss 0.0005028090672567487, accuracy 0.9870836165873556\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 39: train loss 0.0004430720000527799, accuracy 0.9932019034670292\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 49: train loss 0.000388680724427104, accuracy 0.9938817131203264\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:55:40,942 | server.py:232 | fit_round 13 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:55:40,982 | server.py:168 | evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:55:41,312 | server.py:182 | evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:55:41,317 | server.py:218 | fit_round 14: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 1: train loss 0.028496436774730682, accuracy 0.9082256968048946\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 0.0007989196456037462, accuracy 0.9843643779741672\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 9: train loss 0.0006625743699260056, accuracy 0.9870836165873556\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 19: train loss 0.00047844284563325346, accuracy 0.9870836165873556\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 26: train loss 0.0004440025659278035, accuracy 0.9898028552005439\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 34: train loss 0.0007372054969891906, accuracy 0.9843643779741672\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 45: train loss 0.0002794187457766384, accuracy 0.9959211420802175\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 0.00195623398758471, accuracy 0.9707681849082257\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 0.0010159214725717902, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0006123972707428038, accuracy 0.9836845683208701\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 20: train loss 0.0006846637115813792, accuracy 0.9830047586675731\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 26: train loss 0.00036386612919159234, accuracy 0.9891230455472467\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 35: train loss 0.0006070341332815588, accuracy 0.9857239972807614\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 44: train loss 0.0006707508582621813, accuracy 0.9843643779741672\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:56:44,923 | server.py:232 | fit_round 14 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:56:44,963 | server.py:168 | evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 50: train loss 0.0005809819558635354, accuracy 0.9864038069340585\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:56:45,329 | server.py:182 | evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:56:45,337 | server.py:218 | fit_round 15: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 8: train loss 0.0003601029748097062, accuracy 0.9891230455472467\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0004567427677102387, accuracy 0.9877634262406526\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 19: train loss 0.0003930920211132616, accuracy 0.9918422841604351\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 25: train loss 0.0003321107942610979, accuracy 0.9918422841604351\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 32: train loss 0.0003869548672810197, accuracy 0.9884432358939497\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 45: train loss 0.00024514846154488623, accuracy 0.9952413324269205\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 47: train loss 0.0007334224064834416, accuracy 0.9830047586675731\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.0005711762933060527, accuracy 0.9898028552005439\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.00041816962766461074, accuracy 0.9938817131203264\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 16: train loss 0.0006756948423571885, accuracy 0.982324949014276\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 0.0002895304060075432, accuracy 0.9952413324269205\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 31: train loss 0.0008283760980702937, accuracy 0.9836845683208701\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.0008241390460170805, accuracy 0.981645139360979\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 49: train loss 0.0010085456306114793, accuracy 0.9809653297076818\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:57:48,424 | server.py:232 | fit_round 15 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:57:48,454 | server.py:168 | evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:57:48,688 | server.py:182 | evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:57:48,692 | server.py:218 | fit_round 16: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.00045501638669520617, accuracy 0.9918422841604351\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.00042211648542433977, accuracy 0.9884432358939497\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 18: train loss 0.00048027292359620333, accuracy 0.9870836165873556\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 26: train loss 0.0004347182693891227, accuracy 0.9884432358939497\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 36: train loss 0.00027264381060376763, accuracy 0.9966009517335146\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 44: train loss 0.0002217062865383923, accuracy 0.9972807613868117\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 3: train loss 0.00102030741982162, accuracy 0.9809653297076818\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.0005674485582858324, accuracy 0.9864038069340585\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 13: train loss 0.00047619605902582407, accuracy 0.9857239972807614\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 20: train loss 0.0008749250555410981, accuracy 0.981645139360979\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 26: train loss 0.001086211996152997, accuracy 0.9802855200543847\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 38: train loss 0.0009220332140102983, accuracy 0.9796057104010877\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 42: train loss 0.0005488747847266495, accuracy 0.9877634262406526\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:58:50,658 | server.py:232 | fit_round 16 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:58:50,692 | server.py:168 | evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:58:50,945 | server.py:182 | evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:58:50,949 | server.py:218 | fit_round 17: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 1: train loss 0.003636428155004978, accuracy 0.9707681849082257\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 10: train loss 0.00044303646427579224, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0005565562169067562, accuracy 0.9877634262406526\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.0007452541613020003, accuracy 0.982324949014276\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 18: train loss 0.0014286686200648546, accuracy 0.9741672331747111\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 26: train loss 0.00036244155489839613, accuracy 0.9891230455472467\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 36: train loss 0.00035722265602089465, accuracy 0.9938817131203264\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 42: train loss 0.000364577368600294, accuracy 0.9925220938137321\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 4: train loss 0.000651779118925333, accuracy 0.9830047586675731\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.0007178758387453854, accuracy 0.9830047586675731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 11: train loss 0.0005791281582787633, accuracy 0.9870836165873556\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 17: train loss 0.0005953970248810947, accuracy 0.9864038069340585\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 31: train loss 0.0009621934732422233, accuracy 0.9802855200543847\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.0003372524806763977, accuracy 0.990482664853841\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 47: train loss 0.0007906703394837677, accuracy 0.982324949014276\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 15:59:53,564 | server.py:232 | fit_round 17 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:59:53,592 | server.py:168 | evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 15:59:53,820 | server.py:182 | evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 15:59:53,823 | server.py:218 | fit_round 18: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 0.001498769037425518, accuracy 0.9809653297076818\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.0006031557568348944, accuracy 0.991162474507138\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 10: train loss 0.0005893247434869409, accuracy 0.991162474507138\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 17: train loss 0.0004926820984110236, accuracy 0.991162474507138\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 27: train loss 0.0003906860074494034, accuracy 0.9918422841604351\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 34: train loss 0.0010664565488696098, accuracy 0.9802855200543847\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 42: train loss 0.0002720404008869082, accuracy 0.9959211420802175\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 49: train loss 0.0002934354415629059, accuracy 0.9959211420802175\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 4: train loss 0.0018700603395700455, accuracy 0.9721278042148198\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 5: train loss 0.0021619447506964207, accuracy 0.9694085656016316\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 12: train loss 0.0007216267404146492, accuracy 0.9843643779741672\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 22: train loss 0.001260444987565279, accuracy 0.972807613868117\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 29: train loss 0.0015034435782581568, accuracy 0.9741672331747111\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.0007778627332299948, accuracy 0.9809653297076818\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 50: train loss 0.00043815156095661223, accuracy 0.9877634262406526\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:00:58,552 | server.py:232 | fit_round 18 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:00:58,578 | server.py:168 | evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:00:58,815 | server.py:182 | evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:00:58,817 | server.py:218 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 4: train loss 0.0004897647886537015, accuracy 0.9877634262406526\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 5: train loss 0.0004423514474183321, accuracy 0.991162474507138\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 13: train loss 0.00033398676896467805, accuracy 0.9925220938137321\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 21: train loss 0.0003016386763192713, accuracy 0.9932019034670292\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 29: train loss 0.0002322381769772619, accuracy 0.9925220938137321\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 38: train loss 0.00020103111455682665, accuracy 0.9952413324269205\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 45: train loss 0.0003835067036561668, accuracy 0.990482664853841\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 1: train loss 0.002630349714308977, accuracy 0.9748470428280082\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.00035743016633205116, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 11: train loss 0.0008084525470621884, accuracy 0.9877634262406526\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 23: train loss 0.0003578942851163447, accuracy 0.9945615227736234\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 26: train loss 0.0003205501416232437, accuracy 0.9945615227736234\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 0.00025455813738517463, accuracy 0.9959211420802175\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 46: train loss 0.00021348091831896454, accuracy 0.9966009517335146\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:02:04,239 | server.py:232 | fit_round 19 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:02:04,266 | server.py:168 | evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:02:04,500 | server.py:182 | evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:02:04,506 | server.py:218 | fit_round 20: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 0.0006232655723579228, accuracy 0.9891230455472467\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.000705897284206003, accuracy 0.9870836165873556\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 13: train loss 0.00036625369102694094, accuracy 0.9925220938137321\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 20: train loss 0.0005575413815677166, accuracy 0.9891230455472467\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 31: train loss 0.0005374685279093683, accuracy 0.9830047586675731\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 0.0002730382839217782, accuracy 0.9925220938137321\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 48: train loss 0.0002502636343706399, accuracy 0.9932019034670292\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 0.00048770784633234143, accuracy 0.9932019034670292\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.00041285515180788934, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 17: train loss 0.00022267235908657312, accuracy 0.9945615227736234\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 23: train loss 0.00018772721523419023, accuracy 0.9966009517335146\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 27: train loss 0.00017689965898171067, accuracy 0.9972807613868117\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 43: train loss 0.00014109718904364854, accuracy 0.9993201903467029\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 49: train loss 0.00013234076322987676, accuracy 0.9993201903467029\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:03:07,657 | server.py:232 | fit_round 20 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:03:07,688 | server.py:168 | evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:03:07,904 | server.py:182 | evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:03:07,909 | server.py:218 | fit_round 21: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 21: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 3: train loss 0.0006831538630649447, accuracy 0.9857239972807614\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.0008293213322758675, accuracy 0.981645139360979\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 12: train loss 0.0002445880963932723, accuracy 0.9932019034670292\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 18: train loss 0.00035021448275074363, accuracy 0.9925220938137321\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 27: train loss 0.0004403959901537746, accuracy 0.9877634262406526\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 37: train loss 0.00025772509980015457, accuracy 0.9952413324269205\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 41: train loss 0.0003759430255740881, accuracy 0.990482664853841\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 50: train loss 0.00023463756951969117, accuracy 0.9959211420802175\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 0.0009530516690574586, accuracy 0.9864038069340585\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.0008624190813861787, accuracy 0.9870836165873556\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 17: train loss 0.0008453081827610731, accuracy 0.9775662814411965\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 25: train loss 0.00027835858054459095, accuracy 0.9959211420802175\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 34: train loss 0.0004184004501439631, accuracy 0.9877634262406526\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 41: train loss 0.0004574514168780297, accuracy 0.9870836165873556\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 50: train loss 0.0004923807573504746, accuracy 0.9857239972807614\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:04:13,462 | server.py:232 | fit_round 21 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 21 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:04:13,497 | server.py:168 | evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:04:13,767 | server.py:182 | evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:04:13,771 | server.py:218 | fit_round 22: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 22: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.0004336513811722398, accuracy 0.9877634262406526\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 6: train loss 0.00014054602070245892, accuracy 0.9972807613868117\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 6: train loss 0.00014054602070245892, accuracy 0.9972807613868117\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 12: train loss 0.0001070643265848048, accuracy 0.9979605710401088\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 21: train loss 8.359728963114321e-05, accuracy 0.9979605710401088\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 5.307268293108791e-05, accuracy 0.9993201903467029\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 34: train loss 0.00013281729479786009, accuracy 0.9966009517335146\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 44: train loss 4.279767017578706e-05, accuracy 1.0\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 1: train loss 0.0014069774188101292, accuracy 0.9809653297076818\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 7: train loss 0.00038691985537298024, accuracy 0.991162474507138\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 8: train loss 0.000431862601544708, accuracy 0.9898028552005439\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 18: train loss 0.0002787509292829782, accuracy 0.9925220938137321\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 24: train loss 0.00034154526656493545, accuracy 0.9918422841604351\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 32: train loss 0.0015563881024718285, accuracy 0.981645139360979\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 42: train loss 0.0005145826144143939, accuracy 0.9870836165873556\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 48: train loss 0.0006448281346820295, accuracy 0.9843643779741672\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:05:22,699 | server.py:232 | fit_round 22 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 22 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:05:22,730 | server.py:168 | evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:05:22,964 | server.py:182 | evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:05:22,969 | server.py:218 | fit_round 23: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 23: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 5: train loss 0.0010011300910264254, accuracy 0.9884432358939497\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.0005079598631709814, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 15: train loss 0.0003607826947700232, accuracy 0.9952413324269205\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 19: train loss 6.831204518675804e-05, accuracy 0.9993201903467029\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 30: train loss 0.00024209180264733732, accuracy 0.9979605710401088\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 36: train loss 3.8939622754696757e-05, accuracy 1.0\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 40: train loss 4.010056363767944e-05, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 44: train loss 3.285475759184919e-05, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 7: train loss 0.000821369350887835, accuracy 0.9768864717878993\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 4: train loss 0.000243825648794882, accuracy 0.9952413324269205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 16: train loss 0.0006939158192835748, accuracy 0.9836845683208701\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 21: train loss 0.0007884549559094012, accuracy 0.9843643779741672\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 25: train loss 0.0007495470927096903, accuracy 0.9836845683208701\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 40: train loss 0.00019105503452010453, accuracy 0.9966009517335146\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 46: train loss 0.0001522561942692846, accuracy 0.9966009517335146\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:06:33,605 | server.py:232 | fit_round 23 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 23 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:06:33,635 | server.py:168 | evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:06:33,873 | server.py:182 | evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:06:33,882 | server.py:218 | fit_round 24: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 24: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 1: train loss 0.0008518219110555947, accuracy 0.9843643779741672\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 9: train loss 0.00027792705805040896, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 10: train loss 0.00020481483079493046, accuracy 0.9966009517335146\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 16: train loss 0.0015744116390123963, accuracy 0.9870836165873556\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 26: train loss 0.0001736422855174169, accuracy 0.9959211420802175\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 35: train loss 0.00017414598551113158, accuracy 0.9966009517335146\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 42: train loss 0.00017189179197885096, accuracy 0.9959211420802175\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 2: train loss 0.00114624691195786, accuracy 0.9830047586675731\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 9: train loss 0.000215679217944853, accuracy 0.9945615227736234\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 10: train loss 8.182710007531568e-05, accuracy 0.9986403806934059\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 18: train loss 3.221551378373988e-05, accuracy 1.0\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 9.374802903039381e-05, accuracy 0.9979605710401088\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 34: train loss 1.6233458154601976e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 43: train loss 1.481627896282589e-05, accuracy 1.0\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:07:36,955 | server.py:232 | fit_round 24 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 24 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:07:36,982 | server.py:168 | evaluate_round 24: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 24: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:07:37,214 | server.py:182 | evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:07:37,217 | server.py:218 | fit_round 25: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 25: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 2: train loss 0.00034021015744656324, accuracy 0.9918422841604351\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66075)\u001b[0m Epoch 6: train loss 0.000376142532331869, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 7: train loss 0.0003283922851551324, accuracy 0.9918422841604351\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 8: train loss 0.0005016279756091535, accuracy 0.9843643779741672\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 17: train loss 4.4714321120409295e-05, accuracy 0.9993201903467029\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 28: train loss 0.00033662031637504697, accuracy 0.990482664853841\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 32: train loss 1.9346041881362908e-05, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 43: train loss 0.0005244086496531963, accuracy 0.9884432358939497\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66075)\u001b[0m Epoch 2: train loss 0.00039007337181828916, accuracy 0.991162474507138\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 4: train loss 0.0006410633795894682, accuracy 0.9891230455472467\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 6: train loss 0.0009246635599993169, accuracy 0.9864038069340585\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 16: train loss 0.00020007893908768892, accuracy 0.9972807613868117\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 25: train loss 0.00015851655916776508, accuracy 0.9986403806934059\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 31: train loss 0.00013898957695346326, accuracy 0.9986403806934059\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 41: train loss 8.759785123402253e-05, accuracy 0.9993201903467029\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:08:41,881 | server.py:232 | fit_round 25 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 25 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:08:41,909 | server.py:168 | evaluate_round 25: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 25: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=66074)\u001b[0m Epoch 50: train loss 4.169396197539754e-05, accuracy 0.9993201903467029\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:08:42,259 | server.py:182 | evaluate_round 25 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 25 received 3 results and 0 failures\n",
            "INFO flwr 2023-06-08 16:08:42,269 | server.py:147 | FL finished in 1611.4080076070004\n",
            "INFO:flwr:FL finished in 1611.4080076070004\n",
            "INFO flwr 2023-06-08 16:08:42,271 | app.py:218 | app_fit: losses_distributed [(1, 0.33060853769300635), (2, 0.1589464123524069), (3, 0.33787465940054495), (4, 0.33242506811989103), (5, 0.33969118982742963), (6, 0.3224341507720254), (7, 0.33605812897366033), (8, 0.33424159854677565), (9, 0.4977293369663942), (10, 0.39782016348773847), (11, 0.5413260672116258), (12, 0.5594913714804723), (13, 0.7184377838328793), (14, 0.8138056312443234), (15, 0.8501362397820164), (16, 0.9291553133514986), (17, 0.8819255222524977), (18, 0.9409627611262488), (19, 0.9336966394187102), (20, 0.9464123524069028), (21, 0.9464123524069028), (22, 0.9418710263396911), (23, 0.9391462306993641), (24, 0.9436875567665758), (25, 0.9346049046321525)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.33060853769300635), (2, 0.1589464123524069), (3, 0.33787465940054495), (4, 0.33242506811989103), (5, 0.33969118982742963), (6, 0.3224341507720254), (7, 0.33605812897366033), (8, 0.33424159854677565), (9, 0.4977293369663942), (10, 0.39782016348773847), (11, 0.5413260672116258), (12, 0.5594913714804723), (13, 0.7184377838328793), (14, 0.8138056312443234), (15, 0.8501362397820164), (16, 0.9291553133514986), (17, 0.8819255222524977), (18, 0.9409627611262488), (19, 0.9336966394187102), (20, 0.9464123524069028), (21, 0.9464123524069028), (22, 0.9418710263396911), (23, 0.9391462306993641), (24, 0.9436875567665758), (25, 0.9346049046321525)]\n",
            "INFO flwr 2023-06-08 16:08:42,273 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-08 16:08:42,275 | app.py:220 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-06-08 16:08:42,277 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-08 16:08:42,279 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-06-08 16:08:43,198 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing Strategy... :  Fedadam\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=66074)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=66075)\u001b[0m 2023-06-08 15:41:53.347115: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-08 16:08:48,729\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-08 16:08:50,382 | app.py:180 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7845548852.0, 'GPU': 1.0, 'object_store_memory': 3922774425.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7845548852.0, 'GPU': 1.0, 'object_store_memory': 3922774425.0}\n",
            "INFO flwr 2023-06-08 16:08:50,394 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-08 16:08:50,399 | server.py:269 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-06-08 16:08:50,410 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-08 16:08:50,411 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-08 16:08:50,418 | server.py:218 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "\u001b[2m\u001b[36m(pid=78560)\u001b[0m 2023-06-08 16:08:52.722504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 1: train loss 0.025287846103310585, accuracy 0.3834126444595513\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 15: train loss 0.004523782525211573, accuracy 0.9048266485384092\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 16: train loss 0.004263606853783131, accuracy 0.9068660774983005\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 31: train loss 0.0019592943135648966, accuracy 0.964649898028552\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 39: train loss 0.0014542128192260861, accuracy 0.9755268524813052\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 3: train loss 0.015523104928433895, accuracy 0.7450713800135962\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 0.0051866937428712845, accuracy 0.8966689326988443\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 18: train loss 0.003642058465629816, accuracy 0.9225016995241332\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 27: train loss 0.0023915187921375036, accuracy 0.9524133242692047\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 41: train loss 0.0014665225753560662, accuracy 0.9700883752549286\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:09:40,174 | server.py:232 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-06-08 16:09:40,202 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 16:09:40,217 | server.py:168 | evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:09:40,500 | server.py:182 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-06-08 16:09:40,514 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 16:09:40,516 | server.py:218 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 2: train loss 6.072853088378906, accuracy 0.5173351461590755\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 0.0765429213643074, accuracy 0.9503738953093134\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 9: train loss 0.07230735570192337, accuracy 0.946974847042828\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 21: train loss 0.0498262383043766, accuracy 0.9578518014955812\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 32: train loss 0.04966406524181366, accuracy 0.9524133242692047\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 39: train loss 0.045809969305992126, accuracy 0.9544527532290958\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 1: train loss 16.090145111083984, accuracy 0.40720598232494903\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 11: train loss 0.06446319073438644, accuracy 0.9422161794697484\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 0.06446319073438644, accuracy 0.9422161794697484\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 19: train loss 0.05069330707192421, accuracy 0.95581237253569\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 31: train loss 0.05083157494664192, accuracy 0.9524133242692047\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 40: train loss 0.04835417866706848, accuracy 0.9530931339225017\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 49: train loss 0.041039761155843735, accuracy 0.9578518014955812\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:10:35,004 | server.py:232 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:10:35,041 | server.py:168 | evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:10:35,276 | server.py:182 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:10:35,281 | server.py:218 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 321.13897705078125, accuracy 0.460231135282121\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 261.13494873046875, accuracy 0.4677090414683889\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 22: train loss 116.7388687133789, accuracy 0.4724677090414684\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 33: train loss 4.190481662750244, accuracy 0.8470428280081577\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 47: train loss 0.39594566822052, accuracy 0.9354180829367778\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 390.54779052734375, accuracy 0.47314751869476546\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 10: train loss 344.7510986328125, accuracy 0.46430999320190347\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 18: train loss 190.52285766601562, accuracy 0.46498980285520053\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 27: train loss 39.42681884765625, accuracy 0.5635622025832767\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 38: train loss 0.9408987164497375, accuracy 0.919782460910945\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 49: train loss 0.45046377182006836, accuracy 0.9354180829367778\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:11:21,359 | server.py:232 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:11:21,387 | server.py:168 | evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:11:21,629 | server.py:182 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:11:21,632 | server.py:218 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 12: train loss 42.213897705078125, accuracy 0.707681849082257\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 14: train loss 29.37984275817871, accuracy 0.7307953772943576\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 29.37984275817871, accuracy 0.7307953772943576\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 22: train loss 0.6992528438568115, accuracy 0.9082256968048946\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 34: train loss 0.4073590934276581, accuracy 0.9326988443235894\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 48: train loss 0.27437320351600647, accuracy 0.9483344663494222\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 8: train loss 79.86028289794922, accuracy 0.4262406526172672\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 81.63729858398438, accuracy 0.4276002719238613\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 19: train loss 1.0563204288482666, accuracy 0.8789938817131203\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 32: train loss 0.48727643489837646, accuracy 0.9299796057104011\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 43: train loss 0.3452294170856476, accuracy 0.9456152277362339\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:12:06,177 | server.py:232 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:12:06,204 | server.py:168 | evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:12:06,440 | server.py:182 | evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:12:06,447 | server.py:218 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 1: train loss 528.5186767578125, accuracy 0.13528212100611828\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 206.58226013183594, accuracy 0.3161114887831407\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 16: train loss 181.93157958984375, accuracy 0.3487423521414004\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 27: train loss 91.7786865234375, accuracy 0.44391570360299115\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 38: train loss 21.84048080444336, accuracy 0.6220258327668253\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 2: train loss 487.55694580078125, accuracy 0.1441196464989803\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 12: train loss 238.9990234375, accuracy 0.30659415363698167\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 223.5491943359375, accuracy 0.30727396329027873\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 24: train loss 114.80709075927734, accuracy 0.4276002719238613\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 38: train loss 24.185056686401367, accuracy 0.6131883072739633\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 47: train loss 0.8007611036300659, accuracy 0.8837525492861998\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:12:50,738 | server.py:232 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:12:50,781 | server.py:168 | evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:12:51,068 | server.py:182 | evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:12:51,071 | server.py:218 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 72.00362396240234, accuracy 0.611148878314072\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 29.118980407714844, accuracy 0.6261046906866078\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 20: train loss 2.9684665203094482, accuracy 0.8198504418762746\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 31: train loss 0.4134981632232666, accuracy 0.9367777022433719\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 41: train loss 0.33427694439888, accuracy 0.938137321549966\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 5: train loss 86.55662536621094, accuracy 0.5567641060503059\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 12: train loss 35.76538848876953, accuracy 0.6342624065261727\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 15: train loss 18.28382110595703, accuracy 0.6573759347382733\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 25: train loss 0.6522310972213745, accuracy 0.9252209381373215\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 39: train loss 0.3408591151237488, accuracy 0.9449354180829368\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 49: train loss 0.308334082365036, accuracy 0.947654656696125\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:13:35,770 | server.py:232 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:13:35,812 | server.py:168 | evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:13:36,174 | server.py:182 | evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:13:36,180 | server.py:218 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 10: train loss 33.4634895324707, accuracy 0.5853161114887832\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 19.803245544433594, accuracy 0.7946974847042828\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 23: train loss 2.885058641433716, accuracy 0.8932698844323589\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 33: train loss 0.9015159606933594, accuracy 0.9354180829367778\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 44: train loss 0.6576376557350159, accuracy 0.9394969408565602\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 59.77995300292969, accuracy 0.5118966689326988\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 21.020578384399414, accuracy 0.7865397688647179\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 17: train loss 10.851299285888672, accuracy 0.82324949014276\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 28: train loss 1.2351186275482178, accuracy 0.9218218898708361\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 42: train loss 0.5391883254051208, accuracy 0.9401767505098573\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:14:22,184 | server.py:232 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:14:22,223 | server.py:168 | evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 50: train loss 0.5517347455024719, accuracy 0.947654656696125\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:14:22,579 | server.py:182 | evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:14:22,589 | server.py:218 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 118.32623291015625, accuracy 0.4554724677090415\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 12: train loss 101.54720306396484, accuracy 0.5227736233854521\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 25: train loss 24.045053482055664, accuracy 0.8069340584636302\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 34: train loss 4.723576545715332, accuracy 0.9000679809653297\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 45: train loss 1.2866798639297485, accuracy 0.9354180829367778\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 222.27430725097656, accuracy 0.29979605710401086\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 12: train loss 99.6824722290039, accuracy 0.522093813732155\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 16: train loss 63.131507873535156, accuracy 0.6784500339904826\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 29: train loss 12.638144493103027, accuracy 0.8450033990482665\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 42: train loss 2.1692733764648438, accuracy 0.9231815091774304\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:15:08,175 | server.py:232 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:15:08,209 | server.py:168 | evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:15:08,542 | server.py:182 | evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:15:08,545 | server.py:218 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 50: train loss 1.0617337226867676, accuracy 0.9435757987763427\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 28.357425689697266, accuracy 0.7851801495581238\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 12: train loss 23.4801082611084, accuracy 0.8096532970768185\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 25: train loss 3.459787607192993, accuracy 0.919782460910945\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 35: train loss 1.6392245292663574, accuracy 0.9394969408565602\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 45: train loss 1.4627424478530884, accuracy 0.9401767505098573\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 10: train loss 34.37400436401367, accuracy 0.761386811692726\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 14: train loss 15.91204833984375, accuracy 0.8361658735554045\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 19: train loss 6.8064751625061035, accuracy 0.8919102651257648\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 31: train loss 1.5994071960449219, accuracy 0.9354180829367778\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 44: train loss 1.1252434253692627, accuracy 0.9442556084296397\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:15:53,030 | server.py:232 | fit_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:15:53,069 | server.py:168 | evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:15:53,398 | server.py:182 | evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:15:53,407 | server.py:218 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 2: train loss 90.33771514892578, accuracy 0.5227736233854521\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 10: train loss 3.810103178024292, accuracy 0.9129843643779741\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 11: train loss 3.3144381046295166, accuracy 0.9184228416043508\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 14: train loss 2.5212438106536865, accuracy 0.9313392250169953\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 27: train loss 1.5028941631317139, accuracy 0.9408565601631543\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 37: train loss 1.6278657913208008, accuracy 0.9435757987763427\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 48: train loss 1.1881781816482544, accuracy 0.9483344663494222\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 2.6431119441986084, accuracy 0.929299796057104\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 2.4814651012420654, accuracy 0.9306594153636981\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 19: train loss 1.5236709117889404, accuracy 0.9442556084296397\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 27: train loss 1.89578378200531, accuracy 0.938817131203263\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 40: train loss 1.6832642555236816, accuracy 0.9422161794697484\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:16:40,630 | server.py:232 | fit_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:16:40,663 | server.py:168 | evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:16:40,904 | server.py:182 | evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:16:40,910 | server.py:218 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 1: train loss 452.185791015625, accuracy 0.29843643779741674\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 221.78350830078125, accuracy 0.6179469748470429\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 9: train loss 197.26393127441406, accuracy 0.619986403806934\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 23: train loss 8.845409393310547, accuracy 0.8857919782460911\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 36: train loss 2.3996944427490234, accuracy 0.938817131203263\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 43: train loss 1.5656172037124634, accuracy 0.9422161794697484\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 7: train loss 245.7357940673828, accuracy 0.6043507817811012\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 98.50708770751953, accuracy 0.6390210740992522\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 20: train loss 14.569235801696777, accuracy 0.8443235893949694\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 28: train loss 3.039592981338501, accuracy 0.9259007477906186\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 42: train loss 2.0646555423736572, accuracy 0.9422161794697484\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:17:26,318 | server.py:232 | fit_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:17:26,346 | server.py:168 | evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:17:26,579 | server.py:182 | evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:17:26,589 | server.py:218 | fit_round 12: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 4: train loss 262.13372802734375, accuracy 0.5254928619986404\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 9: train loss 112.84611511230469, accuracy 0.6301835486063903\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 34.873680114746094, accuracy 0.7756628144119646\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 26: train loss 3.717679738998413, accuracy 0.9272603670972128\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 38: train loss 1.9710323810577393, accuracy 0.9449354180829368\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 46: train loss 1.818274736404419, accuracy 0.9530931339225017\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 9: train loss 116.1333999633789, accuracy 0.6261046906866078\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 35.74872970581055, accuracy 0.7641060503059144\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 22: train loss 5.04250955581665, accuracy 0.9191026512576479\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 30: train loss 1.9750614166259766, accuracy 0.9415363698164514\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 43: train loss 1.2514228820800781, accuracy 0.9510537049626104\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:18:12,392 | server.py:232 | fit_round 12 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:18:12,423 | server.py:168 | evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:18:12,648 | server.py:182 | evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:18:12,651 | server.py:218 | fit_round 13: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 4: train loss 3.1026177406311035, accuracy 0.9354180829367778\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 8: train loss 2.0984580516815186, accuracy 0.9442556084296397\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 2.0984580516815186, accuracy 0.9442556084296397\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 1.9617668390274048, accuracy 0.9462950373895309\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 25: train loss 1.7084606885910034, accuracy 0.9537729435757988\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 38: train loss 1.509777545928955, accuracy 0.9578518014955812\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 45: train loss 1.4095646142959595, accuracy 0.95581237253569\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 8: train loss 1.6323013305664062, accuracy 0.9537729435757988\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 1.3691956996917725, accuracy 0.9544527532290958\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 21: train loss 1.3286283016204834, accuracy 0.9524133242692047\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 27: train loss 1.2359027862548828, accuracy 0.9537729435757988\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 41: train loss 1.0725533962249756, accuracy 0.9592114208021754\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:18:59,014 | server.py:232 | fit_round 13 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:18:59,044 | server.py:168 | evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:18:59,258 | server.py:182 | evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:18:59,265 | server.py:218 | fit_round 14: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 3: train loss 116.63851928710938, accuracy 0.6954452753229096\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 45.02592468261719, accuracy 0.8470428280081577\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 11: train loss 26.434696197509766, accuracy 0.8755948334466349\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 24: train loss 2.128161907196045, accuracy 0.9537729435757988\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 37: train loss 1.2994023561477661, accuracy 0.9578518014955812\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 45: train loss 1.2167909145355225, accuracy 0.9585316111488783\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 8: train loss 47.38469696044922, accuracy 0.849762066621346\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 15.490412712097168, accuracy 0.9102651257647859\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 21: train loss 4.746303081512451, accuracy 0.9503738953093134\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 29: train loss 2.1965444087982178, accuracy 0.9564921821889871\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 42: train loss 1.699263095855713, accuracy 0.9598912304554724\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:19:44,882 | server.py:232 | fit_round 14 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:19:44,925 | server.py:168 | evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:19:45,138 | server.py:182 | evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:19:45,149 | server.py:218 | fit_round 15: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 3: train loss 177.1691131591797, accuracy 0.7559483344663495\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 103.47081756591797, accuracy 0.8212100611828688\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 10: train loss 75.97073364257812, accuracy 0.8416043507817811\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 24: train loss 4.55340576171875, accuracy 0.9462950373895309\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 36: train loss 1.7792861461639404, accuracy 0.9639700883752549\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 43: train loss 1.6227070093154907, accuracy 0.9626104690686608\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 5: train loss 143.95960998535156, accuracy 0.7831407205982325\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 41.90172576904297, accuracy 0.8810333106730116\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 18: train loss 16.918214797973633, accuracy 0.9218218898708361\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 26: train loss 3.791663646697998, accuracy 0.9462950373895309\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 38: train loss 1.1991394758224487, accuracy 0.9639700883752549\u001b[32m [repeated 25x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:20:32,449 | server.py:232 | fit_round 15 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:20:32,480 | server.py:168 | evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:20:32,714 | server.py:182 | evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:20:32,726 | server.py:218 | fit_round 16: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 50: train loss 1.0496277809143066, accuracy 0.9673691366417403\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 16.830102920532227, accuracy 0.9218218898708361\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 16.830102920532227, accuracy 0.9218218898708361\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 21: train loss 1.3794158697128296, accuracy 0.9612508497620667\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 34: train loss 1.0571694374084473, accuracy 0.9653297076818491\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 41: train loss 0.9926565289497375, accuracy 0.9653297076818491\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 4: train loss 35.72026062011719, accuracy 0.8749150237933379\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 3.8972558975219727, accuracy 0.9503738953093134\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 17: train loss 2.0724551677703857, accuracy 0.9612508497620667\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 24: train loss 1.5600289106369019, accuracy 0.9721278042148198\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 37: train loss 1.4372862577438354, accuracy 0.9687287559483345\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:21:19,479 | server.py:232 | fit_round 16 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:21:19,526 | server.py:168 | evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:21:19,885 | server.py:182 | evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:21:19,893 | server.py:218 | fit_round 17: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 50: train loss 1.3645424842834473, accuracy 0.9687287559483345\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 7: train loss 7.043573379516602, accuracy 0.9265805574439157\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 4.841911315917969, accuracy 0.9306594153636981\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 20: train loss 1.4969526529312134, accuracy 0.9626104690686608\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 33: train loss 1.2213242053985596, accuracy 0.9660095173351462\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 40: train loss 1.3222298622131348, accuracy 0.9687287559483345\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 3: train loss 30.81389617919922, accuracy 0.7335146159075459\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 11: train loss 3.2238690853118896, accuracy 0.9422161794697484\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 12: train loss 2.819091558456421, accuracy 0.9456152277362339\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 19: train loss 1.544007420539856, accuracy 0.9592114208021754\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 31: train loss 0.9797578454017639, accuracy 0.9632902787219578\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 44: train loss 0.7452077865600586, accuracy 0.9741672331747111\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:22:09,829 | server.py:232 | fit_round 17 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:22:09,865 | server.py:168 | evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:22:10,212 | server.py:182 | evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:22:10,221 | server.py:218 | fit_round 18: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 2: train loss 392.1077575683594, accuracy 0.5472467709041469\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 11: train loss 44.25066375732422, accuracy 0.8368456832087016\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 15: train loss 15.6777982711792, accuracy 0.9157036029911625\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 29: train loss 2.2710132598876953, accuracy 0.95581237253569\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 37: train loss 1.2485092878341675, accuracy 0.9626104690686608\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 1: train loss 450.1063537597656, accuracy 0.5098572399728076\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 21.782888412475586, accuracy 0.8878314072059823\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 15: train loss 17.234088897705078, accuracy 0.8987083616587356\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 22: train loss 4.323252201080322, accuracy 0.9401767505098573\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 36: train loss 1.0371742248535156, accuracy 0.9687287559483345\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 49: train loss 0.8304699659347534, accuracy 0.9707681849082257\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:22:54,296 | server.py:232 | fit_round 18 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:22:54,324 | server.py:168 | evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:22:54,679 | server.py:182 | evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:22:54,687 | server.py:218 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 6: train loss 86.35015106201172, accuracy 0.7647858599592114\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 9: train loss 36.78820037841797, accuracy 0.8545207341944255\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 10: train loss 28.243898391723633, accuracy 0.8796736913664174\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 20: train loss 4.101919651031494, accuracy 0.9496940856560163\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 33: train loss 1.0378254652023315, accuracy 0.9687287559483345\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 42: train loss 0.8186466693878174, accuracy 0.973487423521414\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 5: train loss 121.2081069946289, accuracy 0.7348742352141401\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 14.493143081665039, accuracy 0.9089055064581917\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 18: train loss 5.815257549285889, accuracy 0.946974847042828\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 27: train loss 2.0972378253936768, accuracy 0.9673691366417403\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 41: train loss 1.2453199625015259, accuracy 0.9721278042148198\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:23:38,534 | server.py:232 | fit_round 19 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:23:38,562 | server.py:168 | evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:23:38,868 | server.py:182 | evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:23:38,873 | server.py:218 | fit_round 20: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 1: train loss 65.73282623291016, accuracy 0.752549286199864\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 0.9340261220932007, accuracy 0.9707681849082257\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 10: train loss 0.836118757724762, accuracy 0.9721278042148198\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 24: train loss 0.6633456945419312, accuracy 0.9741672331747111\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 36: train loss 0.5806599855422974, accuracy 0.9768864717878993\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 46: train loss 0.5004318356513977, accuracy 0.9775662814411965\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 10: train loss 1.374151349067688, accuracy 0.973487423521414\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 1.3453338146209717, accuracy 0.9748470428280082\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 21: train loss 1.2721617221832275, accuracy 0.9762066621346023\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 33: train loss 0.6188026070594788, accuracy 0.972807613868117\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 46: train loss 0.5523003935813904, accuracy 0.9748470428280082\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:24:23,809 | server.py:232 | fit_round 20 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:24:23,840 | server.py:168 | evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:24:24,053 | server.py:182 | evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:24:24,062 | server.py:218 | fit_round 21: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 21: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 4: train loss 36.60105895996094, accuracy 0.8973487423521413\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 7: train loss 18.100460052490234, accuracy 0.9259007477906186\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 13.48855209350586, accuracy 0.9326988443235894\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 15: train loss 1.8993983268737793, accuracy 0.9687287559483345\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 28: train loss 1.676770806312561, accuracy 0.9809653297076818\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 38: train loss 1.458253264427185, accuracy 0.9796057104010877\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 49: train loss 1.3776766061782837, accuracy 0.981645139360979\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 13: train loss 4.903255462646484, accuracy 0.9571719918422842\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 4.903255462646484, accuracy 0.9571719918422842\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 23: train loss 0.9063911437988281, accuracy 0.9789259007477906\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 33: train loss 0.8207717537879944, accuracy 0.973487423521414\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 47: train loss 0.691209077835083, accuracy 0.973487423521414\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:25:09,297 | server.py:232 | fit_round 21 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 21 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:25:09,334 | server.py:168 | evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:25:09,549 | server.py:182 | evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:25:09,557 | server.py:218 | fit_round 22: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 22: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 6: train loss 56.891395568847656, accuracy 0.8959891230455472\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 8: train loss 38.53302001953125, accuracy 0.9157036029911625\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 17: train loss 5.711724758148193, accuracy 0.9571719918422842\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 31: train loss 0.8393588066101074, accuracy 0.9775662814411965\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 41: train loss 1.5370936393737793, accuracy 0.9768864717878993\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 2: train loss 132.15615844726562, accuracy 0.7593473827328348\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 11.987394332885742, accuracy 0.9408565601631543\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 16: train loss 5.292773723602295, accuracy 0.9578518014955812\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 24: train loss 1.5346646308898926, accuracy 0.973487423521414\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 36: train loss 0.8778825402259827, accuracy 0.9755268524813052\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:25:54,936 | server.py:232 | fit_round 22 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 22 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:25:54,968 | server.py:168 | evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 22: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:25:55,188 | server.py:182 | evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 22 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:25:55,193 | server.py:218 | fit_round 23: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 23: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 50: train loss 0.6628251075744629, accuracy 0.972807613868117\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 8: train loss 7.6584625244140625, accuracy 0.9524133242692047\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 8: train loss 7.6584625244140625, accuracy 0.9524133242692047\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 9: train loss 6.0109381675720215, accuracy 0.9564921821889871\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 20: train loss 1.0573222637176514, accuracy 0.9755268524813052\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 34: train loss 0.6261327862739563, accuracy 0.9748470428280082\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 43: train loss 0.5748609304428101, accuracy 0.9782460910944936\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 5: train loss 18.852264404296875, accuracy 0.9286199864038069\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 14: train loss 1.4284636974334717, accuracy 0.9748470428280082\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 19: train loss 0.7831231355667114, accuracy 0.9789259007477906\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 28: train loss 0.5074682831764221, accuracy 0.9809653297076818\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 39: train loss 0.4663412868976593, accuracy 0.9809653297076818\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:26:40,241 | server.py:232 | fit_round 23 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 23 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:26:40,272 | server.py:168 | evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 23: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:26:40,517 | server.py:182 | evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 23 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:26:40,525 | server.py:218 | fit_round 24: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 24: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 1: train loss 17.615861892700195, accuracy 0.8048946295037389\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 9: train loss 0.6531000137329102, accuracy 0.9782460910944936\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 10: train loss 1.2250205278396606, accuracy 0.9762066621346023\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 22: train loss 0.38493674993515015, accuracy 0.9802855200543847\u001b[32m [repeated 25x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 36: train loss 0.34340527653694153, accuracy 0.9802855200543847\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 44: train loss 0.3183104693889618, accuracy 0.981645139360979\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 1: train loss 17.038169860839844, accuracy 0.8212100611828688\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 12: train loss 0.6069168448448181, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 14: train loss 0.5786227583885193, accuracy 0.9775662814411965\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 25: train loss 0.454117089509964, accuracy 0.9789259007477906\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 36: train loss 0.4028010070323944, accuracy 0.981645139360979\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:27:28,246 | server.py:232 | fit_round 24 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 24 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:27:28,279 | server.py:168 | evaluate_round 24: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 24: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 50: train loss 0.36056533455848694, accuracy 0.9836845683208701\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:27:28,509 | server.py:182 | evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 24 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:27:28,517 | server.py:218 | fit_round 25: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 25: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 8: train loss 22.170242309570312, accuracy 0.9184228416043508\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m Epoch 9: train loss 16.86380958557129, accuracy 0.9320190346702923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 9: train loss 16.86380958557129, accuracy 0.9320190346702923\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 19: train loss 2.348238468170166, accuracy 0.9694085656016316\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 34: train loss 0.5359553098678589, accuracy 0.9809653297076818\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 43: train loss 0.8958625793457031, accuracy 0.9850441876274643\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 4: train loss 77.2509536743164, accuracy 0.822569680489463\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 13: train loss 4.876982688903809, accuracy 0.9578518014955812\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 18: train loss 2.092557907104492, accuracy 0.9714479945615228\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 28: train loss 0.9678218960762024, accuracy 0.9782460910944936\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78560)\u001b[0m Epoch 40: train loss 0.5032271146774292, accuracy 0.982324949014276\u001b[32m [repeated 23x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:28:13,397 | server.py:232 | fit_round 25 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 25 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:28:13,447 | server.py:168 | evaluate_round 25: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 25: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:28:13,696 | server.py:182 | evaluate_round 25 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 25 received 3 results and 0 failures\n",
            "INFO flwr 2023-06-08 16:28:13,703 | server.py:147 | FL finished in 1163.2844899850006\n",
            "INFO:flwr:FL finished in 1163.2844899850006\n",
            "INFO flwr 2023-06-08 16:28:13,704 | app.py:218 | app_fit: losses_distributed [(1, 0.3378746594005449), (2, 0.3369663941871026), (3, 0.3369663941871026), (4, 0.13714804722979113), (5, 0.13714804722979113), (6, 0.477747502270663), (7, 0.16167120799273388), (8, 0.4613987284287011), (9, 0.4822888283378746), (10, 0.3088101725703905), (11, 0.31335149863760214), (12, 0.7756584922797456), (13, 0.5049954586739328), (14, 0.5867393278837421), (15, 0.5049954586739328), (16, 0.4604904632152588), (17, 0.49682107175295187), (18, 0.39963669391462303), (19, 0.7148047229791099), (20, 0.48501362397820164), (21, 0.6194368755676657), (22, 0.6148955495004541), (23, 0.7257039055404177), (24, 0.5095367847411444), (25, 0.33605812897366033)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.3378746594005449), (2, 0.3369663941871026), (3, 0.3369663941871026), (4, 0.13714804722979113), (5, 0.13714804722979113), (6, 0.477747502270663), (7, 0.16167120799273388), (8, 0.4613987284287011), (9, 0.4822888283378746), (10, 0.3088101725703905), (11, 0.31335149863760214), (12, 0.7756584922797456), (13, 0.5049954586739328), (14, 0.5867393278837421), (15, 0.5049954586739328), (16, 0.4604904632152588), (17, 0.49682107175295187), (18, 0.39963669391462303), (19, 0.7148047229791099), (20, 0.48501362397820164), (21, 0.6194368755676657), (22, 0.6148955495004541), (23, 0.7257039055404177), (24, 0.5095367847411444), (25, 0.33605812897366033)]\n",
            "INFO flwr 2023-06-08 16:28:13,714 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-08 16:28:13,720 | app.py:220 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-06-08 16:28:13,724 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-08 16:28:13,729 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78561)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGzCAYAAAAFROyYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhmElEQVR4nO3dd3hUVf4G8HcyaQSSUAIpEBJ6MUAEJAZEEKJREBfLLoiaGBFXii2/XZVdBduKa2FtKC4L6GJDXbHBom4UV9YICiIioQqElkJJQhJIm/v743inJJNkJnPrzPt5nnnmZjJz72EckzfnfM85FkmSJBAREREZSJDeDSAiIiJqjAGFiIiIDIcBhYiIiAyHAYWIiIgMhwGFiIiIDIcBhYiIiAyHAYWIiIgMhwGFiIiIDIcBhYiIiAyHAYWIFHXzzTcjOTlZ0XNaLBY89NBDip6TiIyNAYUowLz66quwWCxub/fff7/ezSMiAgAE690AItLHI488gl69erk8lpKSolNriIhcMaAQBagrrrgCI0eO1LsZRERucYiHiJr497//jbFjx6J9+/aIjIzE5MmT8fPPPzd53gcffICUlBSEh4cjJSUFa9ascXu+p59+GqNHj0aXLl3Qrl07jBgxAu+9916T59XU1OCee+5B165dERkZiauuugpHjhxp8rxDhw5hzpw5GDBgANq1a4cuXbrgt7/9LQ4ePOjyPHk4a+PGjbjzzjvRtWtXdOzYEb///e9RW1uLsrIyZGVloVOnTujUqRPuvfdecIN3ImNgDwpRgCovL8eJEydcHouJicGqVauQnZ2NzMxM/PWvf0V1dTVefvllXHTRRfjhhx/sBbCfffYZrr32WgwePBiLFi3CyZMnkZOTgx49ejS51nPPPYerrroKN9xwA2pra/H222/jt7/9LT755BNMnjzZ/rxbb70Vr7/+OmbMmIHRo0fjiy++cPm+7LvvvsM333yD6dOno0ePHjh48CBefvlljB8/Hjt37kRERITL8++44w7ExcXh4Ycfxrfffou///3v6NixI7755hv07NkTjz/+ONatW4ennnoKKSkpyMrKUuAdJiKfSEQUUFauXCkBcHs7c+aM1LFjR2nWrFkurykqKpKio6NdHk9NTZXi4+OlsrIy+2OfffaZBEBKSkpyeX11dbXL17W1tVJKSoo0YcIE+2Pbtm2TAEhz5sxxee6MGTMkANLChQubPZ8kSVJ+fr4EQPrnP//Z5N+amZkp2Ww2++Pp6emSxWKRbr/9dvtj9fX1Uo8ePaRx48a5edeISGsc4iEKUEuWLMHnn3/e5FZWVobrr78eJ06csN+sVivS0tLw5ZdfAgCOHz+Obdu2ITs7G9HR0fZzXnrppRg8eHCTa7Vr185+fPr0aZSXl2Ps2LHYunWr/fF169YBAO68806X1959990tnq+urg4nT55E37590bFjR5dzymbOnAmLxWL/Oi0tDZIkYebMmfbHrFYrRo4ciV9++aXZ94yItMMhHqIANWrUqCZFsk8++SQAYMKECW5fExUVBUDUgABAv379mjxnwIABTULCJ598gsceewzbtm1DTU2N/XHn0HDo0CEEBQWhT58+Tc7X2NmzZ7Fo0SKsXLkSR48edakbKS8vb/L8nj17unwth6rExMQmj58+fbrJ64lIewwoRGRns9kAAKtWrUJcXFyT7wcHe/8j4+uvv8ZVV12Fiy++GC+99BLi4+MREhKClStX4s0332xTO++44w6sXLkSd999N9LT0xEdHQ2LxYLp06fb/w3OrFar2/O4e1xikSyRITCgEJGd3HvRrVs3ZGRkNPu8pKQkAMDevXubfG/37t0uX//rX/9CeHg4Pv30U4SFhdkfX7lyZZNz2mw27N+/36XXpPH5AOC9995DdnY2nnnmGftj586dQ1lZWQv/OiIyE9agEJFdZmYmoqKi8Pjjj6Ourq7J90tLSwEA8fHxSE1NxWuvveYypPL5559j586dLq+xWq2wWCxoaGiwP3bw4EF88MEHLs+74oorAADPP/+8y+PPPvtsk3ZYrdYmPR0vvPCCyzWIyNzYg0JEdlFRUXj55Zdx0003Yfjw4Zg+fTq6du2KwsJCrF27FmPGjMGLL74IAFi0aBEmT56Miy66CLfccgtOnTqFF154Aeeddx4qKyvt55w8eTIWL16Myy+/HDNmzEBJSQmWLFmCvn37Yvv27fbnpaam4vrrr8dLL72E8vJyjB49Gnl5edi3b1+Tdl555ZVYtWoVoqOjMXjwYOTn5+M///kPunTpov6bRESaYEAhIhczZsxAQkICnnjiCTz11FOoqalB9+7dMXbsWOTk5Nifd/nll+Pdd9/FAw88gPnz56NPnz5YuXIlPvzwQ2zYsMH+vAkTJmD58uV44okncPfdd6NXr17461//ioMHD7oEFABYsWIFunbtijfeeAMffPABJkyYgLVr1zYpZn3uuedgtVrxxhtv4Ny5cxgzZgz+85//IDMzU9X3hoi0Y5FYEUZEREQGwxoUIiIiMhwGFCIiIjIcBhQiIiIyHAYUIiIiMhwGFCIiIjIcBhQiIiIyHFOsg2Kz2XDs2DFERka6bC5GRERExiVJEs6cOYOEhAQEBXnZJyK1wYsvviglJSVJYWFh0qhRo6RNmza1+Py//e1vUv/+/aXw8HCpR48e0t133y2dPXvW4+sdPnxYAsAbb7zxxhtvvJnwdvjwYa+zhtc9KKtXr0Zubi6WLl2KtLQ0PPvss8jMzMTu3bvRrVu3Js9/8803cf/992PFihUYPXo09uzZg5tvvhkWiwWLFy/26JqRkZEAgMOHD9u3eyciIiJjq6ioQGJiov33uDe8Xkk2LS0NF1xwgX0/DpvNhsTERNxxxx24//77mzx/3rx5KCgoQF5env2x//u//8OmTZuwceNGj65ZUVGB6OholJeXM6AQERGZhC+/v70aEKqtrcWWLVtctmEPCgpCRkYG8vPz3b5m9OjR2LJlCzZv3gwA+OWXX7Bu3TpMmjSp2evU1NSgoqLC5UZERESBw6shnhMnTqChoQGxsbEuj8fGxmLXrl1uXzNjxgycOHECF110ESRJQn19PW6//Xb86U9/avY6ixYtwsMPP+xN04iIiMiPqD7NeMOGDXj88cfx0ksvYevWrXj//fexdu1aPProo82+Zv78+SgvL7ffDh8+rHYziYiIyEC86kGJiYmB1WpFcXGxy+PFxcWIi4tz+5oHH3wQN910E2699VYAwJAhQ1BVVYXbbrsNf/7zn91OOwoLC0NYWJg3TSMiMo2GhgbU1dXp3Qwin1mtVgQHB6uyBIhXASU0NBQjRoxAXl4epk6dCkAUyebl5WHevHluX1NdXd0khFitVgCAl/W5RESmV1lZiSNHjvDnH/mNiIgIxMfHIzQ0VNHzej3NODc3F9nZ2Rg5ciRGjRqFZ599FlVVVcjJyQEAZGVloXv37li0aBEAYMqUKVi8eDHOP/98pKWlYd++fXjwwQcxZcoUe1AhIgoEDQ0NOHLkCCIiItC1a1cuPEmmJkkSamtrUVpaigMHDqBfv37eL8bWAq8DyrRp01BaWooFCxagqKgIqampWL9+vb1wtrCw0KWBDzzwACwWCx544AEcPXoUXbt2xZQpU/CXv/xFsX8EEZEZ1NXVQZIkdO3aFe3atdO7OUQ+a9euHUJCQnDo0CHU1tYiPDxcsXN7vQ6KHrgOChH5g3PnzuHAgQPo1auXoj/IifTU0udas3VQiIiIiLTAgEJERESGw4BCRESas1gs+OCDD3w6x0MPPYTU1FRF2kPGw4BCREQtkjd4bXzbt2+f3k3T3e9//3tYrVa8++67ejfF7zCgEJHXVq0C1q3TuxWkpcsvvxzHjx93ufXq1UvvZumquroab7/9Nu69916sWLFC7+agtrZW7yYoigGFiLxSXAxkZQG//S3Q0KB3a8xNkoCqKn1u3s7fDAsLQ1xcnMtNXsvqww8/xPDhwxEeHo7evXvj4YcfRn19vf21e/fuxcUXX4zw8HAMHjwYn3/+eZPz33fffejfvz8iIiLQu3dvPPjgg01W233iiScQGxuLyMhIzJw5E+fOnXP5/nfffYdLL70UMTExiI6Oxrhx47B161aX51gsFrzyyiu48sorERERgUGDBiE/Px/79u3D+PHj0b59e4wePRr79+9v9T159913MXjwYNx///3473//22RblpqaGtx3331ITExEWFgY+vbti+XLl9u///PPP+PKK69EVFQUIiMjMXbsWPt1x48fj7vvvtvlfFOnTsXNN99s/zo5ORmPPvoosrKyEBUVhdtuu83j9/Ljjz/GBRdcgPDwcMTExODqq68GADzyyCNISUlp8m9NTU3Fgw8+2Op7oiQGFCLyyrFj4r66GjhyRN+2mF11NdChgz636mpl/g1ff/01srKycNddd2Hnzp145ZVX8Oqrr9rXurLZbLjmmmsQGhqKTZs2YenSpbjvvvuanCcyMhKvvvoqdu7cieeeew7Lli3D3/72N/v333nnHTz00EN4/PHH8f333yM+Ph4vvfSSyznOnDmD7OxsbNy4Ed9++y369euHSZMm4cyZMy7Pk3+pb9u2DQMHDsSMGTPw+9//HvPnz8f3338PSZKaXR3d2fLly3HjjTciOjoaV1xxBV599VWX72dlZeGtt97C888/j4KCArzyyivo0KEDAODo0aO4+OKLERYWhi+++AJbtmzBLbfc4hLsPPH0009j2LBh+OGHH+wBorX3cu3atbj66qsxadIk/PDDD8jLy8OoUaMAALfccgsKCgrw3Xff2Z//ww8/YPv27fYFWTUjmUB5ebkEQCovL9e7KUQB77PPJEn8/S1JX3yhd2vM5ezZs9LOnTuls2fPSpIkSZWVjvdS61tlpeftzs7OlqxWq9S+fXv77brrrpMkSZImTpwoPf744y7PX7VqlRQfHy9JkiR9+umnUnBwsHT06FH79//9739LAKQ1a9Y0e82nnnpKGjFihP3r9PR0ac6cOS7PSUtLk4YNG9bsORoaGqTIyEjp448/tj8GQHrggQfsX+fn50sApOXLl9sfe+utt6Tw8PBmzytJkrRnzx4pJCREKi0tlSRJktasWSP16tVLstlskiRJ0u7duyUA0ueff+729fPnz5d69eol1dbWuv3+uHHjpLvuusvlsd/85jdSdna2/eukpCRp6tSpLbZTkty/lzfccEOzz7/iiiuk2bNn27++4447pPHjxzf7/Mafa2e+/P72eiVZIgpsJ044jg8cAC65RL+2mF1EBFBZqd+1vXHJJZfg5Zdftn/dvn17AMCPP/6I//3vfy6rgzc0NODcuXOorq5GQUEBEhMTkZCQYP9+enp6k/OvXr0azz//PPbv34/KykrU19e7LOxVUFCA22+/3eU16enp+PLLL+1fFxcX44EHHsCGDRtQUlKChoYGVFdXo7Cw0OV1Q4cOtR/Lq6APGTLE5bFz586hoqKi2cXFVqxYgczMTMTExAAAJk2ahJkzZ+KLL77AxIkTsW3bNlitVowbN87t67dt24axY8ciJCTE7fc9NXLkyCaPtfZebtu2DbNmzWr2nLNmzcItt9yCxYsXIygoCG+++aZLD4xWGFCIyCvOAeWXX/Rrhz+wWIBff88bXvv27dG3b98mj1dWVuLhhx/GNddc0+R7nq6Wm5+fjxtuuAEPP/wwMjMzER0djbfffhvPPPOMV23Mzs7GyZMn8dxzzyEpKQlhYWFIT09vUjzqHArk/ZDcPWaz2dxep6GhAa+99hqKiooQHBzs8viKFSswceLEVrcyaO37QUFBTTaUdLcDdvtGHyBP3svWrj1lyhSEhYVhzZo1CA0NRV1dHa677roWX6MGBhQi8srJk45jBhQaPnw4du/e7Ta8AMCgQYNw+PBhHD9+HPHx8QCAb7/91uU533zzDZKSkvDnP//Z/tihQ4eanGfTpk3IysqyP9b4PP/73//w0ksvYdKkSQCAw4cP44RzolbIunXrcObMGfzwww8um97u2LEDOTk5KCsrw5AhQ2Cz2fDVV18hIyOjyTmGDh2K1157DXV1dW57Ubp27Yrjx4/bv25oaMCOHTtwSStdlp68l0OHDkVeXl6zNSXBwcHIzs7GypUrERoaiunTp+uydxQDChF5hT0o5GzBggW48sor0bNnT1x33XUICgrCjz/+iB07duCxxx5DRkYG+vfvj+zsbDz11FOoqKhw+eUJAP369UNhYSHefvttXHDBBVi7di3WrFnj8py77roLN998M0aOHIkxY8bgjTfewM8//4zevXu7nGfVqlUYOXIkKioq8Mc//lGVX6zLly/H5MmTMWzYMJfHBw8ejHvuuQdvvPEG5s6di+zsbNxyyy14/vnnMWzYMBw6dAglJSX43e9+h3nz5uGFF17A9OnTMX/+fERHR+Pbb7/FqFGjMGDAAEyYMAG5ublYu3Yt+vTpg8WLF6OsrKzVtnnyXi5cuBATJ05Enz59MH36dNTX12PdunUuxcu33norBg0aBEAEPz1wFg8ReaVxDQoFtszMTHzyySf47LPPcMEFF+DCCy/E3/72NyQlJQEQQxVr1qzB2bNnMWrUKNx6661NdrO/6qqrcM8992DevHlITU3FN99802RK67Rp0/Dggw/i3nvvxYgRI3Do0CHMnj3b5TnLly/H6dOnMXz4cNx0002488470a1bN0X/vcXFxVi7di2uvfbaJt8LCgrC1VdfbZ9K/PLLL+O6667DnDlzMHDgQMyaNQtVVVUAgC5duuCLL75AZWUlxo0bhxEjRmDZsmX23pRbbrkF2dnZyMrKwrhx49C7d+9We08Az97L8ePH491338VHH32E1NRUTJgwAZs3b3Z5Tr9+/TB69GgMHDgQaWlpbXqvfMXdjInIKxkZQF6e4+szZ8S0VWoddzMms5AkCf369cOcOXOQm5vb4nO5mzERGULjIX32ohD5l9LSUrz44osoKirSfu0TJ6xBISKvyEWyISFAXZ2oQ3GaoUlEJtetWzfExMTg73//Ozp16qRbOxhQiMhjkuToQRk2DPj+e/agEPkbo1R+cIiHiDxWXQ3I25/8ujI2Z/IQkSoYUIjIY3LvSWgoIC/GyYDiPaP8hUqkBLU+zwwoROQxuf4kJgbo00ccM6B4Tl7Uq/HKpkRmVv3rzpO+LtvfGGtQiMhjcg9Kly5Ar17i+MABUZvy6+rg1ILg4GBERESgtLQUISEhCAri34hkXpIkobq6GiUlJejYsaPLqrpKYEAhIo/JASUmBujZEwgKEjUpRUXAr6uYUwssFgvi4+Nx4MCBJsuPE5lVx44dERcXp/h5GVCIyGPOASUkRISUgwfFMA8DimdCQ0PRr18/DvOQXwgJCVG850TGgEJEHnOuQQGA3r0dAWXMGN2aZTpBQUFcSZaoFRwAJSKPOdegAI46FBbKEpHSGFCIyGPOQzyA6EEBuFgbESmPAYWIPNZcQGEPChEpjQGFiDzGgEJEWmFAISKPuSuSBYCjRx1L4BMRKYEBhYg84rxRoFwk26UL0KGDOOayHkSkJAYUIvJIVRVQUyOO5R4Ui4XDPETeKChw/H9ELWNAISKPyL0nYWFA+/aOxxlQiDzz5pvA4MHAI4/o3RJzYEAhIo84158477vDgELkmRUrxP0XX+jbDrNgQCEijzSuP5E5bxpIRO6dPAls2CCOd+4UNV3UMgYUIvJI4ynGMvagELXuo4+AhgZxXFEhZr5RyxhQiMgjngQU/lVI5N7777t+vXOnPu0wEwYUIvJIcwElOVncnznjqFOhwHHsGPDMM0BZmd4tMa6KCuCzz8TxoEHingGldQwoROQROXw0rkEJDwcSEsQxh3kCz6JFwB/+ALz4ot4tMa5164DaWqB/f+Daa8VjDCitY0AhIo8014MCcNPAQLZvn7j/6Sd922Fk//qXuL/2WuC888Txzz/r1x6zYEAhIo94ElDYgxJ4Dh8W97t26dsOozp7VvSgAMA114h1UADO5PFEsN4NICJzYEAhd+SAsmcPYLMBQfyz18WnnwLV1UDPnsCIEWIV2aAgUbNTVATEx+vdQuNq00dpyZIlSE5ORnh4ONLS0rB58+Zmnzt+/HhYLJYmt8mTJ7e50USkvcYbBTpjQAlMFRXiBojNIgsL9W2PEcmzd665RixwGB4O9OkjHuMwT8u8DiirV69Gbm4uFi5ciK1bt2LYsGHIzMxESUmJ2+e///77OH78uP22Y8cOWK1W/Pa3v/W58USkDXcbBTrjYm2BSe49kXGYx1VtrVj/BHAUxwKOOhQWyrbM64CyePFizJo1Czk5ORg8eDCWLl2KiIgIrJDX8G2kc+fOiIuLs98+//xzREREMKAQmUhlpfhhC7Tcg1JYCNTVadcu0hcDSsu+/BIoLwdiY4H0dMfjznUo1DyvAkptbS22bNmCjIwMxwmCgpCRkYH8/HyPzrF8+XJMnz4d7Z13G2ukpqYGFRUVLjci0o/cexIeDkRENP1+XJz4XkND019a5L8a/7fevVufdhiVPHvn6qsBq9XxOAOKZ7wKKCdOnEBDQwNiY2NdHo+NjUVRUVGrr9+8eTN27NiBW2+9tcXnLVq0CNHR0fZbYmKiN80kIoU1t1GgLCjIMczDOpTAIQeUqChxzx4Uh4YG4IMPxPE117h+z3mqMWfyNE/Teuvly5djyJAhGDVqVIvPmz9/PsrLy+23w/yTjEhXLdWfyFiHEnjkH82XXCLuGVAcNm4ESkuBTp2A8eNdvzdggAj6p04BzZRvErwMKDExMbBarSguLnZ5vLi4GHFxcS2+tqqqCm+//TZmzpzZ6nXCwsIQFRXlciMi/bQ0xVjGmTyBRw4ol14q7ouKRM0FOWbvXHUVEBLi+r127Rz/v3CYp3leBZTQ0FCMGDECeXl59sdsNhvy8vKQ7lwB5Ma7776Lmpoa3HjjjW1rKRHphgGF3JEDynnnOdbzYB2KWA9GDijOs3ecsQ6ldV4P8eTm5mLZsmV47bXXUFBQgNmzZ6Oqqgo5OTkAgKysLMyfP7/J65YvX46pU6eiS0t9xERkSAwo1JgkOQJKYqIYtgA4zAMA338PHDkCdOjg6F1qjEvet87rlWSnTZuG0tJSLFiwAEVFRUhNTcX69evthbOFhYUIarSU4O7du7Fx40Z8Jm/nSESm0tIibTLWoASWU6fEMu4A0KMHMHAgsGEDAwrg6D2ZPFnMbnOHPSita9NS9/PmzcO8efPcfm/Dhg1NHhswYAAklioTmZY3RbInT4o6hOho9dtF+pF7T7p1A8LCREABGFAkyTG9uPHsHWcMKK3jrglE1CpPhngiI4GuXcUxe1H8n/PwDsCAItuxQ+zwHBYGTJrU/PMGDRIzeUpLxY2aYkAholZ5ElAA1qEEksYBRa5B2bcPqK/Xp01GIPeeZGaKGpTmREQAycnimL0o7jGgEFGrPKlBARhQAknjgNKzp6i3qKsL7B601mbvOOMwT8sYUIioRa1tFOiMhbKBo3FACQriTJ69e4GffgKCg4EpU1p/PgNKyxhQiKhFZ844NgBkDwrJGgcUgHUocu/JhAliBdnWcKpxyxhQiKhFcu9Ju3buNwp0xoASOFoKKIG6WJsns3ecsQelZQwoRNQiT+tPAEdAOXhQrKZJ/slmEwuRAa4BJZCHeAoLge++EzNzpk717DWDBon74mLH/2fkwIBCRC3ydAYPIBbsCg4GamuBY8fUbRfpp6REDPsFBQEJCY7HA3mIZ80acX/RRcCv65a2qkMHIClJHLMXpSkGFCJqkacFsgBgtTp+4HKYx3/Jwzvx8SKQyvr3F/cnTzo+N4HCm9k7zjjM0zwGFCJqkTc9KADrUAKBu/oTAGjfXkw3BgKrDqW4GPj6a3F89dXevZYBpXkMKETUIgYUaqy5gAIEZh3Khx+K6fgjRzoCmqcYUJrHgEJELfKmSBbgWiiBoKWAEoh1KPLsHW+HdwBONW4JAwoRtcibGhSAPSiBgAHF4fRp4IsvxLGn04udyTN5jh8X5yIHBhQiahGHeKgxBhSHjz8Wew+lpDiKhL0RFSVmvwFAQYGybTM7BhQialFbA0pREVBdrU6bSF+eBJQDB4CaGu3apBd59k5bek9kch0Kh3lcMaAQUYu8rUHp1Ano2FEcHzyoRotIT/X1jjVu3AWU+HixvkdDA7B/v7Zt01plJfDpp+K4LfUnMrkOhYWyrhhQiKhZ3mwU6EwulOUwj/85flysJBsS4n5BMoslcIZ5/v1v4Nw5oE8fYMiQtp+HM3ncY0AhomZVVIi/mAHvAgrrUPyXPLzTvbtYSdadQAkozrN3LJa2n4cBxT0GFCJqltx7EhHR+kaBzhhQ/FdL9SeyQNg08Nw5YO1acexL/QngCChHjgDl5b6dy58woBBRs7ytP5ExoPgvTwJKICzW9vnnogalRw/gggt8O1fHjo49jTiTx4EBhYia5e0MHhkXa/Nf3vSg7Nol6pj8kTx75+qrmx/q8gaHeZpiQCGiZrWlQBZw7UHx119QgcqTgNK3r/ilXVEhppv7m7o6sbw94NvsHWecatwUAwoRNautPShJSaJosLoaKClRvl2kH08CSni4oxfNH+tQvvpKrPratStw0UXKnJNTjZtiQCGiZrU1oISGOn6BsQ7Fv3gSUAD/nskjz96ZOhWwWpU5J4d4mmJAIaJmtbVIFmAdij+qqQGKi8VxawHFXwtlGxqANWvEsa+zd5zJAaWwEDhzRrnzmhkDChE1q601KABn8vijo0fFfXh4658Jf+1Byc8XIS06GpgwQbnzdu4MxMWJY87kERhQiKhZbR3iARhQ/JHz8E5rC5P5a0CRZ+9MmSKGMpXEYR5XDChE1CwGFHLmaf0J4AgohYX+s2mkJDkCilKzd5wxoLhiQCGiZvlSgyIHFNag+A9vAkpMjNg4UpKAvXvVbZdWtm4FDh0Sqypfdpny5+dUY1cMKETklvNGgb4UyR4+DNTWKtcu0o83AcUfNw2UZ+9MmuTd1g+e4lRjVwwoRORWebmYsQC0rUi2WzfxQ1ySxF+dZH7eBBTAvwKKJDkCipKzd5zJPSgHDwJVVepcw0wYUIjILbn3pH17MWvDWxYL61D8TVsDij8s1rZzJ7BnjyiMnTxZnWvExIjF3wD/CHW+YkAhIrd8Gd6RsQ7FvwRyD4pcHHvppUBUlHrXkYd5WIfCgEJEzfClQFYm16GwB8X8qquBU6fEsacBRV6sbfduwGZTp11akYd31Ji944wzeRwYUIjILV8WaZNxiMd/yL0nkZFikTJP9O4NBAeLcHPkiHptc2fPHuDjj4Ht231fmXX/fuDHH8Wy9lddpUz7msOA4hCsdwOIyJiUHOJhQDE/b4d3ACAkROxsvGuX6EXp2VOdtjV29ixw4YViQz9Z586iRy852fW+Vy+xuWVLs3Lkpe3Hj/ctsHuCU40dGFCIyC0GFHLWloACiDqUXbvE7dJLlW+XOxs3inASHi6KvE+eFMNTp04BW7a4f01srPvwkpwMvPeeeI5as3ecyTUoBw6Inic1pjObBQMKEbmlRA1KcrK4Ly8XvzA6dfK5WaSTtgYUPTYN/M9/xP311wMrVoghnoMHxS/9xvcHDgAVFWJ/neJiYNOm5s87dar6be/aVfTSnDwpep3OP1/9axoVAwoRuaVEDUpEhNgArahI9KKMGKFM20h7vvSgAPoElIwMcR8ZCQwZIm6NSRJQVtZ8eDl4UPRkTJ0KJCSo33aLRQzzfP21qENhQCEiakSJIR5ADPMwoJifWQLKiRPADz+I44kTW3++xSJ69jp1AoYPb/p9SdK+908OKIFeh8JZPETklpIBBWAditn5OsRz7Jjvs2k88eWXIlQMGSLqSnxlsYgC29Z2b1YSl7wXGFCIyC0lalAALtbmL9oaUDp1cgQFLVaUbTy8Y0acaiy0KaAsWbIEycnJCA8PR1paGjZv3tzi88vKyjB37lzEx8cjLCwM/fv3x7p169rUYCJSn82mXEDhYm3mV17u6P3wNqAA2hbK+lNA2b8fOHdO37boyeuAsnr1auTm5mLhwoXYunUrhg0bhszMTJSUlLh9fm1tLS699FIcPHgQ7733Hnbv3o1ly5ahe/fuPjeeiNTh60aBzjjEY35y70nnzm2b9qpVHcovv4hbcDBw8cXqXktNcXGi58lm8499jNrK64CyePFizJo1Czk5ORg8eDCWLl2KiIgIrFixwu3zV6xYgVOnTuGDDz7AmDFjkJycjHHjxmHYsGE+N56I1CHXn3ToAISF+XYuOaAcOuQIPWQubR3ekWm1aWBenrhPTxefXbOSZ/IAgT3M41VAqa2txZYtW5Dh1HcWFBSEjIwM5Ofnu33NRx99hPT0dMydOxexsbFISUnB448/joYWflLV1NSgoqLC5UZE2lGqQBYQUzNDQ4H6eu2XOydlKBVQ1O5B8YfhHRkDipcB5cSJE2hoaEBso9Lo2NhYFBUVuX3NL7/8gvfeew8NDQ1Yt24dHnzwQTzzzDN47LHHmr3OokWLEB0dbb8ltvX/CiJqE6XqTwAgKMixYBuHeczJ14Ai16Ds2aNeL5rN5uhB8aeAEshTjVWfxWOz2dCtWzf8/e9/x4gRIzBt2jT8+c9/xtKlS5t9zfz581FeXm6/HZb/7yAiTSixSJsz1qGYm68BJSlJDBXW1oqFz9Tw448iWEdGAhdcoM41tMSpxl4u1BYTEwOr1Yri4mKXx4uLixEXF+f2NfHx8QgJCYHVarU/NmjQIBQVFaG2thahoaFNXhMWFoYwXwe+iajNlBziARhQzM7XgGK1Av37Az/9JOpQ+vRRrm0yeXhn/HixSaHZyT0o+/YBNTW+14KZkVc9KKGhoRgxYgTy5H40iB6SvLw8pKenu33NmDFjsG/fPthsNvtje/bsQXx8vNtwQkT6UyugcC0Uc/I1oADq16H4U/0JIGq3oqLEkNjevXq3Rh9eD/Hk5uZi2bJleO2111BQUIDZs2ejqqoKOTk5AICsrCzMnz/f/vzZs2fj1KlTuOuuu7Bnzx6sXbsWjz/+OObOnavcv4KIFKVkDQrAtVDMTJKMH1DOnRNLwwP+E1AsFscwT6DWoXi9F8+0adNQWlqKBQsWoKioCKmpqVi/fr29cLawsBBBQY7ck5iYiE8//RT33HMPhg4diu7du+Ouu+7Cfffdp9y/gogUZdYhHu6YrLyTJx2LhfmyfJWai7Xl5wNnzwLx8cCgQcqfXy+DB4t/W6DWobRps8B58+Zh3rx5br+3YcOGJo+lp6fj22+/bculiEgHShfJyj0opaViRdLISGXO62zZMuC224CXXgJmz1b+/IFK7j2JjfWtDkLNHhTn4R0t98xRW6BPNeZePETUhNI9KNHRjrCjRh1KfT3w6KPi+LHHgLo65a8RqJQY3gEcPSilpcCpU76dqzF/qz+RBfpUYwYUImpC6RoUQN1C2TVrHL9Ijx0D3ntP+WsEKqUCSocOQI8e4ljJFWVPnwa+/14cT5yo3HmNQK5B2btXTNEONAwoRORCyY0CnalZKPvss+JerpGQvybfKRVQAHXqUDZsEJ/ZQYN8q5Exoh49RLCrrxfTjQMNAwoRuSgrEz/wAeVqUAD1CmW/+w745hux9sW6daJOYvNmgGVvylAyoKhRh+KvwzsA9+RhQCEiF3L9SWSk2ENHKWoFlOeeE/fTpwNDhwIzZoiv2YuiDDUCipJDPP4cUIDAnmrMgEJELpQukJWpUYNy7BiwerU4vusu1/v33nP8cqW2M3IPSmGh2N/HagXGjVPmnEbDHhQiol+pUX8COGpQDhxwDCH56qWXxPj8RRcBI0aIx4YNAy65RKzAuWSJMtcJVDYbcPSoOFYyoOzfr8xMK3lR81GjxEwxf8SAQkT0K7V6UBITxV+6584BzWx+7pWzZwF5z9G773b9nvz13/8OVFX5fq1AVVwsgkRQkFgEzVfduwPt24tQuX+/7+fz9+EdwBFQdu8OvOnzDChE5ELpRdpkISFAz57iWIk6lDffFL09SUnAb37j+r3Jk8WGdKdPA6+/7vu1ApU8vJOQAAS3aVlPVxaLYyaPr3UokhQYAaVnTxHq6uqUCXVmwoBCRC7U6kEBlKtDkSRHEewddzT95Wm1AnfeKY6ffVa5IaVAo2T9iUypOpQdO4CSEiAiArjwQt/bZVRBQY7l+wNtmIcBhYhcqFWDAii3FsoXX4hfUO3bAzNnun/OzTeLmUi7dgGff+7b9QKVkQOK3Hsybpyys82MKFDrUBhQiMiFFj0ovgYUuffk5puBjh3dPycqyhFeOOW4bdQIKEot1hYIwzuyQF3yngGFiFyoVYMCKBNQ9u4FPvlEHMvDOM254w5R97B+PVBQ0PZrBiq1e1AkqW3nqK0FvvpKHAdCQJHXQmEPChEFNKPXoDz/vLifPBno37/168kFtPLryHNqBJR+/URoLCsTGwe2xaZNYnZWt25ASopybTMq55k89fX6tkVLDChE5ELNGhQ5oBw9KqYbe6usDFi5Uhw3nlrcHPl5//yn8rvo+js1Akq7dkBysjhu6zCPPLwzcaIoIvV3ycnifaupUWcvK6MKgP+0ROSphgbHL3E1AkrnzqJwFQAOHvT+9StWiL+czzvP851rL75YLN5WXQ384x/eXzNQ1dcDx4+LYyUDCuB7oWwg1Z8AgTuThwGFiOycNwrs3Fn581ssba9Dqa93DNPcfbc4l6fXlHtRXngh8Ba7aqtjx8RnISREDKUoyZdC2YoKMcQDBE5AAQJzJg8DChHZyfUnUVHqTd1sa0D56CPg0CFRvHvDDd69dvp08Uv2yBFgzRrvXhuo5OGdHj2UH0bxZdPAr74SPX39+jkW/gsEDChEFNDULJCVtbVQVp4q/Pvfi/F4b4SHA7Nnu56HWqZG/YnMlyGeQBvekQXiVGMGFCKyU7NAVtaWxdq2bgW+/lqsGDtnTtuue/vtolcoPx/YvLlt5wgkWgSUAwe8L5YO1IAiTzXetUv0IAUCBhQistOyB8WbgPLcc+L+d78TG861RVycGOpxPh81T82A0q2b2H1YksS6Np46dkwMcVgsYsfqQNKrFxAWJgJdWwrMzYgBhYjs1FykTeYcUDxZqKuoCHjrLXF8112+XVt+/TvviKnO1Dw1A4rF0rY6lLw8cT9yJNCpk/LtMjKr1fGeBcowDwMKEdlp0YOSlCR+QVVWOoaUWvLyy2LmzejRwKhRvl17+HAx7bi+HnjpJd/O5e/UDChA2+pQAnV4RxZoK8oyoBCRnRY1KOHhQEKCOG5tmOfcORFQAN97T2TylONXXgHOnlXmnP7IaAFFkhhQAm0mDwMKEdlp0YMCeF6H8vbbYjn0xETgmmuUufZVV4mVOU+eBN54Q5lz+ptz54CSEnFslICya5eoQQkPF71pgYgBhYgClhY1KIBnAUWSHFOC580TM3iUYLWKTQQBcf62bljnz44cEfft2qmzYB/gWKxt927P/hvIvSdjx4qQEojkgFJQ4FhQ0Z8xoBCRndY9KC2thfLVV8CPPwIREcCttyp7/ZkzgQ4dRLGhXHhJDs7DO56u2OutPn1EWKysFD0jrQn04R1AvGehoWLbhkOH9G6N+hhQiMhOixoUwLMeFLn3JDtb+b/io6OBnBzX65CD2vUngPhF26ePOG5tmKe+HvjyS3EcyAElONjR8xQIwzwMKEQEQP2NAp21tljb/v1iaXsAuPNOddpwxx2id2DtWmDPHnWuYVZaBBTA8zqU774DzpwRQTU1Vd02GV0grSjLgEJEAIDTpx21AGrVHcjkHpTCQveb9734omjL5Zc7fokprV8/4MorxfELL6hzDbPSKqB4ummgPLwzcaLy+wKZTSBNNQ7w/9REJJPrT6KjxQ62aoqLE4WONpsIKc4qKoDly8WxPCVYLfL5V64UOzmToHUPSmuLtbH+xCGQZvIwoBARAO0KZAExtNJcoezKlaI7f9Ag4LLL1G3HJZcAKSlAVZUjFJGxhngqK8X+SQADCuAaUPx9BhoDChEB0K5AVuauDqWhAXj+eXF8113qzSCRWSyOXpQXXhDFmKT9EM/hwyKIuPP112IYsFcvR6gNZH37ih7OqqqmvY/+hgGFiABo24MCuJ/J88kn4utOnYCbbtKmHTNmiH/zoUPAhx9qc00jq6x0DHepHVC6dAG6dhXHzRUqc3jHVUgI0L+/OPb3YR4GFCICoN0ibTJ3AUXeZfj3vxfrn2ihXTvg9ttdrx/I5N6TqChxU5vzgm3uMKA0FSh1KAwoRARAvx4UuQblxx/FWhdWKzBnjjZtkM2eLf4y/fprYMsWba9tNFoN78haqkMpLga2bxfHEyZo0x4zYEAhooCidw2K3Htx3XXa/XKUJSQAv/udazsClZECyhdfiPvzz9fuc2kGgbIWCgMKEQHQvgdFDiinTgF79zo27lN7anFz5Ou+/TZw/Lg+bTACIwUUDu+457wWij/P5GFAISIA2geUDh2Abt3E8b33ArW1QFoacOGF2ly/sZEjgTFjxIyRl1/Wpw1GoHVAkWtQ9uxx3QBPkoDPPxfHDCiu+vUTQ6FnzgBHj+rdGvUwoBARAO2LZAFHHcoHH4h7vXpPZPL1ly4Fzp3TtSm60TqgJCeLfXnOnXOdNrtvn2hLaChw0UXatMUsQkNFSAH8e5iHAYWIAGjfgwK4rmvRvTtw7bXaXdudqVOBnj2B0lLgrbf0bYtetA4owcGOX7bOwzzy8M6YMdrN6DITeZjnp5/0bYeaGFCICPX1jrUvtAwoch0KAMydq/4S+60JDgbmzRPHzz7r3+P77kiS9gEFcF+HwvqTlg0fLu6//17fdqipTQFlyZIlSE5ORnh4ONLS0rB58+Zmn/vqq6/CYrG43MLDw9vcYCJSnpYbBTqTe1DCw4HbbtPuui259VbxF/v27cC//qV3a7RVViZWKAWAHj20u27jgNLQ4JjBw4Di3gUXiHsGFCerV69Gbm4uFi5ciK1bt2LYsGHIzMxESUlJs6+JiorC8ePH7bdDhw751GgiUpY8vNOxo+hF0MrkycDQocBjj2lb+9KSTp2AO+8Uxzk5/r/WhDO596RLF22HVRov1rZ1qwhL0dHAiBHatcNM5Pdl/34xE84feR1QFi9ejFmzZiEnJweDBw/G0qVLERERgRUrVjT7GovFgri4OPstNjbWp0YTkbL0qD8BgNhYsUDb//2fttdtzSOPAOPHi2Xfp04NnJ2O9RjeAZr2oMjDOxMmiNkq1FTnzkCfPuLYX3tRvAootbW12LJlCzKc+tyCgoKQkZGBfHm7STcqKyuRlJSExMRE/OY3v8HPrZQd19TUoKKiwuVGROrRepE2owsJAd55RxTM7t0L3Hij6xRYf6VXQJF7UIqKRBhk/Yln/H2Yx6uAcuLECTQ0NDTpAYmNjUVRUZHb1wwYMAArVqzAhx9+iNdffx02mw2jR4/GkSNHmr3OokWLEB0dbb8lav1/C1GA0asHxci6dgXWrBH1MWvXAgsX6tueEyeAa64BHn1UvWvoFVCiosRqvgCwbRuwcaM4ZkBp2ciR4v677/Rth1pUn8WTnp6OrKwspKamYty4cXj//ffRtWtXvPLKK82+Zv78+SgvL7ffDsv/1xCRKvRYA8UMhg8Hli0Tx489Brz/vj7tOHUKuPRSEZgeegg4dkyd6+gVUABHL8ry5WLRvsREx/Rjck/uQWFAARATEwOr1Yri4mKXx4uLixEXF+fROUJCQnD++edj3759zT4nLCwMUVFRLjciUg97UJp3443APfeI46ws7RfGKisDLrtM9CwAYqhJ3hZAaXoGFLkO5Z13xH1GBmCxaN8OMxk+XLxHR4/65/YMXgWU0NBQjBgxAnl5efbHbDYb8vLykJ6e7tE5Ghoa8NNPPyE+Pt67lhKRaliD0rInnxQFm1VVomj29GltrlteDmRmih2WY2IcQem119RZo8UIAaW2VtxzeKd1HToAgwaJY3+sQ/F6iCc3NxfLli3Da6+9hoKCAsyePRtVVVXIyckBAGRlZWH+/Pn25z/yyCP47LPP8Msvv2Dr1q248cYbcejQIdx6663K/SuIyCfsQWlZcDCwejWQlCSWYJ8xQ6zVoaYzZ4ArrgA2bxYzNvLygAULgLAw0Ysj96goRZIAuTRQz4AimzhR+zaYkT8P83gdUKZNm4ann34aCxYsQGpqKrZt24b169fbC2cLCwtx3Kmv6fTp05g1axYGDRqESZMmoaKiAt988w0Gy/tFE5HuGFBaFxMj9gxq1w5Yvx548EH1rlVZCUyaBOTni3VZ/vMfsV5Mx47Ab34jnvPPfyp7zdJSoKZGDBl0767suT3hHFBSUsQUdGqdP8/ksUiS8RdzrqioQHR0NMrLy1mPQqSCfv1Ez8B//wuMHat3a4ztrbdEDwog6iV++1tlz19VJcLJf/8rFirLy3NdrGztWuDKK8VO0EeOKLc9wJYtYlZIXJw+9Qw2mxiyOHtWbNr4t79p3wYz2rxZ7AIeEwOUlBivbseX39/ci4dIYXJXufGjvwN7UDx3/fXAH/4gjm++WdnN2qqrgauuEuEkKgr47LOmK6ledpkIJyUl4vtK0bP+BACCghz/1smT9WmDGQ0dKoYgT5wA/G2RdgYUIgXt3Cl+gSQmAo8/rndrPKPXRoFmtmiRKOKsrhZFs0osNX7unDjXF1+InoT164FRo5o+LyTE0YOj5DCP3gEFEMW/H33EAllvhIeLkAL43zAPAwqRAsrKxAyLoUMdq2D++9+6Nslj8i9Xi0XUO1DrgoOBt98WuzH/8ovoVfGlaLamBrj6auDzz4H27cVnp6WJkVlZ4v7DD5Vbht8IAaV3b2DKFP2ub1b+WijLgEKaW7kSmDZN/MVodjabWFiqf3/g2WfFL6lx48T3tm4VvRNGp9dGgWbXpYsomo2IEEMtf/pT285TWwtcd53oMWnXTtSYXHRRy69JTRWFpDU1wLvvtu26jRkhoFDb+OuKsgwopLlHHxXFhRs26N0S3+Tniy74W28VMyAGDgQ+/VR00UdGimK/ggK9W9k61p+03dChInADYq2U1au9e31dnQjrn3wiuuo/+cQRcFtisTh6UZQa5mFAMS+5B2XLFv/aM4oBhTQlSWLVQwAoLNS3LW117Jj45TB6tPiBEBUFLF4MbN8u6k+ci/3M8BcNF2nzze9+B9x3nzjOyRG7M3uirk4MDX3wgVjb5MMPxWJwnrrhBvFZ27gR2L/f62Y3wYBiXuedJwJuRYXY3NJfMKCQpk6edKwUabYtlmpqxF/JAwYAq1aJx265BdizR9SfOE/3NNOYMHtQfPeXv4gVX8+eFYWucuhrTn09cNNNwL/+BYSGij12LrvMu2smJDiKSV9/vU3NtmtocPzhwIBiPsHBwPnni2Mz/MzxFAMKaUr+IQg4Vq00g7VrxZj/ffeJRbTS0sT6A8uXu19QykyLJzGg+M5qBd58UxR5Hjwohm2aqz9qaACys8VwUEiICClXXNG26zoP8/gyrb2oSLTLagW4C4k5memPIk8xoJCmnAOKGXpQ9uwRazJceaVYyCw2VkyF/OYbxw8Ed+SitR9/FD0vRsadjJXRubMYrmnfXiyudv/9TZ/T0CB63d58U/zV+8474rPVVlOniinJv/wiPpNtJf+/mJAgQgqZj5n+KPIUAwppyiwB5cwZ0VuSkgKsWyf+0v3jH0VgycoSY/8tSU4Wv/Dr6kRtipGxBkU5Q4YAr74qjp95RgQRmc0G3Hab6O2wWsU05alTfbte+/ZiBhDgW7Es60/MT/6j6IcfzDF70BMMKKSpxgHFaKut2mziB33//qLepK4OuPxysVrok0+KglhPWCzm+YuGQzzKuu46QN4vdeZM8QvDZgNmzwZWrBDh9o03gGuvVeZ68jDP6tVtn7rPgGJ+/fuLn09nz4rNJP0BAwppyjmgnD2rzAqcSvn+e2DMGFEfUFQE9O0LfPyx6EEZMMD785llbQIGFOU9+qioK5FXh73tNuDvfxfhZNUqUaOilHHjgJ49gfJy8XltCwYU83OePWj0P4o8xYBCmjp2zPVrowzzHDwoNsn79lvRbf7EE8COHaI+oK2bb5mlaI01KMqTi2b79hXT6ZcvF5+jlSsdy9QrJShIzAgC2j7Mw4DiH8zyM8dTDCikKeceFMA4AeXbb8VfuwMGiDqT++4Ta1P4Qu5B2blT7FBrVOxBUUfHjqJotkMH8fU//uEYjlGaHFD+/W+xiaC3GFD8g1l6bT3FgEKakgNK797i3igBRd4F9IILxEwGJSQkiJvNJuoQjKiuTgwNAAwoajjvPNETt22bmL2jlgEDxNT3hgbgrbe8fz0Din+Qe1B++sk/thJhQCHN1NQ4/lq/8EJxb5SAIq9qm5Sk7HmN3uXKjQLVl5QEDBum/nXk3pnXXvPudbW1ouYKYEAxu6Qk8YeGGWYPeoIBhTQj15+EhTl+YBsloMg9KD17KnteowcUOTB26sT1L8xu2jQxHf6HH8Rf0J46dkzMpgsNBbp2Va99pD6Lxb+GeRhQSDPy8E737o6/1IwSUNTqQZF/WBi1qp71J/6jSxfHom/yVgyekP8f7NGj9fV9yPjMsryBJ/hxJM3IPSgJCcYLKGr1oMgBZe9eoKxM2XMrgYu0+Rd5mOf110U9iidYf+JfjN5r6w0GFNKMux6Uo0f13x68vFzsAgooH1C6dHEUBBvxLxr2oPiXSZPEkvvHj4vl9j3BgOJf5D+KCgrEvmFmxoBCmnEOKAkJYry0thYoLdW3XXLvSZcuYg0UpRl5mIcBxb+EhgLXXy+OPV0ThQHFv8THi5+xRp496CkGFNKMc0AJCXHsmqr3MI9a9ScyI3e5cpE2/yMP87z/vthTqjUMKP7HyD9zvMGAQppxDiiAcepQ1Ko/kRn5hwVrUPzPBReIdVHOngX+9a/Wn8+A4n/8ZSYPAwppxqgBRe0elOHDxXDW4cNAcbE612grDvH4H4vF0YviyTAPA4r/8ZeZPAwopAlJcp3FAxgnoKjdgxIZCQwcKI6N9gODAcU/3XijuP/yS8fn252zZx2fAQYU/yH3oOzbB5w+rW9bfMGAQpo4fdqx9LIcUHr0EPd6BxS1e1AA4w7zsAbFP/XsCVxyiTh+443mn3fkiLiPiOBKwv6kc2egTx9xbLQ/irzBgEKakId3unQBwsPFcaD0oADG7XJlD4r/ch7mkST3z3Ee3mnrrt1kTP5Qh8KAQppoXH8CGCOg1NaKNSMAdXtQnH9YNPfLQmt1dY71XxhQ/M+11wLt2gG7dzf/S4r1J/7LqH8UeYMBhTTRUkA5dszzVS+VduSICAzh4eruQ5KaCgQHAyUl+vcYyeQZPEFBQMeOujaFVBAZCVxzjThurliWAcV/GXVY2RsMKKQJdwElLk780m5ocPRiaE2uP+nZU90u7vBwYMgQcWyUv2jk4Z3OnblRoL+Sh3neekv0FjbGgOK/zj9f/Ew7csSxW7XZMKCQJhrP4AHEL0X5a716FbSoP5EZbUyYBbL+b+JEsSDiqVPAunVNv8+A4r8iI4FBg8SxUf4o8hYDCmnCXQ8K4PjBKM8m0JoWM3hkRuty5SJt/s9qdUw5djfMw4Di34z2M8dbDCikidYCSiD0oDgXrem9QSLAGTyBQh7m+eQTRyiVMaD4N6P12nqLAYU0YdSAomUPynnniVqU8nJg/371r9caBpTAkJIi6hHq6oDVqx2PnzkjPosAA4q/cv6jyCizB73BgEKqq60Vs1cA4wUULXtQQkLEbB7AGH/RsAYlcGRni3vnYR75/7noaFGvQP5n2DAxEaG01PHHmJkwoJDq5Bk6ISFN/1rXM6BIkussHi0YaUyYPSiB4/rrRT3Kpk1iXRSAwzuBwHn2oBF+5niLAYVU5zyDp/FUXj0DSmmpWH7fYnEsu682Iy2exCLZwNGtG3DFFeJY7kVhQAkMRvqZ4y0GFFJdc/UngCMYFBW5X6dBTXLvSVwcEBamzTXlorWtW4H6em2u2Rz2oAQWuVh21SpRpM2AEhiM1GvrLQYUUl1LAaVrVyA01HW3Y63I9SdaFMjKBgwQ4/3V1UBBgXbXdYcBJbBMmSLqTQ4fBr76igElUBht9qA3GFBIdS0FlKAg/XY11rr+BBD/3hEjxLHeXa4skg0s4eHAtGni+J//ZEAJFIMHi//2FRXAvn16t8Y7DCikupYCCqBfHYoePSiAMdYmqK0V00wB9qAEEnmY5733gD17xDEDin8LCRHTzAHzDfO0KaAsWbIEycnJCA8PR1paGjZv3uzR695++21YLBZMnTq1LZclkzJqQNGjBwUwxpgwNwoMTKNHA717A5WVjs8/A4r/M8LPnLbwOqCsXr0aubm5WLhwIbZu3Yphw4YhMzMTJfJCF804ePAg/vCHP2Ds2LFtbiyZk7t9eJwFWg+K/MPixx+Bmhptry1zHt4JYj9qwLBYHL0oMq1msJF+5F5bvYeVveX1j6bFixdj1qxZyMnJweDBg7F06VJERERgxYoVzb6moaEBN9xwAx5++GH07t3bpwaTuUgSe1AaS04WwaCuDvjpJ22vLWP9SeC66SbHcUwM0K6dfm0hbch/FBlh9qA3vAootbW12LJlCzIyMhwnCApCRkYG8vPzm33dI488gm7dumHmzJkeXaempgYVFRUuNzKn8nIxYwVoPaBouWFgVZXjl7TWPSgWi/51KFwDJXD17g1cdJE45vBOYOjfX8wePHsW2LlT79Z4zquAcuLECTQ0NCA2Ntbl8djYWBQVFbl9zcaNG7F8+XIsW7bM4+ssWrQI0dHR9lsi/y8yLbn3pFOn5v9S06MHRb5WZKSYeqk1vRdP4hTjwDZrlrgfNkzfdpA2jDR70Buqjj6fOXMGN910E5YtW4YYL34Szp8/H+Xl5fbbYb02aiGftTa8AzgCiryyqxac608ar26rBb17UBhQAttNNwF5ecAzz+jdEtKKGQtlg715ckxMDKxWK4qLi10eLy4uRlxcXJPn79+/HwcPHsSUKVPsj9l+XSkmODgYu3fvRp8+fZq8LiwsDGFaLe1JqvIkoHTqBEREiKGgI0eAvn3Vb5de9Scy+YfFzz+L4ab27bW9PmtQApvFAkyYoHcrSEtmDChe9aCEhoZixIgRyMvLsz9ms9mQl5eH9PT0Js8fOHAgfvrpJ2zbts1+u+qqq3DJJZdg27ZtHLoJAK3N4AHED0uth3n0msEjS0gQN5sN+OEH7a/PHhSiwCL32m7frt/sQW95PcSTm5uLZcuW4bXXXkNBQQFmz56Nqqoq5OTkAACysrIwf/58AEB4eDhSUlJcbh07dkRkZCRSUlIQGhqq7L+GDMeTHhRA+9Vk9e5BAfSd+sciWaLA4jx7cPt2vVvjGa+GeABg2rRpKC0txYIFC1BUVITU1FSsX7/eXjhbWFiIIC6sQL/yNKAEWg8KILpcP/pIny5X9qAQBRaLRfzMWb9e/MyRh3yMzOuAAgDz5s3DvHnz3H5vw4YNLb721VdfbcslyaSMGlCM0IOi55gwAwpR4HEOKGbArg5SlREDSkODY80VPXtQ5CGevXuBsjJtr80iWaLAY7YVZRlQSDV1dYA84ctIAeX4cbGaYnAwEB+v/vWa06UL0KuXON6yRbvr1tSIvVgA9qAQBRK513bnTjF70OgYUEg1RUViqfvgYKBr15afq2VAketPevQArFb1r9cSPYZ55AJZq1WfReqISB/x8eKPRZtNLHtvdAwopBp5inF8fOsb0skBpazM8de9WoxQfyLTY0VZbhRIFLjMNMzDH0+kGk/rTwAgKkrcAPX35DHCDB6ZHivKsv6EKHCZacE2BhRSjTcBBdBumMdIPSgjRojpf4WFQEmJNtfkGihEgYsBhQjGDShG6kGJjAQGDhTHWnW5cooxUeCSNw3ctw84fVrftrSGAYVUY9SAYqQeFED7YR4GFKLA1aUL0Lu3ONZy9mBbMKCQauSA0tI+PM60CCiSZKweFED7LlcGFKLAZpZhHgYUUo08i8fTHhQt9uMpLwfOnBHHRtmr0nkmjySpfz0WyRIFNrPM5GFAIdUYcYhH7j2JiQHat1fvOt4YNkysFVNcrP4MJoBFskSBjj0oFNAqKhzrmbQloKjVk2C0+hMAaNcOSEkRx1r8wOAQD1FgGz5czB48fNix2rcRMaCQKuTek+hoz3sq5IBSWSmGYtRgtPoTmZZ/0TCgEAW2yEhg0CBxbORhHgYUUoW3wzsAEBEBdO4sjtUa5jFiDwqg7Zgwa1CISI9FIr3FgEKq8HYGj0ztOhSj96CoXSh77pxjkzD2oBAFLjPUoTCgkCq8ncEjUzugGLUHJSUFCA8XexHt26fedbhRIBEB2s8ebAsGFFJFW4Z4AEdAUWs2i1F7UEJCgNRUcazmMI9z/YnFot51iMjY5NmDJSXa7CLfFgwopApfA4oa/8PU1ADHj4tjo/WgANqMCbP+hIgA0WM7ZIg4NuowDwMKqcKIAUXulQkPB7p2Vf78vtJiTJhroBCRzOh1KAwopAojBhTn+hMjDm/IPyy2bgUaGtS5BqcYE5HM6CvKMqCQ4urrgaIicezLLB6lC7eMWn8i698f6NABqK4GCgrUuQYDChHJnAtlbTZ92+IOAwoprqREfNitViA21rvXyj0u5845hiOUYtQZPDKr1bEVulpdrgwoRCQ77zwx5F1eru7swbZiQCHFycM7cXHil643wsKAbt3EsdLDPEbvQQFc/6JRA4tkiUim1ezBtmJAIcW1tf5EplYditF7UAD1Z/KwSJaInBm5UDZY7wboqaBADCWEhQGhoe7vve0BIGUCypYtgd2D8uOPQG2t+BwqiUM8ROSMAcWgbr0V+Oablp8TFNRygGkcZpSYHWKxADfcIG5mZMQeFEkyRw9Kr15iP6JTp4CffnLUpCiFAYWInMkB5YcfxASHYAOlAgM1RXtdugDx8WIBr9pacV9X5/ocmw04e1bctLRpEzBjhjGnw7amrfvwyNQIKCUl4r+vxQL06KHceZVmsYhhns8+E3/RqBVQWINCRICYPRgZCZw5I0YV5MXbjCCgA8pHHzV9TJJEWJEDizf39fW+t0mSRM/OqVPiF72Rf5k2p6378MjUCChy70l8vPLDJkq74AJHQLn9duXOe/asmMIMsAeFiISgICA9XfzxUlGhd2tcBXRAccdicQzdREbq04annwZ+/ll08ZsxoBhxiMcM9ScytcaE5QLZ4GAgKkrZcxORea1fb8zees7iMaChQ8X99u36tqOtlAooR48qt3iQGepPZHJA+flnR4+HErhRIBG5Y9SfBwwoBiSPAZoxoFRWOroJ2xpQEhJEt2NdnagdUYKZelASEsRQlM0mCteUwgJZIjITBhQDMnMPitx7EhnZ9iGy4GDxCxpQbpjHTD0ogDrDPCyQJSIzYUAxIDmg7Nolim/NxNcZPDKl61DM1IMCqLOiLBdpIyIzYUAxoB49gI4dxaygXbv0bo13fJ3BI5OLgwO1B0WNFWU5xENEZsKAYkAWi3nrUHwtkJUp2YNSVeXoPTBLD4ocUPbsAcrKlDknAwoRmQkDikGZtQ7FiAFF7j2JigKio30/nxZiYsSqsgCwdasy52QNChGZCQOKQckB5aef9G2Ht4wYUMxWfyJTepiHNShEZCYMKAbFHhRxr2QPilnqT2RKzeSRJKC42PHfhgGFiMyAK8ka1Hnniftjx0TXvFl+qSg9i+fYMd83sJIDitl6UDydySNJYmuEgweBAwfc3zvvJWWWzxIRBTYGFIOKjAR69wZ++UUM81xyid4tap3NBhw/Lo597UGJjRWhpL5enFMOLG0hD/GYrQdl+HBRMH3oELB/v1gEr7kQcuZMy+eyWMR/kzFjgPPP16DxREQ+YkAxsKFDzRVQSkqAhgaxCmxcnG/nslrFL9RDh8Qwjy8Bxaw9KFFRwIABYqp5376tPz82VhTW9uoFJCe73icmiv2liIjMggHFwIYOBT74wDx1KPLwjtz74avERBFQjhzx7Txm7UEBgClTHGvhdOniCByNQ0hSEhARoWNDiYgU1qYi2SVLliA5ORnh4eFIS0vD5s2bm33u+++/j5EjR6Jjx45o3749UlNTsWrVqjY3OJCYbS0UpQpkZUoUyjY0OAKO2XpQAOCJJ8TwTnm5qEX6/nvg3XeBJ58E5swBrrgCGDSI4YSI/I/XAWX16tXIzc3FwoULsXXrVgwbNgyZmZkoaWZXt86dO+PPf/4z8vPzsX37duTk5CAnJweffvqpz433d/JMnh07xC9aozNiQDl2TLx3wcG+DzvpIShI1CJFRendEiIibXkdUBYvXoxZs2YhJycHgwcPxtKlSxEREYEVK1a4ff748eNx9dVXY9CgQejTpw/uuusuDB06FBs3bvS58f6uTx+gXTsxA+OXX/RuTeuUmsEjUyKgyPUniYmiroWIiMzBq4BSW1uLLVu2ICMjw3GCoCBkZGQgPz+/1ddLkoS8vDzs3r0bF198cbPPq6mpQUVFhcstEFmtQEqKODbDMI9S+/DIlAgoZq4/ISIKZF4FlBMnTqChoQGxsbEuj8fGxqKoqKjZ15WXl6NDhw4IDQ3F5MmT8cILL+DSSy9t9vmLFi1CdHS0/ZboyxQOkzNTHYrSQzxKbBho1hk8RESBTpOVZCMjI7Ft2zZ89913+Mtf/oLc3Fxs2LCh2efPnz8f5eXl9tthpba0NSEzrSirVg1KcTFQW9u2c7AHhYjInLyaDBoTEwOr1Yri4mKXx4uLixHXQgViUFAQ+v66kENqaioKCgqwaNEijB8/3u3zw8LCEMZFGwCYa08epQNK165i7Y6aGnFuefM8b7AHhYjInLzqQQkNDcWIESOQl5dnf8xmsyEvLw/p6eken8dms6GmpsabSwcseYhHXknUqKqrgbIycaxUQLFYfB/mYQ8KEZE5eb2cVm5uLrKzszFy5EiMGjUKzz77LKqqqpCTkwMAyMrKQvfu3bFo0SIAop5k5MiR6NOnD2pqarBu3TqsWrUKL7/8srL/Ej8VEwPEx4vl3nfsAC68UO8WuSf3nkREKDslNjFRhLO2BBRJMu9OxkREgc7rgDJt2jSUlpZiwYIFKCoqQmpqKtavX28vnC0sLERQkKNjpqqqCnPmzMGRI0fQrl07DBw4EK+//jqmTZum3L/Czw0dKgLK9u3GDSjOM3gsFuXO68tMnrIyR69TANdZExGZUpsWJJ83bx7mzZvn9nuNi18fe+wxPPbYY225DP1q6FDg00+NXYeidP2JzJeAItefdO3KlVaJiMxGk1k85BszTDVWO6C0ZT8e1p8QEZkXA4oJOE81liR929IcI/egsP6EiMh8GFBMYOBAsZdMWZnvO/uqRell7mW+BBT2oBARmRcDigmEhYmQAhi3DkXtHpQTJ8SeRN5gDwoRkXkxoJiE0etQ1AooHTsC7duLY297j9iDQkRkXgwoJmHkJe9tNjENGlA+oPiyWBt7UIiIzIsBxSSMHFBOnADq6kSYiI9X/vxtqUOpqXGEJvagEBGZDwOKScgBZfdu8cvXSOThnW7dgJAQ5c/floAiDwe1aydW4yUiInNhQDGJ7t1FPUZ9PbBrl96tcaXWDB5ZWwKKc/2JkivbEhGRNhhQTMJiMe4wj1oFsrK2BBTWnxARmRsDionIAcVoU42NGFA4g4eIyNwYUEzEqD0ozhsFqoE9KEREgYcBxUSMuhaKVj0o5eXAmTOevYY9KERE5saAYiIpKeL++HExtdco1A4okZFAdLQ49nSxNvagEBGZGwOKiXToAPTpI46NVIei9iwewLthHpvNEVDYg0JEZE4MKCZjtDqUs2eBU6fEsVo9KIB3AaW0VKwV47wKLRERmQsDiskYrQ5FLpANDwc6dVLvOt4EFLn+JCFBnYXjiIhIfQwoJmO0HhTnGTxqLojmzX48rD8hIjI/BhSTkQPKzz8DDQ36tgVQv0BW1pYeFNafEBGZFwOKyfTuLfaXOXsW2L9f79YYM6CwB4WIyPwYUEzGanVMNzbCMI8WM3gA14AiSS0/lz0oRETmx4BiQkaqQ9GqB0WuQamqAsrKWn4ue1CIiMyPAcWEjLQnj1YBJSIC6NJFHLc2zMMeFCIi82NAMSEjTTVWex8eZ57UoVRWOtZlYQ8KEZF5MaCYkBxQfvnF871p1CBJxgso8vBOdDQQFaV+m4iISB0MKCYUE+MoSt2xQ792nDwpVmwFgPh49a8nB5SW9uNh/QkRkX9gQDEpI9ShyPUnMTFAWJj61/OkB4X1J0RE/oEBxaSMUIeiVYGszJshHgYUIiJzY0AxKSNMNTZiQJF7UDjEQ0RkbgwoJuUcUFpbuEwtWhbIAo61UI4caf7fzB4UIiL/wIBiUgMHAsHBQHl5y0WjatK6B0W+zrlzwIkT7p/DHhQiIv/AgGJSoaEipAD6DfNoHVDCwoDYWHHsbpinvt7RJvagEBGZGwOKieldh6LVPjzOWqpDOXZM7PAcEqLNtGciIlIPA4qJGSWgaNWDArQcUOT6kx49gCB+somITI0/xk1Mz7VQamocdSBGCSisPyEi8h8MKCYmr4Wya5djRVetHD8u7sPCHJv4acGTHhTWnxARmR8Diol17w506iTqLgoKtL22c/2JxaLdddmDQkQUGBhQTMxi0a8ORY/6E6Dl/XjYg0JE5D8YUExOrzoUPWbwAI6AcvQoYLO5fo89KERE/oMBxeT02pNHrx6U+HgxQ6euDigudjwuSexBISLyJwwoJhdoQzzBwY5eG+c6lNOngcpKccyAQkRkfgwoJnfeeaIWpagIKC3V7rpa78PjTN6TxzmgyL0nXbsC7dpp3yYiIlJWmwLKkiVLkJycjPDwcKSlpWHz5s3NPnfZsmUYO3YsOnXqhE6dOiEjI6PF55N3OnQAevcWx1rWoejVgwK4n8nD+hMiIv/idUBZvXo1cnNzsXDhQmzduhXDhg1DZmYmSkpK3D5/w4YNuP766/Hll18iPz8fiYmJuOyyy3BU/g1HPtN6mEeSjBdQWH9CRORfvA4oixcvxqxZs5CTk4PBgwdj6dKliIiIwIoVK9w+/4033sCcOXOQmpqKgQMH4h//+AdsNhvy8vKavUZNTQ0qKipcbtQ8rQPK6dNiR2FAnz1v2INCROT/vAootbW12LJlCzIyMhwnCApCRkYG8vPzPTpHdXU16urq0Llz52afs2jRIkRHR9tvifJvJHJL64Ai95507qxPvQd7UIiI/J9XAeXEiRNoaGhArLzn/a9iY2NRVFTk0Tnuu+8+JCQkuIScxubPn4/y8nL77bC7ZUPJTp5q/PPPYlVZtek5vAOwB4WIKBAEa3mxJ554Am+//TY2bNiA8PDwZp8XFhaGsLAwDVtmbr17AxERQHU1sG8fMGCAutfTcwYP4Agox48D9fVi6jF7UIiI/ItXPSgxMTGwWq0odl4hC0BxcTHi4uJafO3TTz+NJ554Ap999hmGymMSpAirFUhJEcdaDPPo3YMSGwuEhIiVZI8dE/Uwcgcee1CIiPyDVwElNDQUI0aMcClwlQte09PTm33dk08+iUcffRTr16/HyJEj295aapaWdSh6B5SgIMe1Dx927MvTrp22OysTEZF6vB7iyc3NRXZ2NkaOHIlRo0bh2WefRVVVFXJycgAAWVlZ6N69OxYtWgQA+Otf/4oFCxbgzTffRHJysr1WpUOHDujQoYOC/5TAJtehaLEWil778DhLTAQOHhThRJ5RlJSk7c7KRESkHq8DyrRp01BaWooFCxagqKgIqampWL9+vb1wtrCwEEFBjo6Zl19+GbW1tbjuuutczrNw4UI89NBDvrWe7AKpBwVwLZStrhbHrD8hIvIfbSqSnTdvHubNm+f2exs2bHD5+uDBg225BHlJ7kE5cACoqACiotS7ltECirwHD+tPiIj8B/fi8RNdujgCw44d6l2nthaQFw3WM6A478fDGTxERP6HAcWPaFGHIs+WCQkBYmLUu05rnHtQuAYKEZH/YUDxI1rUoTgXyAbp+OlxDijsQSEi8j+aLtRG6tI6oOhJDijFxcCpU+KYPShERP6DPSh+RA4oP/0kdhxWgxEKZAExvCQvRlxX57o2ChERmR8Dih8ZMEAs+15e7rpPjZKMElAsFkehLCB6dEJC9GsPEREpiwHFj4SGAoMGiWO1hnmMElAAxzAPwPoTIiJ/w4DiZ9SuQ9F7o0BnzgGF9SdERP6FAcXPyFON2YNCRERmxoDiZ5wLZZUmScaZxQOwB4WIyJ8xoPgZOaDs3u3YRE8p5eWOfW/Yg0JERGpiQPEzCQlA585AQwNQUKDsueXek44dgYgIZc/dFuxBISLyXwwofsZiUa8OxUj1J4DoNQkKAqxW9qAQEfkbriTrh4YOBb76Svk6FCPN4AGA6GhgxQoRUtTcvZmIiLTHgOKH1JpqbLQeFADIzta7BUREpAYO8fghtQOKEWbwEBGRf2NA8UPnnSdqUYqLgZIS5c5rxB4UIiLyTwwofqh9e6BPH3GsZB0KAwoREWmFAcVPqTHMw4BCRERaYUDxU0oHlPp6MWQEMKAQEZH6GFD8lNJroRQViaXurVagWzdlzklERNQcBhQ/Jfeg7Nwpej98JQ/vxMeLdUeIiIjUxF81fqp3b7Ec/blzwL59vp+P9SdERKQlBhQ/FRSk7DAPAwoREWmJK8n6sSFDgE2bgOefB775xrdzffutuGdAISIiLTCg+LGRI4F//AP43//ETQny+ipERERqYkDxY1lZQGUlcOqUMufr2BG45RZlzkVERNQSBhQ/1q4d8H//p3criIiIvMciWSIiIjIcBhQiIiIyHAYUIiIiMhwGFCIiIjIcBhQiIiIyHAYUIiIiMhwGFCIiIjIcBhQiIiIyHAYUIiIiMhwGFCIiIjIcBhQiIiIyHAYUIiIiMhwGFCIiIjIcU+xmLEkSAKCiokLnlhAREZGn5N/b8u9xb5gioJw5cwYAkJiYqHNLiIiIyFtnzpxBdHS0V6+xSG2JNRqz2Ww4duwYIiMjYbFYFDtvRUUFEhMTcfjwYURFRSl2XmoZ33d98H3XB993ffB910fj912SJJw5cwYJCQkICvKuqsQUPShBQUHo0aOHauePioriB1gHfN/1wfddH3zf9cH3XR/O77u3PScyFskSERGR4TCgEBERkeEEdEAJCwvDwoULERYWpndTAgrfd33wfdcH33d98H3Xh5LvuymKZImIiCiwBHQPChERERkTAwoREREZDgMKERERGQ4DChERERkOAwoREREZTkAHlCVLliA5ORnh4eFIS0vD5s2b9W6SX3vooYdgsVhcbgMHDtS7WX7nv//9L6ZMmYKEhARYLBZ88MEHLt+XJAkLFixAfHw82rVrh4yMDOzdu1efxvqR1t73m2++ucnn//LLL9ensX5i0aJFuOCCCxAZGYlu3bph6tSp2L17t8tzzp07h7lz56JLly7o0KEDrr32WhQXF+vUYv/gyfs+fvz4Jp/322+/3avrBGxAWb16NXJzc7Fw4UJs3boVw4YNQ2ZmJkpKSvRuml8777zzcPz4cftt48aNejfJ71RVVWHYsGFYsmSJ2+8/+eSTeP7557F06VJs2rQJ7du3R2ZmJs6dO6dxS/1La+87AFx++eUun/+33npLwxb6n6+++gpz587Ft99+i88//xx1dXW47LLLUFVVZX/OPffcg48//hjvvvsuvvrqKxw7dgzXXHONjq02P0/edwCYNWuWy+f9ySef9O5CUoAaNWqUNHfuXPvXDQ0NUkJCgrRo0SIdW+XfFi5cKA0bNkzvZgQUANKaNWvsX9tsNikuLk566qmn7I+VlZVJYWFh0ltvvaVDC/1T4/ddkiQpOztb+s1vfqNLewJFSUmJBED66quvJEkSn+2QkBDp3XfftT+noKBAAiDl5+fr1Uy/0/h9lyRJGjdunHTXXXf5dN6A7EGpra3Fli1bkJGRYX8sKCgIGRkZyM/P17Fl/m/v3r1ISEhA7969ccMNN6CwsFDvJgWUAwcOoKioyOWzHx0djbS0NH72NbBhwwZ069YNAwYMwOzZs3Hy5Em9m+RXysvLAQCdO3cGAGzZsgV1dXUun/eBAweiZ8+e/LwrqPH7LnvjjTcQExODlJQUzJ8/H9XV1V6d1xS7GSvtxIkTaGhoQGxsrMvjsbGx2LVrl06t8n9paWl49dVXMWDAABw/fhwPP/wwxo4dix07diAyMlLv5gWEoqIiAHD72Ze/R+q4/PLLcc0116BXr17Yv38//vSnP+GKK65Afn4+rFar3s0zPZvNhrvvvhtjxoxBSkoKAPF5Dw0NRceOHV2ey8+7cty97wAwY8YMJCUlISEhAdu3b8d9992H3bt34/333/f43AEZUEgfV1xxhf146NChSEtLQ1JSEt555x3MnDlTx5YRqW/69On24yFDhmDo0KHo06cPNmzYgIkTJ+rYMv8wd+5c7Nixg3VtGmvufb/tttvsx0OGDEF8fDwmTpyI/fv3o0+fPh6dOyCHeGJiYmC1WptUchcXFyMuLk6nVgWejh07on///ti3b5/eTQkY8uebn3399e7dGzExMfz8K2DevHn45JNP8OWXX6JHjx72x+Pi4lBbW4uysjKX5/Pzrozm3nd30tLSAMCrz3tABpTQ0FCMGDECeXl59sdsNhvy8vKQnp6uY8sCS2VlJfbv34/4+Hi9mxIwevXqhbi4OJfPfkVFBTZt2sTPvsaOHDmCkydP8vPvA0mSMG/ePKxZswZffPEFevXq5fL9ESNGICQkxOXzvnv3bhQWFvLz7oPW3nd3tm3bBgBefd4DdognNzcX2dnZGDlyJEaNGoVnn30WVVVVyMnJ0btpfusPf/gDpkyZgqSkJBw7dgwLFy6E1WrF9ddfr3fT/EplZaXLXykHDhzAtm3b0LlzZ/Ts2RN33303HnvsMfTr1w+9evXCgw8+iISEBEydOlW/RvuBlt73zp074+GHH8a1116LuLg47N+/H/feey/69u2LzMxMHVttbnPnzsWbb76JDz/8EJGRkfa6kujoaLRr1w7R0dGYOXMmcnNz0blzZ0RFReGOO+5Aeno6LrzwQp1bb16tve/79+/Hm2++iUmTJqFLly7Yvn077rnnHlx88cUYOnSo5xfyaQ6Qyb3wwgtSz549pdDQUGnUqFHSt99+q3eT/Nq0adOk+Ph4KTQ0VOrevbs0bdo0ad++fXo3y+98+eWXEoAmt+zsbEmSxFTjBx98UIqNjZXCwsKkiRMnSrt379a30X6gpfe9urpauuyyy6SuXbtKISEhUlJSkjRr1iypqKhI72abmrv3G4C0cuVK+3POnj0rzZkzR+rUqZMUEREhXX311dLx48f1a7QfaO19LywslC6++GKpc+fOUlhYmNS3b1/pj3/8o1ReXu7VdSy/XoyIiIjIMAKyBoWIiIiMjQGFiIiIDIcBhYiIiAyHAYWIiIgMhwGFiIiIDIcBhYiIiAyHAYWIiIgMhwGFiIiIDIcBhYiIiAyHAYWIiIgMhwGFiIiIDOf/AbU59DSGRHjIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO flwr 2023-06-08 16:28:14,276 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=25, round_timeout=None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing Strategy... :  Fedyogi\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=78561)\u001b[0m Epoch 50: train loss 0.30116066336631775, accuracy 0.9830047586675731\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=78560)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=78561)\u001b[0m 2023-06-08 16:08:52.757996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-08 16:28:20,431\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-08 16:28:22,108 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'memory': 7845467751.0, 'object_store_memory': 3922733875.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'memory': 7845467751.0, 'object_store_memory': 3922733875.0}\n",
            "INFO flwr 2023-06-08 16:28:22,122 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-08 16:28:22,125 | server.py:269 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2023-06-08 16:28:22,130 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-08 16:28:22,137 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-08 16:28:22,139 | server.py:218 | fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 4 clients (out of 4)\n",
            "\u001b[2m\u001b[36m(pid=89122)\u001b[0m 2023-06-08 16:28:24.471579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.025299381464719772, accuracy 0.469068660774983\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 9: train loss 0.007121688220649958, accuracy 0.849082256968049\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 10: train loss 0.006558872759342194, accuracy 0.8626784500339905\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 25: train loss 0.0026019816286861897, accuracy 0.9524133242692047\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 40: train loss 0.0014654999831691384, accuracy 0.9768864717878993\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 48: train loss 0.0011576071847230196, accuracy 0.9809653297076818\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 13: train loss 0.005140591878443956, accuracy 0.8898708361658736\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 16: train loss 0.0041932640597224236, accuracy 0.9089055064581917\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 28: train loss 0.002284594578668475, accuracy 0.9530931339225017\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 36: train loss 0.0017805756069719791, accuracy 0.9632902787219578\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:29:10,957 | server.py:232 | fit_round 1 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 4 results and 0 failures\n",
            "WARNING flwr 2023-06-08 16:29:10,982 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 16:29:10,999 | server.py:168 | evaluate_round 1: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 50: train loss 0.0011559062404558063, accuracy 0.9755268524813052\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:29:11,280 | server.py:182 | evaluate_round 1 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 3 results and 0 failures\n",
            "WARNING flwr 2023-06-08 16:29:11,285 | fedavg.py:274 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 16:29:11,292 | server.py:218 | fit_round 2: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 13: train loss 0.002757374197244644, accuracy 0.9564921821889871\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 14: train loss 0.0026006654370576143, accuracy 0.9605710401087696\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 23: train loss 0.0016778614372015, accuracy 0.9741672331747111\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 38: train loss 0.0010851917322725058, accuracy 0.9775662814411965\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.009583162143826485, accuracy 0.8959891230455472\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 9: train loss 0.0034996126778423786, accuracy 0.9313392250169953\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 11: train loss 0.0030520884320139885, accuracy 0.9428959891230455\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 26: train loss 0.0014676798600703478, accuracy 0.9782460910944936\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 41: train loss 0.001032590982504189, accuracy 0.9830047586675731\u001b[32m [repeated 29x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:29:52,086 | server.py:232 | fit_round 2 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:29:52,116 | server.py:168 | evaluate_round 2: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 3 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 49: train loss 0.0007604471757076681, accuracy 0.9870836165873556\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:29:52,346 | server.py:182 | evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:29:52,351 | server.py:218 | fit_round 3: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 14: train loss 0.0012508536456152797, accuracy 0.9768864717878993\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 15: train loss 0.0012149056419730186, accuracy 0.9768864717878993\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 16: train loss 0.0011802013032138348, accuracy 0.9775662814411965\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 0.0008623242611065507, accuracy 0.9809653297076818\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 39: train loss 0.0007138351793400943, accuracy 0.9864038069340585\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 0.0017683159094303846, accuracy 0.9687287559483345\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 15: train loss 0.0011318499455228448, accuracy 0.9830047586675731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 0.0009808448376134038, accuracy 0.9857239972807614\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 28: train loss 0.0008180011645890772, accuracy 0.9843643779741672\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 0.0005043819546699524, accuracy 0.9932019034670292\u001b[32m [repeated 31x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:30:30,152 | server.py:232 | fit_round 3 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:30:30,189 | server.py:168 | evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:30:30,432 | server.py:182 | evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:30:30,436 | server.py:218 | fit_round 4: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 7: train loss 0.0009281127131544054, accuracy 0.9782460910944936\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 11: train loss 0.0008497678791172802, accuracy 0.982324949014276\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.0008497678791172802, accuracy 0.982324949014276\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 16: train loss 0.0007816603174433112, accuracy 0.982324949014276\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 31: train loss 0.0007385700009763241, accuracy 0.9782460910944936\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 46: train loss 0.0007762113818898797, accuracy 0.982324949014276\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 0.0008233042317442596, accuracy 0.982324949014276\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.000612997857388109, accuracy 0.9877634262406526\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 21: train loss 0.00044551308383233845, accuracy 0.9925220938137321\u001b[32m [repeated 32x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 36: train loss 0.0005431412719190121, accuracy 0.9884432358939497\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 45: train loss 0.0002939093392342329, accuracy 0.9959211420802175\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:31:10,554 | server.py:232 | fit_round 4 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:31:10,584 | server.py:168 | evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:31:10,819 | server.py:182 | evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:31:10,828 | server.py:218 | fit_round 5: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 0.0010673515498638153, accuracy 0.9796057104010877\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 15: train loss 0.0007116881315596402, accuracy 0.9850441876274643\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 15: train loss 0.0007116881315596402, accuracy 0.9850441876274643\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 23: train loss 0.0007884644437581301, accuracy 0.9802855200543847\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 32: train loss 0.001128694973886013, accuracy 0.9748470428280082\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 48: train loss 0.0010986095294356346, accuracy 0.973487423521414\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 13: train loss 0.0015005354071035981, accuracy 0.973487423521414\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 14: train loss 0.0012799054384231567, accuracy 0.973487423521414\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 22: train loss 0.0015547681832686067, accuracy 0.9694085656016316\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 0.0006715800263918936, accuracy 0.9891230455472467\u001b[32m [repeated 31x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:31:49,111 | server.py:232 | fit_round 5 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:31:49,141 | server.py:168 | evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:31:49,414 | server.py:182 | evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:31:49,420 | server.py:218 | fit_round 6: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 50: train loss 0.0004480370262172073, accuracy 0.990482664853841\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 7: train loss 0.0020470181480050087, accuracy 0.9694085656016316\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 0.001225458923727274, accuracy 0.9802855200543847\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 20: train loss 0.0018175099976360798, accuracy 0.9748470428280082\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 35: train loss 0.0006838636472821236, accuracy 0.9884432358939497\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 41: train loss 0.000548963260371238, accuracy 0.991162474507138\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.0011553991353139281, accuracy 0.9796057104010877\u001b[32m [repeated 26x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 11: train loss 0.000970229331869632, accuracy 0.9830047586675731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 14: train loss 0.000931061920709908, accuracy 0.9857239972807614\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 18: train loss 0.002831644844263792, accuracy 0.9626104690686608\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 32: train loss 0.0009092984837479889, accuracy 0.9802855200543847\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 0.0006497989525087178, accuracy 0.9850441876274643\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:32:37,421 | server.py:232 | fit_round 6 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:32:37,470 | server.py:168 | evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:32:37,798 | server.py:182 | evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:32:37,804 | server.py:218 | fit_round 7: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.002349560847505927, accuracy 0.973487423521414\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 7: train loss 0.0028649638406932354, accuracy 0.9653297076818491\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 0.003085975768044591, accuracy 0.964649898028552\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 0.0010663711000233889, accuracy 0.9850441876274643\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 25: train loss 0.00037290112231858075, accuracy 0.9952413324269205\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 33: train loss 0.00029482951504178345, accuracy 0.9959211420802175\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 44: train loss 0.00020203078747726977, accuracy 0.9966009517335146\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 0.00042982999002560973, accuracy 0.991162474507138\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 9: train loss 0.0008471615728922188, accuracy 0.9864038069340585\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 19: train loss 0.0006725536077283323, accuracy 0.9884432358939497\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 27: train loss 0.0006065914640203118, accuracy 0.9884432358939497\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 23: train loss 0.0006965750362724066, accuracy 0.9898028552005439\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 33: train loss 0.0005108631448820233, accuracy 0.990482664853841\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 0.0003675936895888299, accuracy 0.9932019034670292\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:33:41,840 | server.py:232 | fit_round 7 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:33:41,869 | server.py:168 | evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:33:42,100 | server.py:182 | evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:33:42,109 | server.py:218 | fit_round 8: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 2: train loss 0.0010588612640276551, accuracy 0.9843643779741672\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 6: train loss 0.0011311224661767483, accuracy 0.9830047586675731\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 0.0013340205186977983, accuracy 0.9809653297076818\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 10: train loss 0.00087843177607283, accuracy 0.9864038069340585\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 14: train loss 0.0003531710826791823, accuracy 0.9945615227736234\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 0.0011750609846785665, accuracy 0.9789259007477906\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 26: train loss 0.0017849766882136464, accuracy 0.9755268524813052\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 0.0022636449430137873, accuracy 0.964649898028552\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 37: train loss 0.0018377675442025065, accuracy 0.9755268524813052\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 45: train loss 0.0001464958768337965, accuracy 0.9986403806934059\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 47: train loss 0.00037294687354005873, accuracy 0.9918422841604351\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 6: train loss 0.0014020876260474324, accuracy 0.9830047586675731\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 0.001487614936195314, accuracy 0.9789259007477906\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 12: train loss 0.001066535827703774, accuracy 0.9857239972807614\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 17: train loss 0.0009905054466798902, accuracy 0.9850441876274643\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 23: train loss 0.0005266732769086957, accuracy 0.9932019034670292\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 29: train loss 0.00037975123268552125, accuracy 0.9945615227736234\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 36: train loss 0.0002807249256875366, accuracy 0.9959211420802175\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 0.00020888731523882598, accuracy 0.9966009517335146\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 0.00046307529555633664, accuracy 0.9877634262406526\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:35:12,734 | server.py:232 | fit_round 8 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:35:12,764 | server.py:168 | evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:35:12,976 | server.py:182 | evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:35:12,982 | server.py:218 | fit_round 9: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 2: train loss 0.0013919182820245624, accuracy 0.981645139360979\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 6: train loss 0.0008945684530772269, accuracy 0.9864038069340585\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.0008945684530772269, accuracy 0.9864038069340585\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 8: train loss 0.000777930545154959, accuracy 0.9891230455472467\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.001188754104077816, accuracy 0.981645139360979\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 17: train loss 0.0016273920191451907, accuracy 0.9748470428280082\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 24: train loss 0.0002087086468236521, accuracy 0.9959211420802175\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 28: train loss 0.00032039647339843214, accuracy 0.9952413324269205\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 34: train loss 0.00023371822317130864, accuracy 0.9966009517335146\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 38: train loss 0.00020078949455637485, accuracy 0.9966009517335146\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 44: train loss 9.446688636671752e-05, accuracy 0.9986403806934059\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 50: train loss 0.00046809198101982474, accuracy 0.9877634262406526\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.0009472369565628469, accuracy 0.9843643779741672\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 0.0009472369565628469, accuracy 0.9843643779741672\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 10: train loss 0.0005840981029905379, accuracy 0.9891230455472467\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 16: train loss 0.0004285542818251997, accuracy 0.9898028552005439\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 20: train loss 0.0003523303603287786, accuracy 0.9952413324269205\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 26: train loss 0.00021513040701393038, accuracy 0.9959211420802175\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 0.00016195578791666776, accuracy 0.9966009517335146\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 36: train loss 0.00036980584263801575, accuracy 0.991162474507138\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 41: train loss 0.0005260933539830148, accuracy 0.9857239972807614\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 0.0010583207476884127, accuracy 0.981645139360979\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:36:59,685 | server.py:232 | fit_round 9 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:36:59,718 | server.py:168 | evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:36:59,949 | server.py:182 | evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:36:59,953 | server.py:218 | fit_round 10: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 50: train loss 0.00013394595589488745, accuracy 0.9972807613868117\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 5: train loss 0.0007864237413741648, accuracy 0.9898028552005439\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.0003838005068246275, accuracy 0.9952413324269205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 9: train loss 0.00025364605244249105, accuracy 0.9966009517335146\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 0.00014450063463300467, accuracy 0.9966009517335146\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 20: train loss 0.0004930717404931784, accuracy 0.990482664853841\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 24: train loss 0.0008970513590611517, accuracy 0.982324949014276\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 28: train loss 0.00032783238566480577, accuracy 0.9925220938137321\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 32: train loss 0.00036758361966349185, accuracy 0.9925220938137321\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 38: train loss 2.138747186108958e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 44: train loss 1.3007389497943223e-05, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 48: train loss 1.1583528248593211e-05, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.0009384251898154616, accuracy 0.982324949014276\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.0008181448793038726, accuracy 0.9850441876274643\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 9: train loss 0.0006354807992465794, accuracy 0.9932019034670292\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 14: train loss 0.0006136830779723823, accuracy 0.9877634262406526\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 20: train loss 0.0005432245088741183, accuracy 0.9898028552005439\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 24: train loss 0.0005146418116055429, accuracy 0.9891230455472467\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 0.0005137473926879466, accuracy 0.9898028552005439\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 0.0005165101611055434, accuracy 0.9891230455472467\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 39: train loss 0.0005095773376524448, accuracy 0.9891230455472467\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 45: train loss 0.0005037838709540665, accuracy 0.9918422841604351\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:38:48,645 | server.py:232 | fit_round 10 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:38:48,681 | server.py:168 | evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:38:48,964 | server.py:182 | evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:38:48,972 | server.py:218 | fit_round 11: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 50: train loss 6.400852726073936e-05, accuracy 0.9993201903467029\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 0.0007772202370688319, accuracy 0.9850441876274643\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 0.0007772202370688319, accuracy 0.9850441876274643\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.0006866742623969913, accuracy 0.9850441876274643\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 16: train loss 0.000745854340493679, accuracy 0.9850441876274643\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 19: train loss 0.00010276032116962597, accuracy 0.9972807613868117\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 27: train loss 0.000224891904508695, accuracy 0.9972807613868117\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 5.973316729068756e-05, accuracy 0.9986403806934059\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 37: train loss 0.00011433794861659408, accuracy 0.9972807613868117\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 5.06433607370127e-05, accuracy 0.9986403806934059\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 48: train loss 3.463780740275979e-05, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 49: train loss 0.0002005035785259679, accuracy 0.9952413324269205\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 6: train loss 0.0002347625995753333, accuracy 0.9952413324269205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 10: train loss 0.00015194252773653716, accuracy 0.9966009517335146\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 10: train loss 0.00042619238956831396, accuracy 0.9932019034670292\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 20: train loss 8.490924665238708e-05, accuracy 0.9979605710401088\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 26: train loss 0.00027294582105241716, accuracy 0.9959211420802175\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 28: train loss 0.00013637430674862117, accuracy 0.9972807613868117\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 7.594354246975854e-05, accuracy 0.9986403806934059\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 41: train loss 1.2831942513003014e-05, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 6.099193706177175e-05, accuracy 0.9986403806934059\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:40:31,853 | server.py:232 | fit_round 11 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:40:31,888 | server.py:168 | evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:40:32,108 | server.py:182 | evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:40:32,116 | server.py:218 | fit_round 12: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 2: train loss 0.0007442830828949809, accuracy 0.9870836165873556\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 4: train loss 0.00021680325153283775, accuracy 0.9966009517335146\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 0.00033700416679494083, accuracy 0.9938817131203264\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 6: train loss 0.0001323256001342088, accuracy 0.9972807613868117\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.0001281517033930868, accuracy 0.9972807613868117\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 19: train loss 0.0003018668794538826, accuracy 0.9938817131203264\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 21: train loss 7.736583211226389e-05, accuracy 0.9979605710401088\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 27: train loss 0.0001280453143408522, accuracy 0.9966009517335146\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 1.1782686669903342e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 40: train loss 1.016978330881102e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 0.0005375806358642876, accuracy 0.9864038069340585\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 49: train loss 3.687459320644848e-05, accuracy 0.9993201903467029\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 5: train loss 0.0007568579167127609, accuracy 0.9843643779741672\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 7: train loss 0.0007303357706405222, accuracy 0.9843643779741672\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 0.00028074023430235684, accuracy 0.9945615227736234\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 15: train loss 0.0002583256282377988, accuracy 0.9959211420802175\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 21: train loss 0.00013562098320107907, accuracy 0.9972807613868117\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 30: train loss 9.381159179611132e-05, accuracy 0.9979605710401088\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 6.342749838950112e-05, accuracy 0.9986403806934059\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 36: train loss 3.141018532915041e-05, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 42: train loss 6.951040995772928e-05, accuracy 0.9979605710401088\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 50: train loss 2.009035597438924e-05, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:42:12,815 | server.py:232 | fit_round 12 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:42:12,852 | server.py:168 | evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:42:13,073 | server.py:182 | evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:42:13,080 | server.py:218 | fit_round 13: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 2: train loss 0.0006403539446182549, accuracy 0.9877634262406526\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 8.888870797818527e-05, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 8: train loss 0.00013120997755322605, accuracy 0.9966009517335146\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 13: train loss 0.0023274067789316177, accuracy 0.9762066621346023\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 20: train loss 2.0645260519813746e-05, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 23: train loss 8.490285836160183e-05, accuracy 0.9986403806934059\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 1.2623243492271286e-05, accuracy 1.0\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 32: train loss 2.3762264390825294e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 38: train loss 1.9070170310442336e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 47: train loss 7.608683063153876e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 48: train loss 1.2295730812184047e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 0.0004623350687325001, accuracy 0.9898028552005439\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 10: train loss 0.0006159147596918046, accuracy 0.9850441876274643\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 0.0007508280104957521, accuracy 0.9857239972807614\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 22: train loss 0.00015417413669638336, accuracy 0.9972807613868117\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 18: train loss 2.5358509446959943e-05, accuracy 0.9993201903467029\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 23: train loss 1.5751646060380153e-05, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 41: train loss 2.4128748918883502e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 1.9630693714134395e-05, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 39: train loss 8.259609785454813e-06, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 47: train loss 6.526046490762383e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:43:53,985 | server.py:232 | fit_round 13 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:43:54,048 | server.py:168 | evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:43:54,406 | server.py:182 | evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:43:54,409 | server.py:218 | fit_round 14: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.0012261781375855207, accuracy 0.9877634262406526\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 5: train loss 0.00043854062096215785, accuracy 0.9877634262406526\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.00037542395875789225, accuracy 0.9918422841604351\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 0.00038449186831712723, accuracy 0.991162474507138\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 14: train loss 0.0006000269786454737, accuracy 0.9864038069340585\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 18: train loss 0.000231789774261415, accuracy 0.9945615227736234\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 24: train loss 6.346517329802737e-05, accuracy 0.9979605710401088\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 0.0005676217842847109, accuracy 0.9891230455472467\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 34: train loss 9.179299922834616e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 1.7497202861704864e-05, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 45: train loss 4.9753602979762945e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 3: train loss 0.0001625055738259107, accuracy 0.9972807613868117\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.0006564926006831229, accuracy 0.9857239972807614\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 9: train loss 0.00013883583596907556, accuracy 0.9972807613868117\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 12: train loss 0.00017508651944808662, accuracy 0.9966009517335146\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 1.221769616677193e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 25: train loss 8.793400411377661e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 30: train loss 2.9526878279284574e-05, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 37: train loss 2.0417734049260616e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 43: train loss 1.6724743545637466e-05, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 48: train loss 1.4544157238560729e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:45:32,434 | server.py:232 | fit_round 14 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:45:32,463 | server.py:168 | evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:45:32,688 | server.py:182 | evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:45:32,694 | server.py:218 | fit_round 15: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 1: train loss 0.0004008332616649568, accuracy 0.9938817131203264\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.00031856700661592185, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.00031856700661592185, accuracy 0.9925220938137321\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 11: train loss 0.00027735784533433616, accuracy 0.9918422841604351\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 18: train loss 0.0005724797956645489, accuracy 0.9843643779741672\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 22: train loss 6.590832981601125e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 9.779801621334627e-05, accuracy 0.9972807613868117\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 35: train loss 4.102740149392048e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 39: train loss 3.6493777315627085e-06, accuracy 1.0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 45: train loss 1.531005727883894e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.0007357478025369346, accuracy 0.9925220938137321\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.0003756004443857819, accuracy 0.9918422841604351\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 0.0009976048022508621, accuracy 0.9809653297076818\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 12: train loss 0.0001247414475074038, accuracy 0.9959211420802175\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 18: train loss 5.9602341934805736e-05, accuracy 0.9993201903467029\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 23: train loss 2.9758961318293586e-05, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 28: train loss 6.5059125518018845e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 1.5749095837236382e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 38: train loss 4.729579814011231e-06, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 4.038686256535584e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:47:08,246 | server.py:232 | fit_round 15 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:47:08,286 | server.py:168 | evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:47:08,628 | server.py:182 | evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:47:08,633 | server.py:218 | fit_round 16: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 50: train loss 3.4931167647300754e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 0.0001439487241441384, accuracy 0.9945615227736234\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.00016555501497350633, accuracy 0.9952413324269205\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 12: train loss 1.040766710502794e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 16: train loss 0.0004230598278809339, accuracy 0.9877634262406526\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 23: train loss 0.0011373991146683693, accuracy 0.9864038069340585\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 3.7058405723655596e-05, accuracy 0.9993201903467029\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 33: train loss 4.193401309748879e-06, accuracy 1.0\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 38: train loss 3.682247779579484e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 43: train loss 1.3040484191151336e-05, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 48: train loss 1.0587384167592973e-05, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 0.0002976172836497426, accuracy 0.9925220938137321\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 7: train loss 0.0002976172836497426, accuracy 0.9925220938137321\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 14: train loss 3.7837282434338704e-05, accuracy 0.9993201903467029\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 18: train loss 1.875821362773422e-05, accuracy 1.0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 25: train loss 1.2731844435620587e-05, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 26: train loss 5.761329703091178e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 36: train loss 8.353639714187011e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 36: train loss 4.297050963941729e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 42: train loss 3.654027295851847e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:48:45,573 | server.py:232 | fit_round 16 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:48:45,603 | server.py:168 | evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:48:45,836 | server.py:182 | evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:48:45,841 | server.py:218 | fit_round 17: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 50: train loss 2.973289383589872e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 6: train loss 0.0001556242787046358, accuracy 0.9959211420802175\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 6: train loss 0.0001556242787046358, accuracy 0.9959211420802175\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 6: train loss 0.0001556242787046358, accuracy 0.9959211420802175\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 11: train loss 0.00017972680507227778, accuracy 0.9945615227736234\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 5.223799689701991e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 26: train loss 4.181148142379243e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 3.676598225865746e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 35: train loss 4.410082510730717e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 2.432818746456178e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 3.3265857837250223e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 3: train loss 0.0008555578533560038, accuracy 0.982324949014276\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 7: train loss 0.0002213674015365541, accuracy 0.9959211420802175\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 11: train loss 2.95070894935634e-05, accuracy 0.9993201903467029\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 8.115583113976754e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 22: train loss 5.71170403418364e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 5.357145255402429e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 37: train loss 4.258301942172693e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 3.5127679893776076e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 48: train loss 3.174822040818981e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:50:16,093 | server.py:232 | fit_round 17 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:50:16,141 | server.py:168 | evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:50:16,375 | server.py:182 | evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:50:16,380 | server.py:218 | fit_round 18: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.0004700332647189498, accuracy 0.9925220938137321\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 0.00023990847694221884, accuracy 0.9959211420802175\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 0.00012418405094649643, accuracy 0.9972807613868117\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 13: train loss 1.2767438420269173e-05, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 20: train loss 8.47927003633231e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 24: train loss 4.632776835933328e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 33: train loss 5.591488388745347e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 40: train loss 4.46398871645215e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 45: train loss 3.957568424084457e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 3] fit, config: {\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 48: train loss 2.547761368987267e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 8: train loss 9.514375960861798e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 12: train loss 6.3025427152751945e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 3.6379785797180375e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 22: train loss 2.8071383439964848e-06, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 31: train loss 2.9319255645532394e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 38: train loss 2.387682798143942e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 44: train loss 2.089264626192744e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 44: train loss 1.4524761127177044e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:51:46,753 | server.py:232 | fit_round 18 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:51:46,782 | server.py:168 | evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:51:47,022 | server.py:182 | evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:51:47,031 | server.py:218 | fit_round 19: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 2: train loss 0.00031583569943904877, accuracy 0.9925220938137321\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 5.767207403550856e-05, accuracy 0.9993201903467029\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 8: train loss 3.541855767252855e-05, accuracy 0.9986403806934059\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 15: train loss 5.939226412010612e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 22: train loss 4.479719791561365e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 26: train loss 3.964074039686238e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 33: train loss 3.3517094379931223e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 40: train loss 2.8615766041184543e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 41: train loss 2.1722785277233925e-06, accuracy 1.0\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 49: train loss 2.314945504622301e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 0.0002998209383804351, accuracy 0.9932019034670292\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 3: train loss 8.9818007836584e-05, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 9: train loss 0.0003826492466032505, accuracy 0.9898028552005439\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 16: train loss 3.3540309232193977e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 2.2429871933127288e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 29: train loss 2.3968589175638044e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 32: train loss 1.6941589819907676e-06, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 41: train loss 1.9200242604711093e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 43: train loss 1.394385208186577e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:53:19,270 | server.py:232 | fit_round 19 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:53:19,305 | server.py:168 | evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:53:19,523 | server.py:182 | evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:53:19,527 | server.py:218 | fit_round 20: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 50: train loss 1.2293021427467465e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m Epoch 4: train loss 9.510575182503089e-05, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 9.510575182503089e-05, accuracy 0.9979605710401088\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 4: train loss 9.510575182503089e-05, accuracy 0.9979605710401088\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 12: train loss 4.036915470351232e-06, accuracy 1.0\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 19: train loss 3.0726059776498005e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 24: train loss 2.6603147489367984e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 31: train loss 2.1772361833427567e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 34: train loss 1.7297187469011988e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 39: train loss 1.5519284488618723e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 46: train loss 1.3531180229620077e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 1: train loss 0.00031020818278193474, accuracy 0.9945615227736234\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 0.000131171167595312, accuracy 0.9972807613868117\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 10: train loss 3.0862809126119828e-06, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 17: train loss 1.5156746258071507e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 19: train loss 2.863102508854354e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 26: train loss 2.0121872239542427e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 33: train loss 1.5370017081295373e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 37: train loss 1.3200514104028116e-06, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 44: train loss 1.0316680345567875e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG flwr 2023-06-08 16:54:49,348 | server.py:232 | fit_round 20 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:54:49,397 | server.py:168 | evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:54:49,731 | server.py:182 | evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:54:49,743 | server.py:218 | fit_round 21: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 21: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 50: train loss 8.439281486971595e-07, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 5: train loss 3.998558440798661e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 3.998558440798661e-06, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 12: train loss 2.3537591005151626e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 18: train loss 1.708136892375478e-06, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 24: train loss 1.3038882116234163e-06, accuracy 1.0\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 31: train loss 9.603393209545175e-07, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 33: train loss 7.680245630581339e-07, accuracy 1.0\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 43: train loss 6.552641593771114e-07, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 46: train loss 5.059728778178396e-07, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 4: train loss 4.0968661778606474e-05, accuracy 0.9979605710401088\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 1: train loss 0.00021184305660426617, accuracy 0.9959211420802175\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 7.552131592092337e-06, accuracy 1.0\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 13: train loss 2.0330442112026503e-06, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 18: train loss 1.688915176600858e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 25: train loss 1.2950231393915601e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 30: train loss 1.1287344250376918e-06, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 36: train loss 9.884621476885513e-07, accuracy 1.0\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 47: train loss 9.448315267945873e-07, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 49: train loss 7.788609082126641e-07, accuracy 1.0\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-08 16:56:23,190 | server.py:232 | fit_round 21 received 4 results and 0 failures\n",
            "DEBUG:flwr:fit_round 21 received 4 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:56:23,226 | server.py:168 | evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG:flwr:evaluate_round 21: strategy sampled 3 clients (out of 4)\n",
            "DEBUG flwr 2023-06-08 16:56:23,458 | server.py:182 | evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 21 received 3 results and 0 failures\n",
            "DEBUG flwr 2023-06-08 16:56:23,463 | server.py:218 | fit_round 22: strategy sampled 4 clients (out of 4)\n",
            "DEBUG:flwr:fit_round 22: strategy sampled 4 clients (out of 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89122)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 5: train loss 0.0002601266314741224, accuracy 0.9952413324269205\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=89121)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89121)\u001b[0m Epoch 7: train loss 7.604081474710256e-06, accuracy 1.0\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 12: train loss 3.169869160046801e-06, accuracy 1.0\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=89122)\u001b[0m Epoch 16: train loss 8.679980396664178e-07, accuracy 1.0\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "loop_list = strategy_list\n",
        "\n",
        "if loop_on_strategies is False: \n",
        "  loop_list = [strategy_type]\n",
        "\n",
        "for strategy_type in loop_list: \n",
        "  print(\"\\nAnalyzing Strategy... : \", strategy_type.capitalize())\n",
        "\n",
        "  # Crea un'istanza del modello e ne ottiene i parametri\n",
        "  if dataset == \"cifar10\":\n",
        "    params = get_parameters(ConvNet())\n",
        "  elif dataset == \"har\":\n",
        "    params = get_parameters(MLP())\n",
        "\n",
        "  if strategy_type == strategy_list[0]:\n",
        "    # Creazione della Strategia FedAvg\n",
        "    # Passa i parametri alla strategia per l'inizializzazione dei parametri lato Server\n",
        "    strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=n_clients,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=n_clients,\n",
        "        initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    )\n",
        "\n",
        "  if strategy_type == strategy_list[1]:\n",
        "    # Creazione della Strategia FedAdagrad\n",
        "    strategy = fl.server.strategy.FedAdagrad(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=n_clients,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=n_clients,\n",
        "        initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    )\n",
        "\n",
        "  if strategy_type == strategy_list[2]:\n",
        "    # Creazione della Strategia FedAdam\n",
        "    strategy = fl.server.strategy.FedAdam(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=n_clients,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=n_clients,\n",
        "        initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    )\n",
        "\n",
        "  if strategy_type == strategy_list[3]:\n",
        "    # Creazione della Strategia FedYogi\n",
        "    # Passa i parametri alla strategia per l'inizializzazione dei parametri lato Server\n",
        "    strategy = fl.server.strategy.FedYogi(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.3,\n",
        "        min_fit_clients=n_clients,\n",
        "        min_evaluate_clients=3,\n",
        "        min_available_clients=n_clients,\n",
        "        initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        "    )\n",
        "\n",
        "  # Specifica le risorse del client se si ha bisogno della GPU (default a 1 per CPU e 0 per GPU)\n",
        "  client_resources = None\n",
        "  if DEVICE.type == \"cuda\":\n",
        "      client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "  # Avvio della Simulazione\n",
        "  history = fl.simulation.start_simulation(\n",
        "      client_fn=client_fn,\n",
        "      num_clients=n_clients,\n",
        "      config=fl.server.ServerConfig(num_rounds=n_rounds), \n",
        "      strategy=strategy,\n",
        "      client_resources=client_resources,\n",
        "  )\n",
        "\n",
        "  '''\n",
        "  federated_weights = server.get_weights()\n",
        "  # Salvare i pesi del modello su disco\n",
        "  torch.save(federated_weights, \"federated_model_weights.pt\")\n",
        "  '''\n",
        "  \n",
        "  acc = [m[1] for m in history.losses_distributed]\n",
        "  plt.figure()\t\t\t\t\t\t\t\t\t\t\t\t# generate a new window\n",
        "  plt.plot(acc, label=strategy_type.capitalize()+' Accuracy', color = strategy_colors[loop_list.index(strategy_type)])\n",
        "  plt.legend()\n",
        "  plt.title(strategy_type.capitalize())\n",
        "  plt.savefig(\"./Outputs/\"+save_path+\"/\"+strategy_type+\".png\", dpi = 300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  strategies_acc.append((strategy_type, max(acc), acc[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Salvataggio dei Dati**"
      ],
      "metadata": {
        "id": "foPMZTGlDa_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategies_acc_df = pd.DataFrame(strategies_acc, columns = [\"Strategy\", \"Best Round Accuracy\", \"Last Round Accuracy\"])\n",
        "strategies_acc_df.to_csv(\"./Outputs/\"+save_path+\"/\"+\"fl_accuracies_over_strategies.csv\")\n",
        "strategies_acc_df.to_excel(\"./Outputs/\"+save_path+\"/\"+\"fl_accuracies_over_strategies.xlsx\")\n",
        "strategies_acc_df"
      ],
      "metadata": {
        "id": "zqcYMOEpIhup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Salvataggio delle Figure**"
      ],
      "metadata": {
        "id": "aefx0t3ODdvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al6IJtZ3XIWC"
      },
      "outputs": [],
      "source": [
        "#strategies_acc_df = pd.DataFrame(strategies_acc, columns=['Strategy', 'Max Accuracy', 'Last Accuracy'])\n",
        "strategies_acc_df.plot.bar()\n",
        "plt.xlabel(loop_list)\n",
        "plt.savefig(\"./Outputs/\"+save_path+\"/\"+\"fl_accuracies_over_strategies.png\", dpi = 300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Salvataggio dei Risultati**"
      ],
      "metadata": {
        "id": "sfhuVW5spwVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Plots and CSVs saved in ./Outputs/'+save_path+' folder.\")\n",
        "print(\"Zipping...\")\n",
        "os.system('zip -r '+save_path+'.zip '+'./Outputs/'+save_path)\n",
        "\n",
        "print(\"\\n\\n Elapsed Time: \", timeit.default_timer() - start_global_time)"
      ],
      "metadata": {
        "id": "YKZ-Pgg2puKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('flower-3.7.12')",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}